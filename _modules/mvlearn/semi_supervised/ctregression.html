

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mvlearn.semi_supervised.ctregression &mdash; mvlearn alpha documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/gallery-dataframe.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html">
          

          
            
            <img src="../../../_static/mvlearn-logo-transparent-white.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Using mvlearn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#installing-the-released-version-with-pip">Installing the released version with pip</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../install.html#including-optional-dependencies-for-full-functionality">Including optional dependencies for full functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#installing-the-released-version-with-conda-forge">Installing the released version with conda-forge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#python-package-dependencies">Python package dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#hardware-requirements">Hardware requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#os-requirements">OS Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Examples Gallery</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-cluster">Examples on cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_coregularized_spectral_tutorial.html">Multiview Coregularized Spectral Clustering Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spherical_kmeans_tutorial.html">Multiview Spherical KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_kmeans_tutorial.html">Multiview KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_kmeans_validation_simulated.html">Multiview vs. Singleview KMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spectral_tutorial.html">Multiview Spectral Clustering Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spectral_validation_simulated.html">Multiview vs. Singleview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_vs_singleview_spectral.html">Multiview vs. Singleview Spectral Clustering of UCI Multiview Digits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spectral_validation_complex.html">Conditional Independence of Views on Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_kmeans_validation_complex.html">Conditional Independence of Views on Multiview KMeans Clustering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-compose">Examples on compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/compose/plot_multiview_construction.html">Constructing multiple views to classify singleview data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/compose/plot_pipeline_sklearn_integration.html">Integrating mvlearn with scikit-learn</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-datasets">Examples on datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/datasets/plot_load_ucimultifeature.html">Loading and Viewing the UCI Multiple Features Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/datasets/plot_gaussianmixtures.html">Generating Multiview Data from Gaussian Mixtures</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-decomposition">Examples on decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/decomposition/plot_group_ica_tutorial.html">ICA: a tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/decomposition/plot_mv_ica_tutorial.html">Multiview Independent Component Analysis (ICA) Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/decomposition/plot_ajive_tutorial.html">Angle-based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-embed">Examples on embed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_gcca_tutorial.html">Generalized Canonical Correlation Analysis (GCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_mcca_tutorial.html">CCA Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_dcca_tutorial.html">Deep CCA (DCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_omnibus_embedding.html">Omnbius Graph Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_kmcca_pgso_tutorial.html">Partial Gram-Schmidt Orthogonalization (PGSO) for KMCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_mvmds_tutorial.html">Multidimensional Scaling (MVMDS) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_cca_comparison.html">Comparing CCA Variants</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_kmcca_tutorial.html">Kernel MCCA (KMCCA) Tutorial</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-plotting">Examples on plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plotting/plot_quick_visualize_tutorial.html">Quickly Visualizing Multiview Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plotting/plot_crossviews_plot.html">Plotting Multiview Data with a Cross-view Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-semi-supervised">Examples on semi_supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/semi_supervised/plot_cotraining_regression.html">2-View Semi-Supervised Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/semi_supervised/plot_cotraining_classification.html">2-View Semi-Supervised Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references/index.html">Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../references/embed.html">Embedding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#canonical-correlation-analysis-cca">Canonical Correlation Analysis (CCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#multiview-canonical-correlation-analysis-mcca">Multiview Canonical Correlation Analysis (MCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#kernel-mcca">Kernel MCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#generalized-canonical-correlation-analysis-gcca">Generalized Canonical Correlation Analysis (GCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#deep-canonical-correlation-analysis-dcca">Deep Canonical Correlation Analysis (DCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#omnibus-embedding">Omnibus Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#multiview-multidimensional-scaling">Multiview Multidimensional Scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#split-autoencoder">Split Autoencoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#dcca-utilities">DCCA Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#dimension-selection">Dimension Selection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/decomposition.html">Decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#multiview-ica">Multiview ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#group-ica">Group ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#group-pca">Group PCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#angle-based-joint-and-individual-variation-explained-ajive">Angle-Based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/cluster.html">Clustering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#multiview-spectral-clustering">Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#co-regularized-multiview-spectral-clustering">Co-Regularized Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#multiview-k-means">Multiview K Means</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#multiview-spherical-k-means">Multiview Spherical K Means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/semi_supervised.html">Semi-Supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/semi_supervised.html#cotraining-classifier">Cotraining Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/semi_supervised.html#cotraining-regressor">Cotraining Regressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/model_selection.html">Model Selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/model_selection.html#cross-validation">Cross Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/model_selection.html#train-test-split">Train-Test Split</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/compose.html">Compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#averagemerger">AverageMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#concatmerger">ConcatMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#randomgaussianprojection">RandomGaussianProjection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#randomsubspacemethod">RandomSubspaceMethod</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#simplesplitter">SimpleSplitter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#viewclassifier">ViewClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#viewtransformer">ViewTransformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/datasets.html">Multiview Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/datasets.html#uci-multiple-feature-dataset-located-here">UCI multiple feature dataset (located here)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/datasets.html#data-simulator">Data Simulator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/datasets.html#factor-model">Factor Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/plotting.html">Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/plotting.html#quick-visualize">Quick Visualize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/plotting.html#crossviews-plot">Crossviews Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/utils.html">Utility Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/utils.html#io">IO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Developer Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing to mvlearn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#submitting-a-bug-report-or-a-feature-request">Submitting a bug report or a feature request</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#how-to-make-a-good-bug-report">How to make a good bug report</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#contributing-code">Contributing Code</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#pull-request-checklist">Pull Request Checklist</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#guidelines">Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#coding-guidelines">Coding Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#docstring-guidelines">Docstring Guidelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#api-of-mvlearn-objects">API of mvlearn Objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#estimators">Estimators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#additional-functionality">Additional Functionality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-4-0">Version 0.4.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id1">mvlearn.compose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id9">mvlearn.construct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id11">mvlearn.decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id13">mvlearn.embed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id17">mvlearn.model_selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id20">mvlearn.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-3-0">Version 0.3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#patch-0-2-1">Patch 0.2.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-2-0">Version 0.2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-1-0">Version 0.1.0</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Useful Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn">mvlearn &#64; GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/mvlearn/">mvlearn &#64; PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn/issues">Issue Tracker</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">mvlearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>mvlearn.semi_supervised.ctregression</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mvlearn.semi_supervised.ctregression</h1><div class="highlight"><pre>
<span></span><span class="c1"># License: MIT</span>
<span class="c1">#</span>
<span class="c1"># Implements multi-view co-training regression for 2-view data.</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">..utils.utils</span> <span class="kn">import</span> <span class="n">check_Xs</span><span class="p">,</span> <span class="n">check_Xs_y_nan_allowed</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">BaseCoTrainEstimator</span>


<div class="viewcode-block" id="CTRegressor"><a class="viewcode-back" href="../../../references/semi_supervised.html#mvlearn.semi_supervised.CTRegressor">[docs]</a><span class="k">class</span> <span class="nc">CTRegressor</span><span class="p">(</span><span class="n">BaseCoTrainEstimator</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class implements the co-training regression for supervised</span>
<span class="sd">    and semi supervised learning with the framework as described in [#1CTR]_.</span>
<span class="sd">    The best use case is when 2 views of input data are sufficiently</span>
<span class="sd">    distinct and independent as detailed in [#1CTR]_. However this can also</span>
<span class="sd">    be successfull when a single matrix of input data is given as</span>
<span class="sd">    both views and two estimators are choosen</span>
<span class="sd">    which are quite different [#2CTR]_.</span>

<span class="sd">    In the semi-supervised case, performance can vary greatly, so using</span>
<span class="sd">    a separate validation set or cross validation procedure is</span>
<span class="sd">    recommended to ensure the regression model has fit well.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator1: sklearn object, (only supports KNeighborsRegressor)</span>
<span class="sd">        The regressor object which will be trained on view1 of the data.</span>

<span class="sd">    estimator2: sklearn object, (only supports KNeighborsRegressor)</span>
<span class="sd">        The regressir object which will be trained on view2 of the data.</span>

<span class="sd">    k_neighbors: int, optional (default = 5)</span>
<span class="sd">        The number of neighbors to be considered for determining the mean</span>
<span class="sd">        squared error.</span>

<span class="sd">    unlabeled_pool_size: int, optional (default = 50)</span>
<span class="sd">        The number of unlabeled_pool samples which will be kept in a</span>
<span class="sd">        separate pool for regression and selection by the updated</span>
<span class="sd">        regressor at each training iteration.</span>

<span class="sd">    num_iter: int, optional (default = 100)</span>
<span class="sd">        The maximum number of iteration to be performed</span>

<span class="sd">    random_state: int (default = None)</span>
<span class="sd">        The seed for fit() method and other class operations</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator1_ : regressor object, used on view1</span>

<span class="sd">    estimator2_ : regressor object, used on view2</span>

<span class="sd">    class_name_: string</span>
<span class="sd">        The name of the class.</span>

<span class="sd">    k_neighbors_ : int</span>
<span class="sd">        The number of neighbors to be considered for determining</span>
<span class="sd">        the mean squared error.</span>

<span class="sd">    unlabeled_pool_size: int</span>
<span class="sd">        The number of unlabeled_pool samples which will be kept in a</span>
<span class="sd">        separate pool for regression and selection by the updated</span>
<span class="sd">        regressor at each training iteration.</span>

<span class="sd">    num_iter: int</span>
<span class="sd">        The maximum number of iterations to be performed</span>

<span class="sd">    n_views : int</span>
<span class="sd">        The number of views in the data</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mvlearn.semi_supervised import CTRegressor</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.neighbors import KNeighborsRegressor</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; # X1 and X2 are the 2 views of the data</span>
<span class="sd">    &gt;&gt;&gt; X1 = [[0], [1], [2], [3], [4], [5], [6]]</span>
<span class="sd">    &gt;&gt;&gt; X2 = [[2], [3], [4], [6], [7], [8], [10]]</span>
<span class="sd">    &gt;&gt;&gt; y = [10, 11, 12, 13, 14, 15, 16]</span>
<span class="sd">    &gt;&gt;&gt; # Converting some of the labeled values to nan</span>
<span class="sd">    &gt;&gt;&gt; y_train = [10, np.nan, 12, np.nan, 14, np.nan, 16]</span>
<span class="sd">    &gt;&gt;&gt; knn1 = KNeighborsRegressor(n_neighbors = 2)</span>
<span class="sd">    &gt;&gt;&gt; knn2 = KNeighborsRegressor(n_neighbors = 2)</span>
<span class="sd">    &gt;&gt;&gt; ctr = CTRegressor(knn1, knn2, k_neighbors = 2, random_state =  42)</span>
<span class="sd">    &gt;&gt;&gt; ctr = ctr.fit([X1, X2], y_train)</span>
<span class="sd">    &gt;&gt;&gt; pred = ctr.predict([X1, X2])</span>
<span class="sd">    &gt;&gt;&gt; print(&quot;True value\n{}&quot;.format(y))</span>
<span class="sd">    True value</span>
<span class="sd">    [10, 11, 12, 13, 14, 15, 16]</span>
<span class="sd">    &gt;&gt;&gt; print(&quot;Predicted value\n{}&quot;.format(pred))</span>
<span class="sd">    Predicted value</span>
<span class="sd">    [10.75 11.25 11.25 13.25 13.25 14.75 15.25]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Multi-view co-training is most helpful for tasks in semi-supervised</span>
<span class="sd">    learning where each view offers unique information not seen in the</span>
<span class="sd">    other. As is shown in the example notebooks for using this algorithm,</span>
<span class="sd">    multi-view co-training can provide good regression results even</span>
<span class="sd">    when number of unlabeled samples far exceeds the number of labeled</span>
<span class="sd">    samples. This regressor uses 2 sklearn regressors which work individually</span>
<span class="sd">    on each view but which share information and thus result in improved</span>
<span class="sd">    performance over looking at the views completely separately.</span>
<span class="sd">    The regressor needs to be KNeighborsRegressor,</span>
<span class="sd">    as described in the [#1CTR]_.</span>

<span class="sd">    Algorithm: Given</span>

<span class="sd">        * a set *L1*, *L2* having labeled training</span>
<span class="sd">        samples of each view respectively</span>

<span class="sd">        * a set *U* of unlabeled samples</span>

<span class="sd">        Create a pool *U&#39;* of examples by choosing examples at random</span>
<span class="sd">        from *U*</span>

<span class="sd">        * Use *L1* to train a regressor *h1* (``estimator1``) that considers</span>
<span class="sd">          only the view1 portion of the data (i.e. Xs[0])</span>
<span class="sd">        * Use *L2* to train a regressor *h2* (``estimator2``) that considers</span>
<span class="sd">          only the view2 portion of the data (i.e. Xs[1])</span>

<span class="sd">        Loop for *T* iterations</span>
<span class="sd">            * for each view *j*</span>
<span class="sd">                * for each *u* in *U&#39;*</span>
<span class="sd">                    * Calculate the neighbors of *u*</span>
<span class="sd">                    * Predict the value of *u* using *hj* estimator</span>
<span class="sd">                    * create a new estimator *hj&#39;* with same parameters</span>
<span class="sd">                    as that of *hj* and train it on the data (*Lj* union *u*)</span>
<span class="sd">                    * predict the value of neighbors from estimator *hj*</span>
<span class="sd">                    and calculate the mean squared error with respect to</span>
<span class="sd">                    original values</span>
<span class="sd">                    * predict the value of neighbors from the new</span>
<span class="sd">                    estimator *hj&#39;* and calculate the mean squared error</span>
<span class="sd">                    with respect to original values</span>
<span class="sd">                    * calculate the difference between the two errors</span>
<span class="sd">                    * store the error in a list named *deltaj*</span>
<span class="sd">            * select the index with maximum positive value from both</span>
<span class="sd">            the *delta1* and *delta2*</span>
<span class="sd">            * let the indexes selected be *index1* and *index2*</span>
<span class="sd">            * Add the *index1* to *L2*</span>
<span class="sd">            * Add the *index2* to *L1*</span>
<span class="sd">            * Remove the  selected index from *U&#39;* and replenish</span>
<span class="sd">            it by taking unlabeled index from *U*</span>
<span class="sd">            * Use *L1* to train the regressor *h1*</span>
<span class="sd">            * Use *L2* to train the regressor *h2*</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [#1CTR] Semi-Supervised Regression with</span>
<span class="sd">            Co-Training by Zhi-Hua Zhou and Ming Li</span>
<span class="sd">            https://pdfs.semanticscholar.org/437c/85ad1c05f60574544d31e96bd8e60393fc92.pdf</span>

<span class="sd">    .. [#2CTR] Goldman, Sally, and Yan Zhou. &quot;Enhancing supervised</span>
<span class="sd">            learning with unlabeled data.&quot; ICML. 2000.</span>
<span class="sd">            http://www.cs.columbia.edu/~dplewis/candidacy/goldman00enhancing.pdf</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator1</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">estimator2</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">k_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">unlabeled_pool_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">num_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>

        <span class="c1"># initialize a BaseCTEstimator object</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">estimator1</span><span class="p">,</span> <span class="n">estimator2</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>

        <span class="c1"># If not given, initialize with default KNeighborsRegrssor</span>
        <span class="k">if</span> <span class="n">estimator1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator1</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">estimator2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator2</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>

        <span class="c1"># Initializing the other attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span> <span class="o">=</span> <span class="n">estimator1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span> <span class="o">=</span> <span class="n">estimator2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_neighbors_</span> <span class="o">=</span> <span class="n">k_neighbors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unlabeled_pool_size</span> <span class="o">=</span> <span class="n">unlabeled_pool_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_iter</span> <span class="o">=</span> <span class="n">num_iter</span>

        <span class="c1"># Used in fit method while selecting a pool of unlabeled samples</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_views</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_name_</span> <span class="o">=</span> <span class="s2">&quot;CTRegressor&quot;</span>

        <span class="c1"># checks whether the parameters given is valid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks that cotraining parameters are valid. Throws AttributeError</span>
<span class="sd">        if estimators are invalid. Throws ValueError if any other parameters</span>
<span class="sd">        are not valid. The checks performed are:</span>
<span class="sd">            - estimator1 and estimator2 are KNeigborsRegressor</span>
<span class="sd">            - k_neighbors_ is positive</span>
<span class="sd">            - unlabeled_pool_size is positive</span>
<span class="sd">            - num_iter is positive</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># The estimator must be KNeighborsRegressor</span>
        <span class="n">to_be_matched</span> <span class="o">=</span> <span class="s2">&quot;KNeighborsRegressor&quot;</span>

        <span class="c1"># Taking the str of estimator object</span>
        <span class="c1"># returns the class name along with other parameters</span>
        <span class="n">string1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="p">)</span>
        <span class="n">string2</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="p">)</span>

        <span class="c1"># slicing the list to get the name of the estimator</span>
        <span class="n">string1</span> <span class="o">=</span> <span class="n">string1</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_be_matched</span><span class="p">)]</span>
        <span class="n">string2</span> <span class="o">=</span> <span class="n">string2</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_be_matched</span><span class="p">)]</span>

        <span class="k">if</span> <span class="n">string1</span> <span class="o">!=</span> <span class="n">to_be_matched</span> <span class="ow">or</span> <span class="n">string2</span> <span class="o">!=</span> <span class="n">to_be_matched</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s2">&quot;Both the estimator needs to be KNeighborsRegressor&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_neighbors_</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;k_neighbors must be positive&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unlabeled_pool_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;unlabeled_pool_size must be positive&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_iter</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;number of iterations must be positive&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="CTRegressor.fit"><a class="viewcode-back" href="../../../references/semi_supervised.html#mvlearn.semi_supervised.CTRegressor.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the regressor object to the data in Xs, y.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : list of array-likes or numpy.ndarray</span>
<span class="sd">            - Xs length: n_views</span>
<span class="sd">            - Xs[i] shape: (n_samples, n_features_i)</span>
<span class="sd">            A list of the different views of data to train on.</span>

<span class="sd">        y : array, shape (n_samples,)</span>
<span class="sd">            The target values of the training data. Unlabeled examples</span>
<span class="sd">            should have label np.nan.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : returns an instance of self</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check whether Xs contain NaN and both Xs and y</span>
        <span class="c1"># are consistent with each other</span>
        <span class="n">Xs</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_Xs_y_nan_allowed</span><span class="p">(</span>
            <span class="n">Xs</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">multiview</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enforce_views</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_views</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Xs contain two view</span>
        <span class="n">X1</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">X2</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Storing the indexes of the unlabeled samples</span>
        <span class="n">U</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

        <span class="c1"># Storing the indexes of the labeled samples</span>
        <span class="n">L</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

        <span class="c1"># making two true labels for each view</span>
        <span class="c1"># So that we can make changes to it without altering original labels</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">y2</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># contains the indexes of labeled samples</span>
        <span class="n">L1</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">L2</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># fitting the estimator object on the train data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="n">L1</span><span class="p">],</span> <span class="n">y1</span><span class="p">[</span><span class="n">L1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X2</span><span class="p">[</span><span class="n">L2</span><span class="p">],</span> <span class="n">y2</span><span class="p">[</span><span class="n">L2</span><span class="p">])</span>

        <span class="c1"># declaring a variable which keeps tracks</span>
        <span class="c1"># of the number of iteration performed</span>
        <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Randomly selected index of unlabeled data samples</span>
        <span class="n">unlabeled_pool</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">U</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">U</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">unlabeled_pool_size</span><span class="p">))</span>

        <span class="c1"># Removing the unlabeled samples which were selected earlier</span>
        <span class="n">U</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">U</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unlabeled_pool</span><span class="p">]</span>

        <span class="k">while</span> <span class="n">it</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_iter</span> <span class="ow">and</span> <span class="n">unlabeled_pool</span><span class="p">:</span>
            <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># list of k nearest neighbors for all unlabeled samples</span>
            <span class="n">neighbors1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span>
                <span class="n">X1</span><span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">],</span>
                <span class="n">n_neighbors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k_neighbors_</span><span class="p">,</span>
                <span class="n">return_distance</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">neighbors2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span>
                <span class="n">X2</span><span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">],</span>
                <span class="n">n_neighbors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k_neighbors_</span><span class="p">,</span>
                <span class="n">return_distance</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># Stores the delta value of each view</span>
            <span class="n">delta1</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">delta2</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">neigh</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">,</span> <span class="n">neighbors1</span><span class="p">)):</span>

                <span class="c1"># Making a copy of L1 to include the unlabeled index</span>
                <span class="n">new_L1</span> <span class="o">=</span> <span class="n">L1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">new_L1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

                <span class="c1"># Predicts the value of unlabeled index</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

                <span class="c1"># assigning the predicted value to new y</span>
                <span class="n">new_y1</span> <span class="o">=</span> <span class="n">y1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">new_y1</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>

                <span class="c1"># prediction array before inclusion of unlabeled index</span>
                <span class="n">pred_before_inc</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="n">pred_before_inc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">predict</span><span class="p">((</span><span class="n">X1</span><span class="p">[</span><span class="n">L1</span><span class="p">])[</span><span class="n">neigh</span><span class="p">])</span>

                <span class="c1"># new estimator for training a regressor model on new L1</span>
                <span class="n">new_estimator</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>

                <span class="c1"># Setting the same parameters as that of estimator1 object</span>
                <span class="n">new_estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">get_params</span><span class="p">())</span>
                <span class="n">new_estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="n">new_L1</span><span class="p">],</span> <span class="n">new_y1</span><span class="p">[</span><span class="n">new_L1</span><span class="p">])</span>

                <span class="c1"># prediction array after inclusion of unlabeled index</span>
                <span class="n">pred_after_inc</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">pred_after_inc</span> <span class="o">=</span> <span class="n">new_estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">((</span><span class="n">X1</span><span class="p">[</span><span class="n">L1</span><span class="p">])[</span><span class="n">neigh</span><span class="p">])</span>

                <span class="n">mse_before_inc</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">y1</span><span class="p">[</span><span class="n">L1</span><span class="p">])[</span><span class="n">neigh</span><span class="p">],</span> <span class="n">pred_before_inc</span><span class="p">)</span>

                <span class="n">mse_after_inc</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">y1</span><span class="p">[</span><span class="n">L1</span><span class="p">])[</span><span class="n">neigh</span><span class="p">],</span> <span class="n">pred_after_inc</span><span class="p">)</span>

                <span class="c1"># appending the calculated value to delta1</span>
                <span class="n">delta1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse_before_inc</span> <span class="o">-</span> <span class="n">mse_after_inc</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">neigh</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">,</span> <span class="n">neighbors2</span><span class="p">)):</span>

                <span class="c1"># Making a copy of L2 to include the unlabeled index</span>
                <span class="n">new_L2</span> <span class="o">=</span> <span class="n">L2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">new_L2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

                <span class="c1"># Predicts the value of unlabeled index</span>
                <span class="n">pred_before_inc</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X2</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

                <span class="c1"># assigning the predicted value to new y</span>
                <span class="n">new_y2</span> <span class="o">=</span> <span class="n">y2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">new_y2</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>

                <span class="c1"># prediction array before inclusion of unlabeled index</span>
                <span class="n">pred_before_inc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">predict</span><span class="p">((</span><span class="n">X2</span><span class="p">[</span><span class="n">L2</span><span class="p">])[</span><span class="n">neigh</span><span class="p">])</span>

                <span class="c1"># new estimator for training a regressor model on new L2</span>
                <span class="n">new_estimator</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>

                <span class="c1"># Setting the same parameters as that of estimator2 object</span>
                <span class="n">new_estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">get_params</span><span class="p">())</span>
                <span class="n">new_estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X2</span><span class="p">[</span><span class="n">new_L2</span><span class="p">],</span> <span class="n">new_y2</span><span class="p">[</span><span class="n">new_L2</span><span class="p">])</span>

                <span class="c1"># prediction array after inclusion of unlabeled index</span>
                <span class="n">pred_after_inc</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">pred_after_inc</span> <span class="o">=</span> <span class="n">new_estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">((</span><span class="n">X2</span><span class="p">[</span><span class="n">L2</span><span class="p">])[</span><span class="n">neigh</span><span class="p">])</span>

                <span class="n">mse_before_inc</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">y2</span><span class="p">[</span><span class="n">L2</span><span class="p">])[</span><span class="n">neigh</span><span class="p">],</span> <span class="n">pred_before_inc</span><span class="p">)</span>

                <span class="n">mse_after_inc</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">y2</span><span class="p">[</span><span class="n">L2</span><span class="p">])[</span><span class="n">neigh</span><span class="p">],</span> <span class="n">pred_after_inc</span><span class="p">)</span>

                <span class="c1"># appending the calculated value to delta2</span>
                <span class="n">delta2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse_before_inc</span> <span class="o">-</span> <span class="n">mse_after_inc</span><span class="p">)</span>

            <span class="n">delta1_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">delta1</span><span class="p">)</span>
            <span class="n">delta2_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">delta2</span><span class="p">)</span>

            <span class="c1"># list containing the indexes to be included</span>
            <span class="n">to_include1</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">to_include2</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            If the length of both the delta&#39;s is equal to 1 then</span>
<span class="sd">            include the corresponding index whose value is positive and</span>
<span class="sd">            greater than the other values.</span>
<span class="sd">            Else selecting the indexes which have postive and maximum</span>
<span class="sd">            value from each delta&#39;s and incase both the indexes are equal</span>
<span class="sd">            then look at the second best positive value.</span>
<span class="sd">            The indexes which are selected from delta1</span>
<span class="sd">            will be added to the labels of the estimator2 object.</span>
<span class="sd">            Similarly, the indexes which are selected from delta2</span>
<span class="sd">            will be added to the labels of the estimator1 object.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="n">delta1_index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">delta2_index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>

                <span class="k">if</span> <span class="n">delta1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">delta2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">delta1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">delta2</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                        <span class="n">L2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                        <span class="n">to_include2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">L1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                        <span class="n">to_include1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">elif</span> <span class="n">delta1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">L2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">to_include2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">elif</span> <span class="n">delta2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">L1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">to_include1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>

                <span class="c1"># Top two indexes from each delta</span>
                <span class="n">index1_1</span><span class="p">,</span> <span class="n">index1_2</span> <span class="o">=</span> <span class="n">delta1_index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">delta1_index</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="n">index2_1</span><span class="p">,</span> <span class="n">index2_2</span> <span class="o">=</span> <span class="n">delta2_index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">delta2_index</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">index1_1</span> <span class="o">!=</span> <span class="n">index2_1</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">delta1</span><span class="p">[</span><span class="n">index1_1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">L2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index1_1</span><span class="p">])</span>
                        <span class="n">to_include2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index1_1</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">delta2</span><span class="p">[</span><span class="n">index2_1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">L1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index2_1</span><span class="p">])</span>
                        <span class="n">to_include1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index2_1</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">delta1</span><span class="p">[</span><span class="n">index1_1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">delta2</span><span class="p">[</span><span class="n">index2_1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">delta1</span><span class="p">[</span><span class="n">index1_1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">delta2</span><span class="p">[</span><span class="n">index2_1</span><span class="p">]:</span>
                            <span class="n">L2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index1_1</span><span class="p">])</span>
                            <span class="n">to_include2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index1_1</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">delta2</span><span class="p">[</span><span class="n">index2_2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">L1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index2_2</span><span class="p">])</span>
                                <span class="n">to_include1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index2_2</span><span class="p">)</span>

                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">L1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index2_1</span><span class="p">])</span>
                            <span class="n">to_include1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index2_1</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">delta1</span><span class="p">[</span><span class="n">index1_2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">L2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index1_2</span><span class="p">])</span>
                                <span class="n">to_include2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index1_2</span><span class="p">)</span>

                    <span class="k">elif</span> <span class="n">delta1</span><span class="p">[</span><span class="n">index1_1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">L2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index1_1</span><span class="p">])</span>
                        <span class="n">to_include2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index1_1</span><span class="p">)</span>

                    <span class="k">elif</span> <span class="n">delta2</span><span class="p">[</span><span class="n">index2_1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">L1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">index2_1</span><span class="p">])</span>
                        <span class="n">to_include1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index2_1</span><span class="p">)</span>

            <span class="c1"># break if to_include1 and to_include2 are empty</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_include1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_include2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="c1"># including the selected index</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">to_include1</span><span class="p">:</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X2</span><span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
                <span class="n">y1</span><span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pred</span>

            <span class="c1"># including the selected index</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">to_include2</span><span class="p">:</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
                <span class="n">y2</span><span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pred</span>

            <span class="c1"># Currently to_include contains the index of unlabeled samples</span>
            <span class="c1"># in the order in which they are stored in unlabeled_pool</span>
            <span class="c1"># Converting them to the value which unlabeled_pool stores</span>
            <span class="c1"># example unlabeled_pool = [10, 15, 17]</span>
            <span class="c1"># current to_include = [1, 2]</span>
            <span class="c1"># updated to_include = [15, 17]</span>
            <span class="n">to_include1</span> <span class="o">=</span> <span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">to_include1</span><span class="p">]</span>
            <span class="n">to_include2</span> <span class="o">=</span> <span class="p">[</span><span class="n">unlabeled_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">to_include2</span><span class="p">]</span>

            <span class="c1"># removing the selected index</span>
            <span class="n">unlabeled_pool</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">u</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">unlabeled_pool</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">u</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">to_include1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">u</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">to_include2</span><span class="p">)]</span>

            <span class="c1"># replenishing the unlabeled pool</span>
            <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">U</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unlabeled_pool</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">unlabeled_pool_size</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">u</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unlabeled_pool</span><span class="p">:</span>
                        <span class="n">unlabeled_pool</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="n">U</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">U</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unlabeled_pool</span><span class="p">]</span>

            <span class="c1"># fitting the model on new train data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="n">L1</span><span class="p">],</span> <span class="n">y1</span><span class="p">[</span><span class="n">L1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X2</span><span class="p">[</span><span class="n">L2</span><span class="p">],</span> <span class="n">y2</span><span class="p">[</span><span class="n">L2</span><span class="p">])</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="CTRegressor.predict"><a class="viewcode-back" href="../../../references/semi_supervised.html#mvlearn.semi_supervised.CTRegressor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the values of the samples in the two input views.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : list of array-likes or numpy.ndarray</span>
<span class="sd">            - Xs length: n_views</span>
<span class="sd">            - Xs[i] shape: (n_samples, n_features_i)</span>
<span class="sd">            A list of the different views of data to predict.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_pred : array-like (n_samples,)</span>
<span class="sd">            The average of the predictions from both estimators is returned</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="n">check_Xs</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">multiview</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enforce_views</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_views</span><span class="p">)</span>

        <span class="n">X1</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">X2</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># predicting the value of each view</span>
        <span class="n">pred1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator1_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
        <span class="n">pred2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator2_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>

        <span class="c1"># Taking the average of the predicted value and returning it</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">pred1</span> <span class="o">+</span> <span class="n">pred2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-2020

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
<p style="text-align: center; margin: .5rem;">
    <a href="https://www.netlify.com">
        <img src="https://www.netlify.com/img/global/badges/netlify-color-accent.svg" />
    </a>
</p>
 


</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../_static/js/copybutton.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>