<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mvlearn.embed.kmcca &mdash; mvlearn alpha documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/mvlearn-logo-32x32.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/js/copybutton.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html">
            <img src="../../../_static/mvlearn-logo-transparent-white.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.4.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Using mvlearn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Overview of mvlearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#installing-the-released-version-with-pip">Installing the released version with pip</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../install.html#including-optional-dependencies-for-full-functionality">Including optional dependencies for full functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#installing-the-released-version-with-conda-forge">Installing the released version with conda-forge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#python-package-dependencies">Python package dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#hardware-requirements">Hardware requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#os-requirements">OS Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Examples Gallery</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-cluster">Examples on cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_coregularized_spectral_tutorial.html">Multiview Coregularized Spectral Clustering Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spherical_kmeans_tutorial.html">Multiview Spherical KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_kmeans_tutorial.html">Multiview KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_vs_singleview_spectral.html">Multiview vs. Singleview Spectral Clustering of UCI Multiview Digits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_kmeans_validation_simulated.html">Multiview vs. Singleview KMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spectral_tutorial.html">Multiview Spectral Clustering Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spectral_validation_simulated.html">Multiview vs. Singleview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_spectral_validation_complex.html">Conditional Independence of Views on Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/cluster/plot_mv_kmeans_validation_complex.html">Conditional Independence of Views on Multiview KMeans Clustering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-compose">Examples on compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/compose/plot_multiview_construction.html">Constructing multiple views to classify singleview data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/compose/plot_pipeline_sklearn_integration.html">Integrating mvlearn with scikit-learn</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-datasets">Examples on datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/datasets/plot_load_ucimultifeature.html">Loading and Viewing the UCI Multiple Features Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/datasets/plot_gaussianmixtures.html">Generating Multiview Data from Gaussian Mixtures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/datasets/plot_nutrimouse.html">An mvlearn case study: the Nutrimouse dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-decomposition">Examples on decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/decomposition/plot_group_ica_tutorial.html">ICA: a tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/decomposition/plot_mv_ica_tutorial.html">Multiview Independent Component Analysis (ICA) Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/decomposition/plot_ajive_tutorial.html">Angle-based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-embed">Examples on embed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_gcca_tutorial.html">Generalized Canonical Correlation Analysis (GCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_mcca_tutorial.html">CCA Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_dcca_tutorial.html">Deep CCA (DCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_omnibus_embedding.html">Omnbius Graph Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_kmcca_pgso_tutorial.html">Partial Gram-Schmidt Orthogonalization (PGSO) for KMCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_mvmds_tutorial.html">Multidimensional Scaling (MVMDS) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_cca_comparison.html">Comparing CCA Variants</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/embed/plot_kmcca_tutorial.html">Kernel MCCA (KMCCA) Tutorial</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-plotting">Examples on plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plotting/plot_quick_visualize_tutorial.html">Quickly Visualizing Multiview Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plotting/plot_crossviews_plot.html">Plotting Multiview Data with a Cross-view Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/index.html#examples-on-semi-supervised">Examples on semi_supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/semi_supervised/plot_cotraining_regression.html">2-View Semi-Supervised Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/semi_supervised/plot_cotraining_classification.html">2-View Semi-Supervised Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references/index.html">Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../references/embed.html">Embedding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#canonical-correlation-analysis-cca">Canonical Correlation Analysis (CCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#multiview-canonical-correlation-analysis-mcca">Multiview Canonical Correlation Analysis (MCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#kernel-mcca">Kernel MCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#generalized-canonical-correlation-analysis-gcca">Generalized Canonical Correlation Analysis (GCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#deep-canonical-correlation-analysis-dcca">Deep Canonical Correlation Analysis (DCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#omnibus-embedding">Omnibus Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#multiview-multidimensional-scaling">Multiview Multidimensional Scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#split-autoencoder">Split Autoencoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#dcca-utilities">DCCA Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/embed.html#dimension-selection">Dimension Selection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/decomposition.html">Decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#multiview-ica">Multiview ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#group-ica">Group ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#group-pca">Group PCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/decomposition.html#angle-based-joint-and-individual-variation-explained-ajive">Angle-Based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/cluster.html">Clustering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#multiview-spectral-clustering">Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#co-regularized-multiview-spectral-clustering">Co-Regularized Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#multiview-k-means">Multiview K Means</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/cluster.html#multiview-spherical-k-means">Multiview Spherical K Means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/semi_supervised.html">Semi-Supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/semi_supervised.html#cotraining-classifier">Cotraining Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/semi_supervised.html#cotraining-regressor">Cotraining Regressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/model_selection.html">Model Selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/model_selection.html#cross-validation">Cross Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/model_selection.html#train-test-split">Train-Test Split</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/compose.html">Compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#averagemerger">AverageMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#concatmerger">ConcatMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#randomgaussianprojection">RandomGaussianProjection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#randomsubspacemethod">RandomSubspaceMethod</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#simplesplitter">SimpleSplitter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#viewclassifier">ViewClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/compose.html#viewtransformer">ViewTransformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/datasets.html">Multiview Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/datasets.html#uci-multiple-feature-dataset">UCI multiple feature dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/datasets.html#nutrimouse-dataset">Nutrimouse dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/datasets.html#data-simulator">Data Simulator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/datasets.html#factor-model">Factor Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/plotting.html">Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/plotting.html#quick-visualize">Quick Visualize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references/plotting.html#crossviews-plot">Crossviews Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../references/utils.html">Utility Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references/utils.html#io">IO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing to mvlearn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#submitting-a-bug-report-or-a-feature-request">Submitting a bug report or a feature request</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#how-to-make-a-good-bug-report">How to make a good bug report</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#contributing-code">Contributing Code</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#pull-request-checklist">Pull Request Checklist</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#guidelines">Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#coding-guidelines">Coding Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#docstring-guidelines">Docstring Guidelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributing.html#api-of-mvlearn-objects">API of mvlearn Objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#estimators">Estimators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../contributing.html#additional-functionality">Additional Functionality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#unreleased">Unreleased</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-4-1">Version 0.4.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-4-0">Version 0.4.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id3">mvlearn.compose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id11">mvlearn.construct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id13">mvlearn.decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id15">mvlearn.embed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id19">mvlearn.model_selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../changelog.html#id22">mvlearn.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-3-0">Version 0.3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#patch-0-2-1">Patch 0.2.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-2-0">Version 0.2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../changelog.html#version-0-1-0">Version 0.1.0</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Useful Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn">mvlearn &#64; GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/mvlearn/">mvlearn &#64; PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn/issues">Issue Tracker</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">mvlearn</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>mvlearn.embed.kmcca</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mvlearn.embed.kmcca</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Kernel Multiview Canonical Correlation Analysis&quot;&quot;&quot;</span>

<span class="c1"># Authors: Iain Carmichael, Ronan Perry</span>
<span class="c1"># License: MIT</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_kernels</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">check_Xs</span><span class="p">,</span> <span class="n">param_as_list</span>
<span class="kn">from</span> <span class="nn">..compose</span> <span class="kn">import</span> <span class="n">SimpleSplitter</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">eigh_wrapper</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">BaseCCA</span><span class="p">,</span> <span class="n">_check_regs</span><span class="p">,</span> <span class="n">_initial_svds</span><span class="p">,</span> <span class="n">_deterministic_decomp</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_array</span>


<div class="viewcode-block" id="KMCCA"><a class="viewcode-back" href="../../../references/embed.html#mvlearn.embed.KMCCA">[docs]</a><span class="k">class</span> <span class="nc">KMCCA</span><span class="p">(</span><span class="n">BaseCCA</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Kernel multi-view canonical correlation analysis.</span>

<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    n_components : int, None (default 1)</span>
<span class="sd">        Number of components to compute. If None, will use the number of</span>
<span class="sd">        features.</span>

<span class="sd">    kernel : str, callable, or list (default &#39;linear&#39;)</span>
<span class="sd">        The kernel function to use. This is the metric argument to</span>
<span class="sd">        ``sklearn.metrics.pairwise.pairwise_kernels``. A list will</span>
<span class="sd">        specify for each view separately.</span>

<span class="sd">    kernel_params : dict, or list (default {})</span>
<span class="sd">        Key word arguments to ``sklearn.metrics.pairwise.pairwise_kernels``.</span>
<span class="sd">        A list will specify for each view separately.</span>

<span class="sd">    regs : float, None, or list, optional (default None)</span>
<span class="sd">        None equates to 0. Floats are nonnegative. The value is used to</span>
<span class="sd">        regularize singular values in each view based on `diag_mode`</span>
<span class="sd">        A list will specify the method for each view separately.</span>

<span class="sd">    signal_ranks : int, None, or list, optional (default None)</span>
<span class="sd">        Largest SVD rank to compute for each view. If None, the full rank</span>
<span class="sd">        decomposition will be used. A list will specify for each view</span>
<span class="sd">        separately.</span>

<span class="sd">    sval_thresh : float, or list (default 1e-3)</span>
<span class="sd">        For each view we throw out singular values of (1/n)K, the gram matrix</span>
<span class="sd">        scaled by n_samples, below this threshold. A non-zero value deals with</span>
<span class="sd">        singular gram matrices.</span>

<span class="sd">    diag_mode : &#39;A&#39; | &#39;B&#39; | &#39;C&#39; (default &#39;A&#39;)</span>
<span class="sd">        Method of regularizing singular values `s` with regularization</span>
<span class="sd">        parameter `r`</span>

<span class="sd">        - &#39;A&#39; : :math:`(1 - r) * K^2 + r * K` [#1kmcca]_</span>

<span class="sd">        - &#39;B&#39; : :math:`(1-r) (K + n/2 \kappa * I)^2` where</span>
<span class="sd">          :math:`\kappa = r / (1 - r)` [#2kmcca]_</span>

<span class="sd">        - &#39;C&#39; : :math:`(1 - r) K^2 + r * I_n` [#3kmcca]_</span>

<span class="sd">    center : bool, or list (default True)</span>
<span class="sd">        Whether or not to initially mean center the data. A list will</span>
<span class="sd">        specify for each view separately.</span>

<span class="sd">    filter_params : bool (default False)</span>
<span class="sd">        See ``sklearn.metrics.pairwise.pairwise_kernels`` documentation.</span>

<span class="sd">    n_jobs : int, None, optional (default None)</span>
<span class="sd">        Number of jobs to run in parallel when computing kernel matrices.</span>
<span class="sd">        See ``sklearn.metrics.pairwise.pairwise_kernels`` documentation.</span>

<span class="sd">    multiview_output : bool, optional (default True)</span>
<span class="sd">        If True, the ``.transform`` method returns one dataset per view.</span>
<span class="sd">        Otherwise, it returns one dataset, of shape (n_samples, n_components)</span>

<span class="sd">    pgso : bool, optional (default False)</span>
<span class="sd">        If True, computes a partial Gram-Schmidt orthogonalization</span>
<span class="sd">        approximation of the kernel matrices to the given tolerance.</span>

<span class="sd">    tol : float (default 0.1)</span>
<span class="sd">        The minimum matrix trace difference between a kernel matrix and its</span>
<span class="sd">        computed pgso approximation, relative to the kernel trace.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    kernel_col_means_ : list of numpy.ndarray, shape (n_samples,)</span>
<span class="sd">        The column means of each gram matrix</span>

<span class="sd">    kernel_mat_means_ : list</span>
<span class="sd">        The total means of each gram matrix</span>

<span class="sd">    dual_vars_ : numpy.ndarray, shape (n_views, n_samples, n_components)</span>
<span class="sd">        The loadings for the gram matrix of each view</span>

<span class="sd">    common_score_norms_ : numpy.ndarray, shape (n_components,)</span>
<span class="sd">        Column norms of the sum of the view scores.</span>
<span class="sd">        Useful for projecting new data</span>

<span class="sd">    evals_ : numpy.ndarray, shape (n_components,)</span>
<span class="sd">        The generalized eigenvalue problem eigenvalues.</span>

<span class="sd">    Xs_ : list of numpy.ndarray, length (n_views,)</span>
<span class="sd">        - Xs[i] shape (n_samples, n_features_i)</span>
<span class="sd">        The original data matrices for use in kernel matrix computation</span>
<span class="sd">        during calls to ``.transform``.</span>

<span class="sd">    n_views_ : int</span>
<span class="sd">        The number of views</span>

<span class="sd">    n_features_ : list</span>
<span class="sd">        The number of features in each fitted view</span>

<span class="sd">    n_components_ : int</span>
<span class="sd">        The number of components in each transformed view</span>

<span class="sd">    pgso_Ls_ : list of numpy.ndarray, length (n_views,)</span>
<span class="sd">        - pgso_Ls_[i] shape (n_samples, rank_i)</span>
<span class="sd">        The Gram-Schmidt approximations of the kernel matrices</span>

<span class="sd">    pgso_norms_ : list of numpy.ndarray, length (n_views,)</span>
<span class="sd">        - pgso_norms_[i] shape (rank_i,)</span>
<span class="sd">        The maximum norms found during the Gram-Schmidt procedure, descending</span>

<span class="sd">    pgso_idxs_ : list of numpy.ndarray, length (n_views,)</span>
<span class="sd">        - pgso_idxs_[i] shape (rank_i,)</span>
<span class="sd">        The sample indices of the maximum norms</span>

<span class="sd">    pgso_Xs_ : list of numpy.ndarray, length (n_views,)</span>
<span class="sd">        - pgso_Xs_[i] shape (rank_i, n_features)</span>
<span class="sd">        The samples with indices saved in pgso_idxs_, sorted by pgso_norms_</span>

<span class="sd">    pgso_ranks_ : list, length (n_views,)</span>
<span class="sd">        The ranks of the partial Gram-Schmidt results for each view.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Traditional CCA aims to find useful projections of features in each view</span>
<span class="sd">    of data, computing a weighted sum, but may not extract useful descriptors</span>
<span class="sd">    of the data because of its linearity. KMCCA offers an alternative solution</span>
<span class="sd">    by first projecting the data onto a higher dimensional feature space.</span>

<span class="sd">    .. math::</span>
<span class="sd">        \phi: \mathbf{x} = (x_1,...,x_m) \mapsto</span>
<span class="sd">        \phi(\mathbf{x}) = (z_1,...,z_N),</span>
<span class="sd">        (m &lt;&lt; N)</span>

<span class="sd">    before performing CCA in the new feature space.</span>

<span class="sd">    Kernels are effectively distance functions that compute inner products in</span>
<span class="sd">    the higher dimensional feature space, a method known as the kernel trick.</span>
<span class="sd">    A kernel function K, such that for all :math:`\mathbf{x},</span>
<span class="sd">    \mathbf{z} \in X`</span>

<span class="sd">    .. math::</span>
<span class="sd">        K(\mathbf{x}, \mathbf{z}) = \langle\phi(\mathbf{x})</span>
<span class="sd">        \cdot \phi(\mathbf{z})\rangle.</span>

<span class="sd">    The kernel matrix :math:`K_i` has entries computed from the kernel</span>
<span class="sd">    function. Using the kernel trick, loadings of the kernel matrix</span>
<span class="sd">    (dual_vars_) are solved for rather than of the features from :math:`\phi`.</span>

<span class="sd">    Kernel matrices grow exponentially with the size of data. They not only</span>
<span class="sd">    have to store :math:`n^2` elements, but also face the complexity of matrix</span>
<span class="sd">    eigenvalue problems. In a Cholesky decomposition a positive definite</span>
<span class="sd">    matrix K is decomposed to a lower triangular matrix :math:`L` :</span>
<span class="sd">    :math:`K = LL&#39;`.</span>

<span class="sd">    The dual partial Gram-Schmidt orthogonalization (PSGO) is equivalent to the</span>
<span class="sd">    Incomplete Cholesky Decomposition (ICD) which looks for a low rank</span>
<span class="sd">    approximation of :math:`L`, reducing the cost of operations of the matrix</span>
<span class="sd">    such that :math:`\frac{1}{\sum_i K_{ii}} tr(K - LL^T) \leq tol`.</span>

<span class="sd">    A PSGO tolerance yielding rank :math:`m` leads to storage requirements of</span>
<span class="sd">    :math:`O(mn)` instead of :math:`O(n^2)` and becomes :math:`O(nm^2)` instead</span>
<span class="sd">    of :math:`O(n^3)` [#3kmcca]_.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    MCCA</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [#1kmcca] Hardoon D., et al. &quot;Canonical Correlation Analysis: An</span>
<span class="sd">                 Overview with Application to Learning Methods&quot;, Neural</span>
<span class="sd">                 Computation, Volume 16 (12), pp 2639-2664, 2004.</span>
<span class="sd">    .. [#2kmcca] Bach, F. and Jordan, M. &quot;Kernel Independent Component</span>
<span class="sd">                 Analysis.&quot; Journal of Machine Learning Research, 3:1-48, 2002.</span>
<span class="sd">    .. [#3kmcca] Kuss, M. and Graepel, T.. &quot;The Geometry of Kernel Canonical</span>
<span class="sd">                 Correlation Analysis.&quot; MPI Technical Report, 108. (2003).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mvlearn.embed import KMCCA</span>
<span class="sd">    &gt;&gt;&gt; X1 = [[0, 0, 1], [1, 0, 0], [2, 2, 2], [3, 5, 4]]</span>
<span class="sd">    &gt;&gt;&gt; X2 = [[0.1, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]]</span>
<span class="sd">    &gt;&gt;&gt; X3 = [[0, 1, 0], [1, 9, 0], [4, 3, 3,], [12, 8, 10]]</span>
<span class="sd">    &gt;&gt;&gt; kmcca = KMCCA()</span>
<span class="sd">    &gt;&gt;&gt; kmcca.fit([X1, X2, X3])</span>
<span class="sd">    KMCCA()</span>
<span class="sd">    &gt;&gt;&gt; Xs_scores = kmcca.transform([X1, X2, X3])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">kernel_params</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">regs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">signal_ranks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">sval_thresh</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">diag_mode</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">,</span>
        <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">filter_params</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">multiview_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">pgso</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">0.1</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regs</span> <span class="o">=</span> <span class="n">regs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span> <span class="o">=</span> <span class="n">kernel_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signal_ranks</span> <span class="o">=</span> <span class="n">signal_ranks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sval_thresh</span> <span class="o">=</span> <span class="n">sval_thresh</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diag_mode</span> <span class="o">=</span> <span class="n">diag_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filter_params</span> <span class="o">=</span> <span class="n">filter_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiview_output</span> <span class="o">=</span> <span class="n">multiview_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pgso</span> <span class="o">=</span> <span class="n">pgso</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper method for `.fit` function&quot;&quot;&quot;</span>
        <span class="n">Xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_views_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">=</span> <span class="n">check_Xs</span><span class="p">(</span>
            <span class="n">Xs</span><span class="p">,</span> <span class="n">multiview</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_dimensions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">centers</span> <span class="o">=</span> <span class="n">param_as_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_views_</span><span class="p">)</span>

        <span class="c1"># set up (centered) kernels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_col_means_</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_views_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_mat_means_</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_views_</span>

        <span class="n">Ks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgso</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pgso_Ls_</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pgso_norms_</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pgso_idxs_</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pgso_Xs_</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pgso_ranks_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Xs_</span> <span class="o">=</span> <span class="n">Xs</span>  <span class="c1"># stored for `transform` step</span>

        <span class="k">for</span> <span class="n">view</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_views_</span><span class="p">):</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_kernel</span><span class="p">(</span><span class="n">Xs</span><span class="p">[</span><span class="n">view</span><span class="p">],</span> <span class="n">view</span><span class="o">=</span><span class="n">view</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgso</span><span class="p">:</span>
                <span class="n">L</span><span class="p">,</span> <span class="n">maxs</span><span class="p">,</span> <span class="n">idxs</span> <span class="o">=</span> <span class="n">_pgso_decomp</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pgso_Ls_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pgso_norms_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">maxs</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pgso_idxs_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pgso_Xs_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Xs</span><span class="p">[</span><span class="n">view</span><span class="p">][</span><span class="n">idxs</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pgso_ranks_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">maxs</span><span class="p">))</span>
                <span class="n">K</span> <span class="o">=</span> <span class="n">L</span> <span class="o">@</span> <span class="n">L</span><span class="o">.</span><span class="n">T</span>
                <span class="k">del</span> <span class="n">L</span>
            <span class="k">if</span> <span class="n">centers</span><span class="p">[</span><span class="n">view</span><span class="p">]:</span>
                <span class="n">K</span><span class="p">,</span> <span class="n">col_mean</span><span class="p">,</span> <span class="n">mat_mean</span> <span class="o">=</span> <span class="n">_center_kernel</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">kernel_col_means_</span><span class="p">[</span><span class="n">view</span><span class="p">]</span> <span class="o">=</span> <span class="n">col_mean</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">kernel_mat_means_</span><span class="p">[</span><span class="n">view</span><span class="p">]</span> <span class="o">=</span> <span class="n">mat_mean</span>
            <span class="n">Ks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dual_vars_</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">common_scores_normed</span><span class="p">,</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">common_score_norms_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evals_</span> <span class="o">=</span> <span class="n">_kmcca_gevp</span><span class="p">(</span>
                <span class="n">Ks</span><span class="p">,</span>
                <span class="n">signal_ranks</span><span class="o">=</span><span class="n">param_as_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signal_ranks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_views_</span><span class="p">),</span>
                <span class="n">sval_thresh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sval_thresh</span><span class="p">,</span>
                <span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span>
                <span class="n">regs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regs</span><span class="p">,</span>
                <span class="n">diag_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">diag_mode</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">common_scores_normed</span>

    <span class="k">def</span> <span class="nf">transform_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">view</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform a view, projecting it using fitted loadings.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray, shape (n_samples, n_features)</span>
<span class="sd">            The view to transform</span>

<span class="sd">        view : int</span>
<span class="sd">            The numeric index of the single view X with respect to the fitted</span>
<span class="sd">            views.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_scores : numpy.ndarray, shape (n_samples, n_components)</span>
<span class="sd">            Transformed view</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgso</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">view</span><span class="o">=</span><span class="n">view</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pgso_Xs_</span><span class="p">[</span><span class="n">view</span><span class="p">])</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">_pgso_construct</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgso_Ls_</span><span class="p">[</span><span class="n">view</span><span class="p">],</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">pgso_idxs_</span><span class="p">[</span><span class="n">view</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgso_norms_</span><span class="p">[</span><span class="n">view</span><span class="p">])</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">L</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgso_Ls_</span><span class="p">[</span><span class="n">view</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">view</span><span class="o">=</span><span class="n">view</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Xs_</span><span class="p">[</span><span class="n">view</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_col_means_</span><span class="p">[</span><span class="n">view</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">row_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">/</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">K</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_col_means_</span><span class="p">[</span><span class="n">view</span><span class="p">]</span>
            <span class="n">K</span> <span class="o">-=</span> <span class="n">row_means</span>
            <span class="n">K</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_mat_means_</span><span class="p">[</span><span class="n">view</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual_vars_</span><span class="p">[</span><span class="n">view</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_get_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">view</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a gram (kernel) matrix between a set of observations and</span>
<span class="sd">        itself or a second set of observations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray, shape (n, d)</span>
<span class="sd">            The data matrix</span>

<span class="sd">        view : int</span>
<span class="sd">            The view index, for the kernel parameter selection</span>

<span class="sd">        Y : numpy.ndarray, shape (m, d), optional (default None)</span>
<span class="sd">            Second data matrix</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : numpy.ndarray, shape (n, n) or (n, m) if Y provided</span>
<span class="sd">            The kernel matrix with entries from the kernel function</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">[</span><span class="n">view</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">kernel_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span><span class="p">[</span><span class="n">view</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kernel_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_params</span>

        <span class="k">return</span> <span class="n">pairwise_kernels</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">filter_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_params</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="o">**</span><span class="n">kernel_params</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_components_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;dual_vars_&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual_vars_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted properly yet&quot;</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_pgso_decomp</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs the partial Gram-Schmidt orthogonalization procedure</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        K : numpy.ndarray, shape (n_samples, n_samples)</span>
<span class="sd">            The kernel matrix to approximate</span>

<span class="sd">        tol : float, optional (default 0.1)</span>
<span class="sd">            The tolerance of the kernel matrix approximation</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">        L : numpy.ndarray, shape (n_samples, r)</span>
<span class="sd">            The lower triangular approximation matrix</span>

<span class="sd">        maxs : numpy.ndarray, shape (r,)</span>
<span class="sd">            The maximum diagonal element of K during Gram-Schmidt iterations</span>

<span class="sd">        indices : numpy.ndarray, shape (r,)</span>
<span class="sd">            The sample indices of each of the values in `maxs`.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The procedure iteratively constructs a lower triangular matrix L and</span>
<span class="sd">    stops when the approximation L gives is below the tolerance, i.e.</span>

<span class="sd">        ..math::</span>
<span class="sd">            \frac{1}{\sum_i K_{ii}} tr(K - LL^T) \leq tol</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">norm2</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">norm2_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">max_sizes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">max_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">M</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">max_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
        <span class="n">max_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">max_idx</span><span class="p">)</span>
        <span class="n">max_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm2</span><span class="p">[</span><span class="n">max_idx</span><span class="p">]))</span>
        <span class="n">L</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">K</span><span class="p">[:,</span> <span class="n">max_idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">L</span><span class="p">[:,</span> <span class="p">:</span><span class="n">j</span><span class="p">]</span> <span class="o">@</span> <span class="n">L</span><span class="p">[</span><span class="n">max_idx</span><span class="p">,</span> <span class="p">:</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
            <span class="p">)</span> <span class="o">/</span> <span class="n">max_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">norm2</span> <span class="o">-=</span> <span class="n">L</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span>
        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span> <span class="o">/</span> <span class="n">norm2_sum</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">L</span><span class="p">[:,</span> <span class="p">:</span><span class="n">M</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">max_sizes</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">max_indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_pgso_construct</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">maxs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs features for samples from a partial Gram-Schmidt</span>
<span class="sd">    orthogonalization on different samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        K : numpy.ndarray, shape (n_new_samples, n_new_samples)</span>
<span class="sd">            The kernel matrix of new samples to approximate</span>

<span class="sd">        L : numpy.ndarray, shape (n_samples, r)</span>
<span class="sd">            Lower triangular Gram-Schmidt decomposition of a kernel matrix</span>

<span class="sd">        indices : numpy.ndarray, shape (n_features,)</span>
<span class="sd">            The sample indices of the maximums</span>

<span class="sd">        maxs : numpy.ndarray, shape (n_features,)</span>
<span class="sd">            The maximum diagonal elements during construction of L</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">        L_oos : numpy.ndarray, shape (n_samples, r)</span>
<span class="sd">            The lower triangular approximation matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">L_oos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">L_oos</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">K</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">L_oos</span><span class="p">[:,</span> <span class="p">:</span><span class="n">j</span><span class="p">]</span> <span class="o">@</span> <span class="n">L</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="p">:</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">maxs</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">L_oos</span>


<span class="k">def</span> <span class="nf">_kmcca_gevp</span><span class="p">(</span>
    <span class="n">Ks</span><span class="p">,</span>
    <span class="n">signal_ranks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_components</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">regs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sval_thresh</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">diag_mode</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes kernel MCCA using the eigenvector formulation where we compute</span>
<span class="sd">    matrix square roots via SVDs. By throwing out zero singular values of</span>
<span class="sd">    the kernel views we can avoid singularity issues.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    Ks : list of numpy.ndarray, length (n_views,)</span>
<span class="sd">        - Ks[i] shape (n_samples, n_samples)</span>
<span class="sd">        List of kernel matrices</span>

<span class="sd">    n_components : int, None</span>
<span class="sd">        Number of components to compute. If None, will use the number of</span>
<span class="sd">        features.</span>

<span class="sd">    regs : float, None, or list</span>
<span class="sd">        None equates to 0. Floats are nonnegative. The value is used to</span>
<span class="sd">        regularize singular values in each view based on `diag_mode`</span>
<span class="sd">        A list will specify the method for each view separately.</span>

<span class="sd">    signal_ranks : int, None, or list</span>
<span class="sd">        Largest SVD rank to compute for each view. If None, the full rank</span>
<span class="sd">        decomposition will be used. A list will specify for each view</span>
<span class="sd">        separately.</span>

<span class="sd">    sval_thresh : float, (default 1e-3)</span>
<span class="sd">        For each view we throw out singular values of (1/n)K, the gram matrix</span>
<span class="sd">        scaled by n_samples, below this threshold. A non-zero value deals with</span>
<span class="sd">        singular gram matrices.</span>

<span class="sd">    diag_mode : &#39;A&#39; | &#39;B&#39; | &#39;C&#39; (default &#39;A&#39;)</span>
<span class="sd">        Method of regularizing singular values `s` with regularization</span>
<span class="sd">        parameter `r`</span>

<span class="sd">        - &#39;A&#39; : (1 - r) * K^2 + r * K [#1kmcca]_</span>

<span class="sd">        - &#39;B&#39; : (1-r) (K + n/2 kappa * I)^2 where kappa = r / (1 - r)</span>
<span class="sd">          [#2kmcca]_</span>

<span class="sd">        - &#39;C&#39; : (1 - r) K^2 + r * I [#3kmcca]_</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dual_vars : numpy.ndarray, shape (n_views, n_samples, n_components)</span>
<span class="sd">        The loadings for each view used to project new data,</span>
<span class="sd">        each of shape (n_features_b, n_components).</span>

<span class="sd">    scores : numpy.ndarray, shape (n_views, n_samples, n_components)</span>
<span class="sd">        Projections of each data view.</span>

<span class="sd">    common_scores_normed : numpy.ndarray, shape (n_samples, n_components)</span>
<span class="sd">        Normalized sum of the view scores.</span>

<span class="sd">    common_norms : numpy.ndarray, shape (n_components,)</span>
<span class="sd">        Column norms of the sum of the view scores.</span>
<span class="sd">        Useful for projecting new data</span>

<span class="sd">    gevals : numpy.ndarray, shape (n_components,)</span>
<span class="sd">        The generalized eigenvalue problem eigenvalues.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">sval_thresh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># put sval_thresh on the scale of svals K.</span>
        <span class="n">sval_thresh</span> <span class="o">*=</span> <span class="n">Ks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">Us</span><span class="p">,</span> <span class="n">svds</span> <span class="o">=</span> <span class="n">_initial_svds</span><span class="p">(</span><span class="n">Ks</span><span class="p">,</span>
                             <span class="n">signal_ranks</span><span class="o">=</span><span class="n">signal_ranks</span><span class="p">,</span>
                             <span class="n">normalized_scores</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                             <span class="n">sval_thresh</span><span class="o">=</span><span class="n">sval_thresh</span><span class="p">)</span>
    <span class="n">svals</span> <span class="o">=</span> <span class="p">[</span><span class="n">svd</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">svd</span> <span class="ow">in</span> <span class="n">svds</span><span class="p">]</span>

    <span class="n">Us</span><span class="p">,</span> <span class="n">n_views</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features_reduced</span> <span class="o">=</span> <span class="n">check_Xs</span><span class="p">(</span>
        <span class="n">Us</span><span class="p">,</span> <span class="n">return_dimensions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">regs</span> <span class="o">=</span> <span class="n">_check_regs</span><span class="p">(</span><span class="n">regs</span><span class="o">=</span><span class="n">regs</span><span class="p">,</span> <span class="n">n_views</span><span class="o">=</span><span class="n">n_views</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_components</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_features_reduced</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_components</span> <span class="o">&gt;</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_features_reduced</span><span class="p">):</span>
        <span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Requested too many components!&quot;</span><span class="p">)</span>
    <span class="n">n_components</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_features_reduced</span><span class="p">))</span>

    <span class="c1"># get singular values of transformed view gram matrices</span>
    <span class="n">reg_svals</span> <span class="o">=</span> <span class="n">_regularize_svals</span><span class="p">(</span>
        <span class="n">svals</span><span class="o">=</span><span class="n">svals</span><span class="p">,</span> <span class="n">regs</span><span class="o">=</span><span class="n">regs</span><span class="p">,</span> <span class="n">diag_mode</span><span class="o">=</span><span class="n">diag_mode</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span>
    <span class="p">)</span>

    <span class="c1"># constructe matrix for eigen decomposition</span>
    <span class="n">C</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">)]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">):</span>
        <span class="n">C</span><span class="p">[</span><span class="n">b</span><span class="p">][</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_features_reduced</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>

    <span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">),</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">U_a</span> <span class="o">=</span> <span class="n">Us</span><span class="p">[</span><span class="n">a</span><span class="p">]</span>
        <span class="n">s_a</span> <span class="o">=</span> <span class="n">svals</span><span class="p">[</span><span class="n">a</span><span class="p">]</span>
        <span class="n">t_a</span> <span class="o">=</span> <span class="n">reg_svals</span><span class="p">[</span><span class="n">a</span><span class="p">]</span>
        <span class="n">q_a</span> <span class="o">=</span> <span class="n">s_a</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">t_a</span><span class="p">))</span>

        <span class="n">U_b</span> <span class="o">=</span> <span class="n">Us</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
        <span class="n">s_b</span> <span class="o">=</span> <span class="n">svals</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
        <span class="n">t_b</span> <span class="o">=</span> <span class="n">reg_svals</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
        <span class="n">q_b</span> <span class="o">=</span> <span class="n">s_b</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">t_b</span><span class="p">))</span>

        <span class="n">C</span><span class="p">[</span><span class="n">a</span><span class="p">][</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">U_a</span> <span class="o">*</span> <span class="n">q_a</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">U_b</span> <span class="o">*</span> <span class="n">q_b</span><span class="p">)</span>
        <span class="n">C</span><span class="p">[</span><span class="n">b</span><span class="p">][</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">a</span><span class="p">][</span><span class="n">b</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

    <span class="n">gevals</span><span class="p">,</span> <span class="n">gevecs</span> <span class="o">=</span> <span class="n">eigh_wrapper</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
    <span class="n">gevecs</span> <span class="o">=</span> <span class="p">[</span><span class="n">gevec</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">gevec</span> <span class="ow">in</span> <span class="n">SimpleSplitter</span><span class="p">(</span>
        <span class="n">n_features_reduced</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">gevecs</span><span class="o">.</span><span class="n">T</span><span class="p">)]</span>

    <span class="n">dual_vars</span> <span class="o">=</span> <span class="p">[(</span><span class="n">Us</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">reg_svals</span><span class="p">[</span><span class="n">b</span><span class="p">]))</span> <span class="o">@</span> <span class="n">gevecs</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
                 <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">)]</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">Ks</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">@</span> <span class="n">dual_vars</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">)]</span>
    <span class="n">common_scores</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">common_norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">common_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">common_scores_normed</span> <span class="o">=</span> <span class="n">common_scores</span> <span class="o">/</span> <span class="n">common_norms</span>

    <span class="c1"># enforce deterministic output due to possible sign flips</span>
    <span class="n">common_scores_normed</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">dual_vars</span> <span class="o">=</span> <span class="n">_deterministic_decomp</span><span class="p">(</span>
        <span class="n">common_scores_normed</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">dual_vars</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">dual_vars</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">common_scores_normed</span><span class="p">,</span> \
        <span class="n">common_norms</span><span class="p">,</span> <span class="n">gevals</span>


<span class="k">def</span> <span class="nf">_regularize_svals</span><span class="p">(</span><span class="n">svals</span><span class="p">,</span> <span class="n">regs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">diag_mode</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">,</span>
                      <span class="n">n_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Regularizes singular values for various mode options.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    svals : list of numpy.ndarray</span>
<span class="sd">        Singular values of each kernel matrix.</span>

<span class="sd">    regs : None, float, or list</span>
<span class="sd">        Regularization parameter for each view.</span>

<span class="sd">    diag_mode : &#39;A&#39; | &#39;B&#39; | &#39;C&#39;</span>
<span class="sd">        Method of regularizing singular values `s` with regularization</span>
<span class="sd">        parameter `r`</span>

<span class="sd">    n_samples : None, int</span>
<span class="sd">        Number of samples. Needed for mode B.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    reg_svals : list of array-like</span>
<span class="sd">        Regularized singular values for each view and given diag_mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_views</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">svals</span><span class="p">)</span>

    <span class="n">reg_svals</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_views</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">svals</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">regs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">regs</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">r</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">s</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">elif</span> <span class="n">diag_mode</span> <span class="o">==</span> <span class="s2">&quot;A&quot;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="n">s</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">r</span> <span class="o">*</span> <span class="n">s</span>
        <span class="k">elif</span> <span class="n">diag_mode</span> <span class="o">==</span> <span class="s2">&quot;B&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">n_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">s</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kappa</span> <span class="o">=</span> <span class="n">r</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="p">)</span>
                <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">kappa</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">elif</span> <span class="n">diag_mode</span> <span class="o">==</span> <span class="s2">&quot;C&quot;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="n">s</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">r</span>

        <span class="n">reg_svals</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span>

    <span class="k">return</span> <span class="n">reg_svals</span>


<span class="k">def</span> <span class="nf">_center_kernel</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Centers a kernel matrix data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    K : np.ndarray, shape (n,n)</span>
<span class="sd">        A kernel matrix</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    K_c : numpy.ndarray, shape (n,n)</span>
<span class="sd">        The centered kernel matrix</span>

<span class="sd">    col_mean : numpy.ndarray, shape (n,)</span>
<span class="sd">        Mean of each kernel matrix column</span>

<span class="sd">    mat_mean : float</span>
<span class="sd">        Mean of entire kernel matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">col_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">mat_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">col_mean</span><span class="p">)</span>
    <span class="n">K_c</span> <span class="o">=</span> <span class="n">K</span> <span class="o">-</span> <span class="n">col_mean</span> <span class="o">-</span> <span class="n">col_mean</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">+</span> <span class="n">mat_mean</span>

    <span class="k">return</span> <span class="n">K_c</span><span class="p">,</span> <span class="n">col_mean</span><span class="p">,</span> <span class="n">mat_mean</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2020.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
<p style="text-align: center; margin: .5rem;">
    <a href="https://www.netlify.com">
        <img src="https://www.netlify.com/img/global/badges/netlify-color-accent.svg" />
    </a>
</p>
 


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>