

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Semi-Supervised &mdash; mvlearn alpha documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Selection" href="model_selection.html" />
    <link rel="prev" title="Clustering" href="cluster.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/mvlearn-logo-transparent-white.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.4.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Using mvlearn</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing-the-released-version-with-pip">Installing the released version with pip</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install.html#including-optional-dependencies-for-full-functionality">Including optional dependencies for full functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing-the-released-version-with-conda-forge">Installing the released version with conda-forge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#python-package-dependencies">Python package dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#hardware-requirements">Hardware requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#os-requirements">OS Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-cluster">Examples on cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_coregularized_spectral_tutorial.html">Multiview Coregularized Spectral Clustering Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spherical_kmeans_tutorial.html">Multiview Spherical KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_tutorial.html">Multiview KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_validation_simulated.html">Multiview vs. Singleview KMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_tutorial.html">Multiview Spectral Clustering Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_validation_simulated.html">Multiview vs. Singleview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_vs_singleview_spectral.html">Multiview vs. Singleview Spectral Clustering of UCI Multiview Digits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_validation_complex.html">Conditional Independence of Views on Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_validation_complex.html">Conditional Independence of Views on Multiview KMeans Clustering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-compose">Examples on compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/compose/plot_multiview_construction.html">Constructing multiple views to classify singleview data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/compose/plot_pipeline_sklearn_integration.html">Integrating mvlearn with scikit-learn</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-datasets">Examples on datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_load_ucimultifeature.html">Loading and Viewing the UCI Multiple Features Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_gaussianmixtures.html">Generating Multiview Data from Gaussian Mixtures</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-decomposition">Examples on decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_group_ica_tutorial.html">ICA: a tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_mv_ica_tutorial.html">Multiview Independent Component Analysis (ICA) Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_ajive_tutorial.html">Angle-based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-embed">Examples on embed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_gcca_tutorial.html">Generalized Canonical Correlation Analysis (GCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_mcca_tutorial.html">CCA Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_dcca_tutorial.html">Deep CCA (DCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_omnibus_embedding.html">Omnbius Graph Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_kmcca_pgso_tutorial.html">Partial Gram-Schmidt Orthogonalization (PGSO) for KMCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_mvmds_tutorial.html">Multidimensional Scaling (MVMDS) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_cca_comparison.html">Comparing CCA Variants</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_kmcca_tutorial.html">Kernel MCCA (KMCCA) Tutorial</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-plotting">Examples on plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plotting/plot_quick_visualize_tutorial.html">Quickly Visualizing Multiview Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plotting/plot_crossviews_plot.html">Plotting Multiview Data with a Cross-view Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-semi-supervised">Examples on semi_supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/semi_supervised/plot_cotraining_regression.html">2-View Semi-Supervised Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/semi_supervised/plot_cotraining_classification.html">2-View Semi-Supervised Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="embed.html">Embedding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="embed.html#canonical-correlation-analysis-cca">Canonical Correlation Analysis (CCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#multiview-canonical-correlation-analysis-mcca">Multiview Canonical Correlation Analysis (MCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#kernel-mcca">Kernel MCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#generalized-canonical-correlation-analysis-gcca">Generalized Canonical Correlation Analysis (GCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#deep-canonical-correlation-analysis-dcca">Deep Canonical Correlation Analysis (DCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#omnibus-embedding">Omnibus Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#multiview-multidimensional-scaling">Multiview Multidimensional Scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#split-autoencoder">Split Autoencoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#dcca-utilities">DCCA Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#dimension-selection">Dimension Selection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">Decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#multiview-ica">Multiview ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#group-ica">Group ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#group-pca">Group PCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#angle-based-joint-and-individual-variation-explained-ajive">Angle-Based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cluster.html">Clustering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cluster.html#multiview-spectral-clustering">Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="cluster.html#co-regularized-multiview-spectral-clustering">Co-Regularized Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="cluster.html#multiview-k-means">Multiview K Means</a></li>
<li class="toctree-l3"><a class="reference internal" href="cluster.html#multiview-spherical-k-means">Multiview Spherical K Means</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Semi-Supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cotraining-classifier">Cotraining Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cotraining-regressor">Cotraining Regressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_selection.html">Model Selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_selection.html#cross-validation">Cross Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_selection.html#train-test-split">Train-Test Split</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compose.html">Compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compose.html#averagemerger">AverageMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#concatmerger">ConcatMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#randomgaussianprojection">RandomGaussianProjection</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#randomsubspacemethod">RandomSubspaceMethod</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#simplesplitter">SimpleSplitter</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#viewclassifier">ViewClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#viewtransformer">ViewTransformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets.html">Multiview Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#uci-multiple-feature-dataset-located-here">UCI multiple feature dataset (located here)</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#data-simulator">Data Simulator</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#factor-model">Factor Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plotting.html">Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plotting.html#quick-visualize">Quick Visualize</a></li>
<li class="toctree-l3"><a class="reference internal" href="plotting.html#crossviews-plot">Crossviews Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">Utility Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="utils.html#io">IO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Developer Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to mvlearn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-a-bug-report-or-a-feature-request">Submitting a bug report or a feature request</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#how-to-make-a-good-bug-report">How to make a good bug report</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#contributing-code">Contributing Code</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#pull-request-checklist">Pull Request Checklist</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#guidelines">Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#coding-guidelines">Coding Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#docstring-guidelines">Docstring Guidelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#api-of-mvlearn-objects">API of mvlearn Objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#estimators">Estimators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#additional-functionality">Additional Functionality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-4-1">Version 0.4.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-4-0">Version 0.4.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id2">mvlearn.compose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id10">mvlearn.construct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id12">mvlearn.decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id14">mvlearn.embed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id18">mvlearn.model_selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id21">mvlearn.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-3-0">Version 0.3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#patch-0-2-1">Patch 0.2.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-2-0">Version 0.2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-1-0">Version 0.1.0</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Useful Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn">mvlearn &#64; GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/mvlearn/">mvlearn &#64; PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn/issues">Issue Tracker</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">mvlearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Reference</a> &raquo;</li>
        
      <li>Semi-Supervised</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/mvlearn/mvlearn/blob/main/docs/references/semi_supervised.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="semi-supervised">
<h1>Semi-Supervised<a class="headerlink" href="#semi-supervised" title="Permalink to this headline">¶</a></h1>
<div class="section" id="cotraining-classifier">
<h2>Cotraining Classifier<a class="headerlink" href="#cotraining-classifier" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mvlearn.semi_supervised.CTClassifier">
<em class="property">class </em><code class="descclassname">mvlearn.semi_supervised.</code><code class="descname">CTClassifier</code><span class="sig-paren">(</span><em>estimator1=None</em>, <em>estimator2=None</em>, <em>p=None</em>, <em>n=None</em>, <em>unlabeled_pool_size=75</em>, <em>num_iter=50</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/semi_supervised/ctclassifier.html#CTClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements the co-training classifier for supervised and
semi-supervised learning with the framework as described in <a class="footnote-reference" href="#ctc" id="id1">[1]</a>.
The best use case is when the 2 views of input data are sufficiently
distinct and independent as detailed in <a class="footnote-reference" href="#ctc" id="id2">[1]</a>. However, this can
also be successful when a single matrix of input data is given as
both views and two estimators are chosen which are quite different.
<a class="footnote-reference" href="#id4" id="id3">[2]</a>. See the examples below.</p>
<p>In the semi-supervised case, performance can vary greatly, so using
a separate validation set or cross validation procedure is
recommended to ensure the classifier has fit well.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>estimator1</strong> (<em>classifier object</em><em>, </em><em>(</em><em>default=sklearn GaussianNB</em><em>)</em>) -- The classifier object which will be trained on view 1 of the data.
This classifier should support the predict_proba() function so that
classification probabilities can be computed and co-training can be
performed effectively.</li>
<li><strong>estimator2</strong> (<em>classifier object</em><em>, </em><em>(</em><em>default=sklearn GaussianNB</em><em>)</em>) -- The classifier object which will be trained on view 2 of the data.
Does not need to be of the same type as <code class="docutils literal notranslate"><span class="pre">estimator1</span></code>, but should
support predict_proba().</li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) -- The number of positive classifications from the unlabeled_pool
training set which will be given a positive &quot;label&quot;. If None, the
default is the floor of the ratio of positive to negative examples
in the labeled training data (at least 1). If only one of <code class="docutils literal notranslate"><span class="pre">p</span></code> or
<code class="docutils literal notranslate"><span class="pre">n</span></code> is not None, the other will be set to be the same. When the
labels are 0 or 1, positive is defined as 1, and in general, positive
is the larger label.</li>
<li><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) -- The number of negative classifications from the unlabeled_pool
training set which will be given a negative &quot;label&quot;. If None, the
default is the floor of the ratio of positive to negative examples
in the labeled training data (at least 1). If only one of <code class="docutils literal notranslate"><span class="pre">p</span></code> or
<code class="docutils literal notranslate"><span class="pre">n</span></code> is not None, the other will be set to be the same. When the
labels are 0 or 1, negative is defined as 0, and in general, negative
is the smaller label.</li>
<li><strong>unlabeled_pool_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=75</em><em>)</em>) -- The number of unlabeled_pool samples which will be kept in a
separate pool for classification and selection by the updated
classifier at each training iteration.</li>
<li><strong>num_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=50</em><em>)</em>) -- The maximum number of training iterations to run.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> (</em><em>default=None</em><em>)</em>) -- The starting random seed for fit() and class operations, passed to
numpy.random.seed().</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTClassifier.estimator1_">
<code class="descname">estimator1_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.estimator1_" title="Permalink to this definition">¶</a></dt>
<dd><p>The classifier used on view 1.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">classifier object</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTClassifier.estimator2_">
<code class="descname">estimator2_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.estimator2_" title="Permalink to this definition">¶</a></dt>
<dd><p>The classifier used on view 2.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">classifier object</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTClassifier.class_name_">
<code class="descname">class_name_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.class_name_" title="Permalink to this definition">¶</a></dt>
<dd><p>The name of the class.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">string</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTClassifier.p_">
<code class="descname">p_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.p_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of positive classifications from the unlabeled_pool
training set which will be given a positive &quot;label&quot; each round.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a>, optional (default=None)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTClassifier.n_">
<code class="descname">n_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.n_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of negative classifications from the unlabeled_pool
training set which will be given a negative &quot;label&quot; each round.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a>, optional (default=None)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTClassifier.classes_">
<code class="descname">classes_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p>Unique class labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like of shape (n_classes,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Supervised learning of single-view data with 2 distinct estimators</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.semi_supervised</span> <span class="kn">import</span> <span class="n">CTClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Only using the first view</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X1_train</span><span class="p">,</span> <span class="n">X1_test</span><span class="p">,</span> <span class="n">l_train</span><span class="p">,</span> <span class="n">l_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Supervised learning with a single view of data and 2 estimator types</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator1</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ctc</span> <span class="o">=</span> <span class="n">CTClassifier</span><span class="p">(</span><span class="n">estimator1</span><span class="p">,</span> <span class="n">estimator2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use the same matrix for each view</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ctc</span> <span class="o">=</span> <span class="n">ctc</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">X1_train</span><span class="p">],</span> <span class="n">l_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">preds</span> <span class="o">=</span> <span class="n">ctc</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X1_test</span><span class="p">,</span> <span class="n">X1_test</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">preds</span><span class="o">==</span><span class="n">l_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
<span class="go">Accuracy:  0.97</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Multi-view co-training is most helpful for tasks in semi-supervised
learning where each view offers unique information not seen in the
other. As is shown in the example notebooks for using this algorithm,
multi-view co-training can provide good classification results even
when number of unlabeled samples far exceeds the number of labeled
samples. This classifier uses 2 classifiers which work individually
on each view but which share information and thus result in improved
performance over looking at the views completely separately or even
when concatenating the views to get more features in a single-view
setting. The classifier can be initialized with or without the
classifiers desired for each view being specified, but if the
classifier for a certain view is specified, then it must support a
predict_proba() method in order to give a sense of the most likely labels
for different examples. This is because the algorithm must be able to
determine which of the training samples it is most confident about during
training epochs. The algorithm, as first proposed by Blum and Mitchell,
is described in detail below.</p>
<p><em>Algorithm</em></p>
<p>Given:</p>
<blockquote>
<div><ul class="simple">
<li>a set <em>L</em> of labeled training samples (with 2 views)</li>
<li>a set <em>U</em> of unlabeled samples (with 2 views)</li>
</ul>
</div></blockquote>
<p>Create a pool <em>U'</em> of examples by choosing <em>u</em> examples at random
from <em>U</em></p>
<p>Loop for <em>k</em> iterations</p>
<blockquote>
<div><ul class="simple">
<li>Use <em>L</em> to train a classifier <em>h1</em> (<code class="docutils literal notranslate"><span class="pre">estimator1</span></code>) that considers
only the view 1 portion of the data (i.e. Xs[0])</li>
<li>Use <em>L</em> to train a classifier <em>h2</em> (<code class="docutils literal notranslate"><span class="pre">estimator2</span></code>) that considers
only the view 2 portion of the data (i.e. Xs[1])</li>
<li>Allow <em>h1</em> to label <em>p</em> (<code class="docutils literal notranslate"><span class="pre">self.p_</span></code>) positive and <em>n</em> (<code class="docutils literal notranslate"><span class="pre">self.n_</span></code>)
negative samples from view 1 of <em>U'</em></li>
<li>Allow <em>h2</em> to label <em>p</em> positive and <em>n</em> negative samples
from view 2 of <em>U'</em></li>
<li>Add these self-labeled samples to <em>L</em></li>
<li>Randomly take 2*p* + 2*n* samples from <em>U</em> to replenish <em>U'</em></li>
</ul>
</div></blockquote>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="ctc" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id2">2</a>)</em> Blum, A., and Mitchell, T. &quot;Combining labeled and unlabeled
data with co-training.&quot; In Proceedings of the Eleventh Annual
Conference on Computational Learning Theory, pages 92–100, 1998.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[2]</a></td><td>Goldman, Sally, and Yan Zhou. &quot;Enhancing supervised
learning with unlabeled data.&quot; In Proceedings of the Eleventh
Annual Conference on Computational Learning Theory, 2000.</td></tr>
</tbody>
</table>
<dl class="method">
<dt id="mvlearn.semi_supervised.CTClassifier.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>Xs</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a co-train estimator to the semi-supervised data and
then predict.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<blockquote>
<div>A list of the different views of data to fit and
then predict.</div></blockquote>
</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) -- Targets of the training data. Unlabeled examples should
have label np.nan.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong> -- Predictions for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.semi_supervised.CTClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>Xs</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/semi_supervised/ctclassifier.html#CTClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the classifier object to the data in Xs, y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of the different views of data to train on.</p>
</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) -- The labels of the training data. Unlabeled examples should
have label np.nan.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">returns an instance of self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.semi_supervised.CTClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/semi_supervised/ctclassifier.html#CTClassifier.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the classes of the examples in the two input views.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- <ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of the different views of data to predict.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>y_pred</strong> -- The predicted class of each input example. If the two classifiers
don't agree, pick the one with the highest predicted probability
from predict_proba().</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array-like (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.semi_supervised.CTClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/semi_supervised/ctclassifier.html#CTClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.semi_supervised.CTClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of each example belonging to a each class.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- <ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of the different views of data to predict.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>y_proba</strong> -- The probability of each sample being in each class.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array-like (n_samples, n_classes)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cotraining-regressor">
<h2>Cotraining Regressor<a class="headerlink" href="#cotraining-regressor" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mvlearn.semi_supervised.CTRegressor">
<em class="property">class </em><code class="descclassname">mvlearn.semi_supervised.</code><code class="descname">CTRegressor</code><span class="sig-paren">(</span><em>estimator1=None</em>, <em>estimator2=None</em>, <em>k_neighbors=5</em>, <em>unlabeled_pool_size=50</em>, <em>num_iter=100</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/semi_supervised/ctregression.html#CTRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements the co-training regression for supervised
and semi supervised learning with the framework as described in <a class="footnote-reference" href="#ctr" id="id5">[3]</a>.
The best use case is when 2 views of input data are sufficiently
distinct and independent as detailed in <a class="footnote-reference" href="#ctr" id="id6">[3]</a>. However this can also
be successfull when a single matrix of input data is given as
both views and two estimators are choosen
which are quite different <a class="footnote-reference" href="#id9" id="id7">[4]</a>.</p>
<p>In the semi-supervised case, performance can vary greatly, so using
a separate validation set or cross validation procedure is
recommended to ensure the regression model has fit well.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>estimator1</strong> (<em>sklearn object</em><em>, </em><em>(</em><em>only supports KNeighborsRegressor</em><em>)</em>) -- The regressor object which will be trained on view1 of the data.</li>
<li><strong>estimator2</strong> (<em>sklearn object</em><em>, </em><em>(</em><em>only supports KNeighborsRegressor</em><em>)</em>) -- The regressir object which will be trained on view2 of the data.</li>
<li><strong>k_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 5</em><em>)</em>) -- The number of neighbors to be considered for determining the mean
squared error.</li>
<li><strong>unlabeled_pool_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 50</em><em>)</em>) -- The number of unlabeled_pool samples which will be kept in a
separate pool for regression and selection by the updated
regressor at each training iteration.</li>
<li><strong>num_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) -- The maximum number of iteration to be performed</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em> (</em><em>default = None</em><em>)</em>) -- The seed for fit() method and other class operations</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTRegressor.estimator1_">
<code class="descname">estimator1_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.estimator1_" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">regressor object, used on view1</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTRegressor.estimator2_">
<code class="descname">estimator2_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.estimator2_" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">regressor object, used on view2</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTRegressor.class_name_">
<code class="descname">class_name_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.class_name_" title="Permalink to this definition">¶</a></dt>
<dd><p>The name of the class.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">string</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTRegressor.k_neighbors_">
<code class="descname">k_neighbors_</code><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.k_neighbors_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of neighbors to be considered for determining
the mean squared error.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTRegressor.unlabeled_pool_size">
<code class="descname">unlabeled_pool_size</code><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.unlabeled_pool_size" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of unlabeled_pool samples which will be kept in a
separate pool for regression and selection by the updated
regressor at each training iteration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTRegressor.num_iter">
<code class="descname">num_iter</code><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.num_iter" title="Permalink to this definition">¶</a></dt>
<dd><p>The maximum number of iterations to be performed</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.semi_supervised.CTRegressor.n_views">
<code class="descname">n_views</code><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.n_views" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of views in the data</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.semi_supervised</span> <span class="kn">import</span> <span class="n">CTRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># X1 and X2 are the 2 views of the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X2</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Converting some of the labeled values to nan</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_train</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">16</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn1</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn2</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ctr</span> <span class="o">=</span> <span class="n">CTRegressor</span><span class="p">(</span><span class="n">knn1</span><span class="p">,</span> <span class="n">knn2</span><span class="p">,</span> <span class="n">k_neighbors</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span>  <span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ctr</span> <span class="o">=</span> <span class="n">ctr</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">ctr</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True value</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="go">True value</span>
<span class="go">[10, 11, 12, 13, 14, 15, 16]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted value</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
<span class="go">Predicted value</span>
<span class="go">[10.75 11.25 11.25 13.25 13.25 14.75 15.25]</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Multi-view co-training is most helpful for tasks in semi-supervised
learning where each view offers unique information not seen in the
other. As is shown in the example notebooks for using this algorithm,
multi-view co-training can provide good regression results even
when number of unlabeled samples far exceeds the number of labeled
samples. This regressor uses 2 sklearn regressors which work individually
on each view but which share information and thus result in improved
performance over looking at the views completely separately.
The regressor needs to be KNeighborsRegressor,
as described in the <a class="footnote-reference" href="#ctr" id="id8">[3]</a>.</p>
<p>Algorithm: Given</p>
<blockquote>
<div><ul class="simple">
<li>a set <em>L1</em>, <em>L2</em> having labeled training</li>
</ul>
<p>samples of each view respectively</p>
<ul class="simple">
<li>a set <em>U</em> of unlabeled samples</li>
</ul>
<p>Create a pool <em>U'</em> of examples by choosing examples at random
from <em>U</em></p>
<ul class="simple">
<li>Use <em>L1</em> to train a regressor <em>h1</em> (<code class="docutils literal notranslate"><span class="pre">estimator1</span></code>) that considers
only the view1 portion of the data (i.e. Xs[0])</li>
<li>Use <em>L2</em> to train a regressor <em>h2</em> (<code class="docutils literal notranslate"><span class="pre">estimator2</span></code>) that considers
only the view2 portion of the data (i.e. Xs[1])</li>
</ul>
<dl class="docutils">
<dt>Loop for <em>T</em> iterations</dt>
<dd><ul class="first">
<li><dl class="first docutils">
<dt>for each view <em>j</em></dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt>for each <em>u</em> in <em>U'</em></dt>
<dd><ul class="first simple">
<li>Calculate the neighbors of <em>u</em></li>
<li>Predict the value of <em>u</em> using <em>hj</em> estimator</li>
<li>create a new estimator <em>hj'</em> with same parameters</li>
</ul>
<p class="last">as that of <em>hj</em> and train it on the data (<em>Lj</em> union <em>u</em>)
* predict the value of neighbors from estimator <em>hj</em>
and calculate the mean squared error with respect to
original values
* predict the value of neighbors from the new
estimator <em>hj'</em> and calculate the mean squared error
with respect to original values
* calculate the difference between the two errors
* store the error in a list named <em>deltaj</em></p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">select the index with maximum positive value from both</p>
</li>
</ul>
<p class="last">the <em>delta1</em> and <em>delta2</em>
* let the indexes selected be <em>index1</em> and <em>index2</em>
* Add the <em>index1</em> to <em>L2</em>
* Add the <em>index2</em> to <em>L1</em>
* Remove the  selected index from <em>U'</em> and replenish
it by taking unlabeled index from <em>U</em>
* Use <em>L1</em> to train the regressor <em>h1</em>
* Use <em>L2</em> to train the regressor <em>h2</em></p>
</dd>
</dl>
</div></blockquote>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="ctr" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td><em>(<a class="fn-backref" href="#id5">1</a>, <a class="fn-backref" href="#id6">2</a>, <a class="fn-backref" href="#id8">3</a>)</em> Zhou, Zhi-Hua and Li, Ming. &quot;Semi-supervised regression with
co-training.&quot; In Proceedings of the 19th International Joint
Conference on Artificial Intelligence, page 908–913, 2005</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id9" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[4]</a></td><td>Goldman, Sally, and Yan Zhou. &quot;Enhancing supervised
learning with unlabeled data.&quot; In Proceedings of the Eleventh
Annual Conference on Computational Learning Theory, 2000.</td></tr>
</tbody>
</table>
<dl class="method">
<dt id="mvlearn.semi_supervised.CTRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>Xs</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/semi_supervised/ctregression.html#CTRegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the regressor object to the data in Xs, y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of the different views of data to train on.</p>
</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) -- The target values of the training data. Unlabeled examples
should have label np.nan.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">returns an instance of self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.semi_supervised.CTRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/semi_supervised/ctregression.html#CTRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the values of the samples in the two input views.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- <ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of the different views of data to predict.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>y_pred</strong> -- The average of the predictions from both estimators is returned</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array-like (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.semi_supervised.CTRegressor.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>Xs</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.semi_supervised.CTRegressor.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a co-train estimator to the semi-supervised data and
then predict.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<blockquote>
<div>A list of the different views of data to fit and
then predict.</div></blockquote>
</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) -- Targets of the training data. Unlabeled examples should
have label np.nan.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong> -- Predictions for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="model_selection.html" class="btn btn-neutral float-right" title="Model Selection" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="cluster.html" class="btn btn-neutral" title="Clustering" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-2020

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
<p style="text-align: center; margin: .5rem;">
    <a href="https://www.netlify.com">
        <img src="https://www.netlify.com/img/global/badges/netlify-color-accent.svg" />
    </a>
</p>
 


</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/js/copybutton.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>