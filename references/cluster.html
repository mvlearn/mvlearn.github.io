<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Clustering &mdash; mvlearn alpha documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/mvlearn-logo-32x32.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/copybutton.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Semi-Supervised" href="semi_supervised.html" />
    <link rel="prev" title="Decomposition" href="decomposition.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/mvlearn-logo-transparent-white.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.4.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Using mvlearn</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview of mvlearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing-the-released-version-with-pip">Installing the released version with pip</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install.html#including-optional-dependencies-for-full-functionality">Including optional dependencies for full functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing-the-released-version-with-conda-forge">Installing the released version with conda-forge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#python-package-dependencies">Python package dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#hardware-requirements">Hardware requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#os-requirements">OS Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-cluster">Examples on cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_coregularized_spectral_tutorial.html">Multiview Coregularized Spectral Clustering Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spherical_kmeans_tutorial.html">Multiview Spherical KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_tutorial.html">Multiview KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_vs_singleview_spectral.html">Multiview vs. Singleview Spectral Clustering of UCI Multiview Digits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_validation_simulated.html">Multiview vs. Singleview KMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_tutorial.html">Multiview Spectral Clustering Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_validation_simulated.html">Multiview vs. Singleview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_validation_complex.html">Conditional Independence of Views on Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_validation_complex.html">Conditional Independence of Views on Multiview KMeans Clustering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-compose">Examples on compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/compose/plot_multiview_construction.html">Constructing multiple views to classify singleview data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/compose/plot_pipeline_sklearn_integration.html">Integrating mvlearn with scikit-learn</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-datasets">Examples on datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_load_ucimultifeature.html">Loading and Viewing the UCI Multiple Features Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_gaussianmixtures.html">Generating Multiview Data from Gaussian Mixtures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_nutrimouse.html">An mvlearn case study: the Nutrimouse dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-decomposition">Examples on decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_group_ica_tutorial.html">ICA: a tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_mv_ica_tutorial.html">Multiview Independent Component Analysis (ICA) Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_ajive_tutorial.html">Angle-based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-embed">Examples on embed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_gcca_tutorial.html">Generalized Canonical Correlation Analysis (GCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_mcca_tutorial.html">CCA Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_dcca_tutorial.html">Deep CCA (DCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_kmcca_pgso_tutorial.html">Partial Gram-Schmidt Orthogonalization (PGSO) for KMCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_mvmds_tutorial.html">Multidimensional Scaling (MVMDS) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_cca_comparison.html">Comparing CCA Variants</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_kmcca_tutorial.html">Kernel MCCA (KMCCA) Tutorial</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-plotting">Examples on plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plotting/plot_quick_visualize_tutorial.html">Quickly Visualizing Multiview Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plotting/plot_crossviews_plot.html">Plotting Multiview Data with a Cross-view Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-semi-supervised">Examples on semi_supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/semi_supervised/plot_cotraining_regression.html">2-View Semi-Supervised Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/semi_supervised/plot_cotraining_classification.html">2-View Semi-Supervised Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="embed.html">Embedding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="embed.html#canonical-correlation-analysis-cca">Canonical Correlation Analysis (CCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#multiview-canonical-correlation-analysis-mcca">Multiview Canonical Correlation Analysis (MCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#kernel-mcca">Kernel MCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#generalized-canonical-correlation-analysis-gcca">Generalized Canonical Correlation Analysis (GCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#deep-canonical-correlation-analysis-dcca">Deep Canonical Correlation Analysis (DCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#multiview-multidimensional-scaling">Multiview Multidimensional Scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#split-autoencoder">Split Autoencoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#dcca-utilities">DCCA Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#dimension-selection">Dimension Selection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">Decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#multiview-ica">Multiview ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#group-ica">Group ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#group-pca">Group PCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#angle-based-joint-and-individual-variation-explained-ajive">Angle-Based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Clustering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multiview-spectral-clustering">Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#co-regularized-multiview-spectral-clustering">Co-Regularized Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiview-k-means">Multiview K Means</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiview-spherical-k-means">Multiview Spherical K Means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised.html">Semi-Supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semi_supervised.html#cotraining-classifier">Cotraining Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="semi_supervised.html#cotraining-regressor">Cotraining Regressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_selection.html">Model Selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_selection.html#cross-validation">Cross Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_selection.html#train-test-split">Train-Test Split</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compose.html">Compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compose.html#averagemerger">AverageMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#concatmerger">ConcatMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#randomgaussianprojection">RandomGaussianProjection</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#randomsubspacemethod">RandomSubspaceMethod</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#simplesplitter">SimpleSplitter</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#viewclassifier">ViewClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#viewtransformer">ViewTransformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets.html">Multiview Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#uci-multiple-feature-dataset">UCI multiple feature dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#nutrimouse-dataset">Nutrimouse dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#data-simulator">Data Simulator</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#factor-model">Factor Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plotting.html">Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plotting.html#quick-visualize">Quick Visualize</a></li>
<li class="toctree-l3"><a class="reference internal" href="plotting.html#crossviews-plot">Crossviews Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">Utility Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="utils.html#io">IO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to mvlearn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-a-bug-report-or-a-feature-request">Submitting a bug report or a feature request</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#how-to-make-a-good-bug-report">How to make a good bug report</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#contributing-code">Contributing Code</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#pull-request-checklist">Pull Request Checklist</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#guidelines">Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#coding-guidelines">Coding Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#docstring-guidelines">Docstring Guidelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#api-of-mvlearn-objects">API of mvlearn Objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#estimators">Estimators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#additional-functionality">Additional Functionality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#unreleased">Unreleased</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-4-1">Version 0.4.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-4-0">Version 0.4.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id4">mvlearn.compose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id12">mvlearn.construct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id14">mvlearn.decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id16">mvlearn.embed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id20">mvlearn.model_selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id23">mvlearn.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-3-0">Version 0.3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#patch-0-2-1">Patch 0.2.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-2-0">Version 0.2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-1-0">Version 0.1.0</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Useful Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn">mvlearn &#64; GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/mvlearn/">mvlearn &#64; PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn/issues">Issue Tracker</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">mvlearn</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Reference</a> &raquo;</li>
      <li>Clustering</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/mvlearn/mvlearn/blob/main/docs/references/cluster.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="clustering">
<h1>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h1>
<section id="multiview-spectral-clustering">
<h2>Multiview Spectral Clustering<a class="headerlink" href="#multiview-spectral-clustering" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewSpectralClustering">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mvlearn.cluster.</span></span><span class="sig-name descname"><span class="pre">MultiviewSpectralClustering</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_view</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affinity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rbf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_spectral.html#MultiviewSpectralClustering"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>An implementation of multi-view spectral clustering.</p>
<p>An implementation of multi-view spectral clustering using the
basic co-training framework as described in <a class="footnote-reference brackets" href="#clu" id="id1">1</a>.
Additionally, this can be effective when the dataset naturally
contains features that are of 2 different data types, such as
continuous features and categorical features <a class="footnote-reference brackets" href="#id8" id="id2">4</a>, and then the
original features are separated into two views in this way.</p>
<p>This algorithm can handle 2 or more views of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) -- The number of clusters</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for k-means.</p></li>
<li><p><strong>info_view</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- The most informative view. Must be between 0 and n_views-1
If given, then the final clustering will be performed on the
designated view alone. Otherwise, the algorithm will concatenate
across all views and cluster on the result.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The maximum number of iterations to run the clustering
algorithm.</p></li>
<li><p><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The number of random initializations to use for k-means clustering.</p></li>
<li><p><strong>affinity</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='rbf'</em>) -- The affinity metric used to construct the affinity matrix. Options
include 'rbf' (radial basis function), 'nearest_neighbors', and
'poly' (polynomial)</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Kernel coefficient for rbf and polynomial kernels. If None then
gamma is computed as 1 / (2 * median(pair_wise_distances(X))^2)
for each data view X.</p></li>
<li><p><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- Only used if nearest neighbors is selected for affinity. The
number of neighbors to use for the nearest neighbors kernel.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewSpectralClustering.labels_">
<span class="sig-name descname"><span class="pre">labels_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each sample in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewSpectralClustering.embedding_">
<span class="sig-name descname"><span class="pre">embedding_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering.embedding_" title="Permalink to this definition">¶</a></dt>
<dd><p>The final spectral representation of the data to be used as input
for the KMeans clustering step.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples, n_clusters)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>Multi-view spectral clustering adapts the spectral clustering algorithm
to applications where more than one view of data is available. This
algorithm relies on the basic assumptions of the co-training, which are:
(a) Sufficiency: each view is sufficient for classification on its own,
(b) Compatibility: the target functions in both views predict the same
labels for co-occurring features with high probability, and (c)
Conditional independence: the views are conditionally independent given
the class labels. In contrast to multi-view k-means clustering,
multi-view spectral clustering performs well on arbitrary shaped clusters,
and can therefore be readily used in applications where clusters are not
expected to be convex. However multi-view spectral clustering tends to be
computationally expensive unless the similarity graph for the data is
sparse.</p>
<p>Multi-view spectral clustering works by using the spectral embedding
from one view to constrain the similarity graph in the other view. By
iteratively applying this procedure, the clustering of the two views
tend to each other. Here we outline the algorithm for the Multi-view
Spectral clustering algorithm for 2 views.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><em>Multi-view Spectral Clustering Algorithm (for 2 views)</em></p>
<p>Input: Similarity matrix for both views: <span class="math notranslate nohighlight">\(\mathbf{K}_1, \mathbf{K}_2\)</span></p>
<p>Output: Assignments to k clusters</p>
<ol class="arabic">
<li><p>Initialize: <span class="math notranslate nohighlight">\(\mathbf{L}_v = \mathbf{D}_v^{-1/2}
\mathbf{K}_v\mathbf{D}_v^{-1/2}\)</span> for <span class="math notranslate nohighlight">\(v = 1, 2\)</span>
<span class="math notranslate nohighlight">\(\mathbf{U}_v^0\)</span> is an <span class="math notranslate nohighlight">\(n \times k\)</span> matrix with the
top k eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{L}_v\)</span> for <span class="math notranslate nohighlight">\(v = 1, 2\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(i = 1\)</span> to iter:</p>
<blockquote>
<div><ol class="loweralpha simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{S}_1 = sym(\mathbf{U}_2^{i-1}
{\mathbf{U}_2^{i-1}}^T\mathbf{K}_1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{S}_2 = sym(\mathbf{U}_1^{i-1}
{\mathbf{U}_1^{i-1}}^T\mathbf{K}_2)\)</span></p></li>
<li><p>Use <span class="math notranslate nohighlight">\(\mathbf{S}_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{S}_2\)</span> as the new
graph similarities and compute the Laplacians. Solve for the
largest k eigenvectors to obtain <span class="math notranslate nohighlight">\(\mathbf{U}_1^i\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{U}_2^i\)</span>.</p></li>
</ol>
</div></blockquote>
</li>
<li><p>Row-normalize <span class="math notranslate nohighlight">\(\mathbf{U}_1^i\)</span> and <span class="math notranslate nohighlight">\(\mathbf{U}_2^i\)</span>.</p></li>
<li><p>Form matrix <span class="math notranslate nohighlight">\(\mathbf{V} = \mathbf{U}_v^i\)</span>, where <span class="math notranslate nohighlight">\(v\)</span> is
believed to be the most informative view a priori. If there is no
prior knowledge on the view informativeness, matrix
<span class="math notranslate nohighlight">\(\mathbf{V}\)</span> can also be set to the column-wise concatenation
of the two <span class="math notranslate nohighlight">\(\mathbf{U}_v^i\)</span> s.</p></li>
<li><p>Assign example j to cluster c if the j-th row of <span class="math notranslate nohighlight">\(\mathbf{V}\)</span>
is assigned to cluster c by the k-means algorithm.</p></li>
</ol>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="clu"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Abhishek Kumar and Hal Daume. &quot;A co-training approach for
multi-view spectral clustering.&quot; In Proceedings of the 28th
International Conference on Machine Learning, page 393–400.
Omnipress, 2011.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewSpectralClustering</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_spectral</span> <span class="o">=</span> <span class="n">MultiviewSpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_spectral</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.872</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="co-regularized-multiview-spectral-clustering">
<h2>Co-Regularized Multiview Spectral Clustering<a class="headerlink" href="#co-regularized-multiview-spectral-clustering" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewCoRegSpectralClustering">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mvlearn.cluster.</span></span><span class="sig-name descname"><span class="pre">MultiviewCoRegSpectralClustering</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_view</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affinity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rbf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_coreg_spectral.html#MultiviewCoRegSpectralClustering"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>An implementation of co-regularized multi-view spectral clustering based on
an unsupervied version of the co-training framework.
This algorithm uses the pairwise co-regularization scheme as described
in <a class="footnote-reference brackets" href="#id4" id="id3">2</a>. This algorithm can handle 2 or more views of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) -- The number of clusters</p></li>
<li><p><strong>v_lambda</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=2</em>) -- The regularization parameter. This parameter trades-off the spectral
clustering objectives with the degree of agreement between each pair
of views in the new representation. Must be a positive value.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for k-means.</p></li>
<li><p><strong>info_view</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- The most informative view. Must be between 0 and n_views-1
If given, then the final clustering will be performed on the
designated view alone. Otherwise, the algorithm will concatenate
across all views and cluster on the result.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The maximum number of iterations to run the clustering
algorithm.</p></li>
<li><p><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The number of random initializations to use for k-means clustering.</p></li>
<li><p><strong>affinity</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='rbf'</em>) -- The affinity metric used to construct the affinity matrix. Options
include 'rbf' (radial basis function), 'nearest_neighbors', and
'poly' (polynomial)</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Kernel coefficient for rbf and polynomial kernels. If None then
gamma is computed as 1 / (2 * median(pair_wise_distances(X))^2)
for each data view X.</p></li>
<li><p><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- Only used if nearest neighbors is selected for affinity. The
number of neighbors to use for the nearest neighbors kernel.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewCoRegSpectralClustering.labels_">
<span class="sig-name descname"><span class="pre">labels_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each point.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewCoRegSpectralClustering.embedding_">
<span class="sig-name descname"><span class="pre">embedding_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.embedding_" title="Permalink to this definition">¶</a></dt>
<dd><p>The final spectral representation of the data to be used as input
for the KMeans clustering step.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples, n_clusters)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewCoRegSpectralClustering.objective_">
<span class="sig-name descname"><span class="pre">objective_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.objective_" title="Permalink to this definition">¶</a></dt>
<dd><p>The value of the spectral clustering objective for each view at
the end of each iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_views, n_iterations)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>In standard spectral clustering, the eigenvector matrix U for a given view
is the new data representation to be used for the subsequent k-means
clustering stage. In this algorithm, the objective function has been
altered to encourage the pairwise similarities of examples under the new
representation to be similar across all views.</p>
<p>The modified spectral clustering objective for the case of two views is
shown and derived in [#4Clu]. In the clustering objective, the
hyperparameter lambda trades-off the spectral clustering objectives and
the disagreement term.</p>
<p>For a fixed lambda and n, the objective function is bounded from above and
non-decreasing. As such, the algorithm is guaranteed to converge.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>Abhishek Kumar, Piyush Rai, and Hal Daume.  Co-regularized
multi-view spectral cluster-ing. In Proceedings of the 24th
International Conference on Neural Information Processing Systems,
page 1413–1421. Curran Associates Inc., 2011.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewCoRegSpectralClustering</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_spectral</span> <span class="o">=</span> <span class="n">MultiviewCoRegSpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_spectral</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">,</span> <span class="n">average_method</span><span class="o">=</span><span class="s1">&#39;arithmetic&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.663</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="multiview-k-means">
<h2>Multiview K Means<a class="headerlink" href="#multiview-k-means" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewKMeans">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mvlearn.cluster.</span></span><span class="sig-name descname"><span class="pre">MultiviewKMeans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'k-means++'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">300</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_kmeans.html#MultiviewKMeans"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements multi-view k-means.</p>
<p>This class implements multi-view k-means using the co-EM framework
as described in <a class="footnote-reference brackets" href="#id7" id="id5">3</a>. This algorithm is most suitable for cases
in which the different views of data are conditionally independent.
Additionally, this can be effective when the dataset naturally
contains features that are of 2 different data types, such as
continuous features and categorical features <a class="footnote-reference brackets" href="#id8" id="id6">4</a>, and then the
original features are separated into two views in this way.</p>
<p>This algorithm currently handles two views of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=2</em>) -- The number of clusters</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for initializing centroids.
Can seed the random number generator with an int.</p></li>
<li><p><strong>init</strong> (<em>{'k-means++'</em><em>, </em><em>'random'}</em><em> or </em><em>list of array-likes</em><em>, </em><em>default='k-means++'</em>) -- <p>Method of initializing centroids.</p>
<p>'k-means++': selects initial cluster centers for k-means clustering
via a method that speeds up convergence.</p>
<p>'random': choose n_cluster samples from the data for the initial
centroids.</p>
<p>If a list of array-likes is passed, the list should have a length of
equal to the number of views. Each of the array-likes should have
the shape (n_clusters, n_features_i) for the ith view, where
n_features_i is the number of features in the ith view of the input
data.</p>
</p></li>
<li><p><strong>patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- The number of EM iterations with no decrease in the objective
function after which the algorithm will terminate.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=300</em>) -- The maximum number of EM iterations to run before
termination.</p></li>
<li><p><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- Number of times the k-means algorithm will run on different
centroid seeds. The final result will be the best output of
n_init runs with respect to total inertia across all views.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>default=1e-4</em>) -- Relative tolerance with regards to inertia to declare convergence.</p></li>
<li><p><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>default=None</em>) -- The number of jobs to use for computation. This works by computing
each of the n_init runs in parallel.
None means 1. -1 means using all processors.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewKMeans.labels_">
<span class="sig-name descname"><span class="pre">labels_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each sample in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewKMeans.centroids_">
<span class="sig-name descname"><span class="pre">centroids_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans.centroids_" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">centroids_</span></code> length: n_views
<code class="docutils literal notranslate"><span class="pre">centroids_[i]</span></code> shape: (n_clusters, n_features_i)</p>
<p>The cluster centroids for each of the two views. <code class="docutils literal notranslate"><span class="pre">centroids_[0]</span></code>
corresponds to the centroids of view 1 and <code class="docutils literal notranslate"><span class="pre">centroids_[1]</span></code>
corresponds to the centroids of view 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of array-likes</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>Multi-view k-means clustering adapts the traditional k-means clustering
algorithm to handle two views of data. This algorithm requires that a
conditional independence assumption between views holds true. In cases
where both views are informative and conditionally independent, multi-view
k-means clustering can outperform its single-view analog run on a
concatenated version of the two views of data. This is quite useful for
applications where you wish to cluster data from two different modalities
or data with features that naturally fall into two different partitions.
Multi-view k-means works by iteratively performing the maximization and
expectation steps of traditional EM in one view, and then using the
computed hidden variables as the input for the maximization step in
the other view. This algorithm, referred to as Co-EM, is described
below.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><em>Co-EM Algorithm</em></p>
<p>Input: Unlabeled data D with 2 views</p>
<ol class="arabic">
<li><p>Initialize <span class="math notranslate nohighlight">\(\Theta_0^{(2)}\)</span>, T, <span class="math notranslate nohighlight">\(t = 0\)</span>.</p></li>
<li><p>E step for view 2: compute expectation for hidden variables given</p></li>
<li><p>Loop until stopping criterion is true:</p>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>For v = 1 ... 2:</p>
<ol class="lowerroman simple">
<li><p><span class="math notranslate nohighlight">\(t = t + 1\)</span></p></li>
<li><p>M step view v: Find model parameters <span class="math notranslate nohighlight">\(\Theta_t^{(v)}\)</span>
that maximize the likelihood for the data given the expected
values for hidden variables of view <span class="math notranslate nohighlight">\(\overline{v}\)</span> of
iteration <span class="math notranslate nohighlight">\(t\)</span> - 1</p></li>
<li><p>E step view <span class="math notranslate nohighlight">\(v\)</span>: compute expectation for hidden
variables given the model parameters <span class="math notranslate nohighlight">\(\Theta_t^{(v)}\)</span></p></li>
</ol>
</li>
</ol>
</div></blockquote>
</li>
<li><p>return combined <span class="math notranslate nohighlight">\(\hat{\Theta} = \Theta_{t-1}^{(1)} \cup
\Theta_t^{(2)}\)</span></p></li>
</ol>
<p>The final assignment of examples to partitions is performed by assigning
each example to the cluster with the largest averaged posterior
probability over both views.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id7"><span class="brackets">3</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id9">2</a>)</span></dt>
<dd><p>Steffen Bickel and Tobias Scheffer. Multi-view clustering. In
Proceedings of the Fourth IEEE International Conference on Data
Mining, page 19–26. IEEE Computer Society, 2004.</p>
</dd>
<dt class="label" id="id8"><span class="brackets">4</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id6">2</a>,<a href="#id10">3</a>)</span></dt>
<dd><p>Guoqing Chao, Shiliang Sun, and J. Bi. A survey on multi-view
clustering.arXiv preprint, arXiv:1712.06246, 2017.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewKMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_kmeans</span> <span class="o">=</span> <span class="n">MultiviewKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.770</span>
</pre></div>
</div>
<p>&quot;&quot;</p>
</dd></dl>

</section>
<section id="multiview-spherical-k-means">
<h2>Multiview Spherical K Means<a class="headerlink" href="#multiview-spherical-k-means" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewSphericalKMeans">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mvlearn.cluster.</span></span><span class="sig-name descname"><span class="pre">MultiviewSphericalKMeans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'k-means++'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_spherical_kmeans.html#MultiviewSphericalKMeans"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans" title="Permalink to this definition">¶</a></dt>
<dd><p>An implementation of multi-view spherical K-Means.</p>
<p>An implementation of multi-view spherical K-Means using the
co-EM framework as described in <a class="footnote-reference brackets" href="#id7" id="id9">3</a>. This algorithm is
most suitable for cases in which the different views of data
are conditionally independent. Additionally, this can be effective
when the dataset naturally contains features that are of 2 different
data types, such as continuous features and categorical features
<a class="footnote-reference brackets" href="#id8" id="id10">4</a>, and then the original features are separated into two
views in this way.</p>
<p>This algorithm currently handles two views of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=2</em>) -- The number of clusters</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for initializing centroids.
Can seed the random number generator with an int.</p></li>
<li><p><strong>init</strong> (<em>{'k-means++'</em><em>, </em><em>'random'}</em><em> or </em><em>list of array-likes</em><em>, </em><em>default='k-means++'</em>) -- <p>Method of initializing centroids.</p>
<p>'k-means++': selects initial cluster centers for k-means clustering
via a method that speeds up convergence.</p>
<p>'random': choose n_cluster samples from the data for the initial
centroids.</p>
<p>If a list of array-likes is passed, the list should have a length of
equal to the number of views. Each of the array-likes should have
the shape (n_clusters, n_features_i) for the ith view, where
n_features_i is the number of features in the ith view of the input
data.</p>
</p></li>
<li><p><strong>patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- The number of EM iterations with no decrease in the objective
function after which the algorithm will terminate.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- The maximum number of EM iterations to run before
termination.</p></li>
<li><p><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- Number of times the k-means algorithm will run on different
centroid seeds. The final result will be the best output of
n_init runs with respect to total inertia across all views.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>default=1e-4</em>) -- Relative tolerance with regards to inertia to declare convergence.</p></li>
<li><p><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em>, </em><em>default=None</em>) -- The number of jobs to use for computation. This works by computing
each of the n_init runs in parallel.
None means 1. -1 means using all processors.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewSphericalKMeans.labels_">
<span class="sig-name descname"><span class="pre">labels_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each sample in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mvlearn.cluster.MultiviewSphericalKMeans.centroids_">
<span class="sig-name descname"><span class="pre">centroids_</span></span><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans.centroids_" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">centroids_</span></code> length: n_views
<code class="docutils literal notranslate"><span class="pre">centroids_[i]</span></code> shape: (n_clusters, n_features_i)</p>
<p>The cluster centroids for each of the two views. <code class="docutils literal notranslate"><span class="pre">centroids_[0]</span></code>
corresponds to the centroids of view 1 and <code class="docutils literal notranslate"><span class="pre">centroids_[1]</span></code>
corresponds to the centroids of view 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of array-likes</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>Multi-view spherical k-means clustering adapts the traditional spherical
kmeans clustering algorithm to handle two views of data. This algorithm
is similar to the mult-view k-means algorithm, except it uses cosine
distance instead of euclidean distance for the purposes of computing
the optimization objective and making assignments. This algorithm
requires that a conditional independence assumption between views holds
true. In cases where both views are informative and conditionally
independent, multi-view spherical k-means clustering can outperform its
single-view analog run on a concatenated version of the two views of data.
This is quite useful for applications where you wish to cluster data from
two different modalities or data with features that naturally fall into two
different partitions. Multi-view spherical k-means works by iteratively
performing the maximization and expectation steps of traditional EM in
one view, and then using the computed hidden variables as the input for the
maximization step in the other view. This algorithm is described in the
section for multi-view k-means clustering.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewSphericalKMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_kmeans</span> <span class="o">=</span> <span class="n">MultiviewSphericalKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compute nmi between true class labels and multi-view cluster labels</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.823</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="decomposition.html" class="btn btn-neutral float-left" title="Decomposition" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="semi_supervised.html" class="btn btn-neutral float-right" title="Semi-Supervised" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2020.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
<p style="text-align: center; margin: .5rem;">
    <a href="https://www.netlify.com">
        <img src="https://www.netlify.com/img/global/badges/netlify-color-accent.svg" />
    </a>
</p>
 


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>