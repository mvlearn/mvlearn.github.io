

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Clustering &mdash; mvlearn alpha documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/mvlearn-logo-32x32.ico"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Semi-Supervised" href="semi_supervised.html" />
    <link rel="prev" title="Decomposition" href="decomposition.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/mvlearn-logo-transparent-white.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.4.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Using mvlearn</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview of mvlearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing-the-released-version-with-pip">Installing the released version with pip</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install.html#including-optional-dependencies-for-full-functionality">Including optional dependencies for full functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing-the-released-version-with-conda-forge">Installing the released version with conda-forge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#python-package-dependencies">Python package dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#hardware-requirements">Hardware requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#os-requirements">OS Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-cluster">Examples on cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_coregularized_spectral_tutorial.html">Multiview Coregularized Spectral Clustering Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spherical_kmeans_tutorial.html">Multiview Spherical KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_tutorial.html">Multiview KMeans Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_vs_singleview_spectral.html">Multiview vs. Singleview Spectral Clustering of UCI Multiview Digits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_validation_simulated.html">Multiview vs. Singleview KMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_tutorial.html">Multiview Spectral Clustering Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_validation_simulated.html">Multiview vs. Singleview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_spectral_validation_complex.html">Conditional Independence of Views on Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/cluster/plot_mv_kmeans_validation_complex.html">Conditional Independence of Views on Multiview KMeans Clustering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-compose">Examples on compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/compose/plot_multiview_construction.html">Constructing multiple views to classify singleview data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/compose/plot_pipeline_sklearn_integration.html">Integrating mvlearn with scikit-learn</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-datasets">Examples on datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_load_ucimultifeature.html">Loading and Viewing the UCI Multiple Features Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_gaussianmixtures.html">Generating Multiview Data from Gaussian Mixtures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/plot_nutrimouse.html">An mvlearn case study: the Nutrimouse dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-decomposition">Examples on decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_group_ica_tutorial.html">ICA: a tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_mv_ica_tutorial.html">Multiview Independent Component Analysis (ICA) Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decomposition/plot_ajive_tutorial.html">Angle-based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-embed">Examples on embed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_gcca_tutorial.html">Generalized Canonical Correlation Analysis (GCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_mcca_tutorial.html">CCA Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_dcca_tutorial.html">Deep CCA (DCCA) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_omnibus_embedding.html">Omnbius Graph Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_kmcca_pgso_tutorial.html">Partial Gram-Schmidt Orthogonalization (PGSO) for KMCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_mvmds_tutorial.html">Multidimensional Scaling (MVMDS) Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_cca_comparison.html">Comparing CCA Variants</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/embed/plot_kmcca_tutorial.html">Kernel MCCA (KMCCA) Tutorial</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-plotting">Examples on plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plotting/plot_quick_visualize_tutorial.html">Quickly Visualizing Multiview Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plotting/plot_crossviews_plot.html">Plotting Multiview Data with a Cross-view Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/index.html#examples-on-semi-supervised">Examples on semi_supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/semi_supervised/plot_cotraining_regression.html">2-View Semi-Supervised Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/semi_supervised/plot_cotraining_classification.html">2-View Semi-Supervised Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="embed.html">Embedding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="embed.html#canonical-correlation-analysis-cca">Canonical Correlation Analysis (CCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#multiview-canonical-correlation-analysis-mcca">Multiview Canonical Correlation Analysis (MCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#kernel-mcca">Kernel MCCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#generalized-canonical-correlation-analysis-gcca">Generalized Canonical Correlation Analysis (GCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#deep-canonical-correlation-analysis-dcca">Deep Canonical Correlation Analysis (DCCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#omnibus-embedding">Omnibus Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#multiview-multidimensional-scaling">Multiview Multidimensional Scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#split-autoencoder">Split Autoencoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#dcca-utilities">DCCA Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="embed.html#dimension-selection">Dimension Selection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">Decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#multiview-ica">Multiview ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#group-ica">Group ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#group-pca">Group PCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="decomposition.html#angle-based-joint-and-individual-variation-explained-ajive">Angle-Based Joint and Individual Variation Explained (AJIVE)</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Clustering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multiview-spectral-clustering">Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#co-regularized-multiview-spectral-clustering">Co-Regularized Multiview Spectral Clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiview-k-means">Multiview K Means</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiview-spherical-k-means">Multiview Spherical K Means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised.html">Semi-Supervised</a><ul>
<li class="toctree-l3"><a class="reference internal" href="semi_supervised.html#cotraining-classifier">Cotraining Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="semi_supervised.html#cotraining-regressor">Cotraining Regressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_selection.html">Model Selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_selection.html#cross-validation">Cross Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_selection.html#train-test-split">Train-Test Split</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compose.html">Compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compose.html#averagemerger">AverageMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#concatmerger">ConcatMerger</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#randomgaussianprojection">RandomGaussianProjection</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#randomsubspacemethod">RandomSubspaceMethod</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#simplesplitter">SimpleSplitter</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#viewclassifier">ViewClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="compose.html#viewtransformer">ViewTransformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets.html">Multiview Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#uci-multiple-feature-dataset">UCI multiple feature dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#nutrimouse-dataset">Nutrimouse dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#data-simulator">Data Simulator</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets.html#factor-model">Factor Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plotting.html">Plotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plotting.html#quick-visualize">Quick Visualize</a></li>
<li class="toctree-l3"><a class="reference internal" href="plotting.html#crossviews-plot">Crossviews Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">Utility Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="utils.html#io">IO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Developer Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to mvlearn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-a-bug-report-or-a-feature-request">Submitting a bug report or a feature request</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#how-to-make-a-good-bug-report">How to make a good bug report</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#contributing-code">Contributing Code</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#pull-request-checklist">Pull Request Checklist</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#guidelines">Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#coding-guidelines">Coding Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#docstring-guidelines">Docstring Guidelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#api-of-mvlearn-objects">API of mvlearn Objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#estimators">Estimators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#additional-functionality">Additional Functionality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#unreleased">Unreleased</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-4-1">Version 0.4.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-4-0">Version 0.4.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id3">mvlearn.compose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id11">mvlearn.construct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id13">mvlearn.decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id15">mvlearn.embed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id19">mvlearn.model_selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id22">mvlearn.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-3-0">Version 0.3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#patch-0-2-1">Patch 0.2.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-2-0">Version 0.2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-0-1-0">Version 0.1.0</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Useful Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn">mvlearn &#64; GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/mvlearn/">mvlearn &#64; PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/mvlearn/mvlearn/issues">Issue Tracker</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">mvlearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Reference</a> &raquo;</li>
        
      <li>Clustering</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/mvlearn/mvlearn/blob/main/docs/references/cluster.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="clustering">
<h1>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h1>
<div class="section" id="multiview-spectral-clustering">
<h2>Multiview Spectral Clustering<a class="headerlink" href="#multiview-spectral-clustering" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mvlearn.cluster.MultiviewSpectralClustering">
<em class="property">class </em><code class="descclassname">mvlearn.cluster.</code><code class="descname">MultiviewSpectralClustering</code><span class="sig-paren">(</span><em>n_clusters=2</em>, <em>random_state=None</em>, <em>info_view=None</em>, <em>max_iter=10</em>, <em>n_init=10</em>, <em>affinity='rbf'</em>, <em>gamma=None</em>, <em>n_neighbors=10</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_spectral.html#MultiviewSpectralClustering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>An implementation of multi-view spectral clustering.</p>
<p>An implementation of multi-view spectral clustering using the
basic co-training framework as described in <a class="footnote-reference" href="#clu" id="id1">[1]</a>.
Additionally, this can be effective when the dataset naturally
contains features that are of 2 different data types, such as
continuous features and categorical features <a class="footnote-reference" href="#id8" id="id2">[4]</a>, and then the
original features are separated into two views in this way.</p>
<p>This algorithm can handle 2 or more views of data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The number of clusters</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for k-means.</li>
<li><strong>info_view</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- The most informative view. Must be between 0 and n_views-1
If given, then the final clustering will be performed on the
designated view alone. Otherwise, the algorithm will concatenate
across all views and cluster on the result.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The maximum number of iterations to run the clustering
algorithm.</li>
<li><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The number of random initializations to use for k-means clustering.</li>
<li><strong>affinity</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='rbf'</em>) -- The affinity metric used to construct the affinity matrix. Options
include 'rbf' (radial basis function), 'nearest_neighbors', and
'poly' (polynomial)</li>
<li><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Kernel coefficient for rbf and polynomial kernels. If None then
gamma is computed as 1 / (2 * median(pair_wise_distances(X))^2)
for each data view X.</li>
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- Only used if nearest neighbors is selected for affinity. The
number of neighbors to use for the nearest neighbors kernel.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewSpectralClustering.labels_">
<code class="descname">labels_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each sample in the fitted data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like, shape (n_samples)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewSpectralClustering.embedding_">
<code class="descname">embedding_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering.embedding_" title="Permalink to this definition">¶</a></dt>
<dd><p>The final spectral representation of the data to be used as input
for the KMeans clustering step.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like, shape (n_samples, n_clusters)</td>
</tr>
</tbody>
</table>
</dd></dl>

<p class="rubric">Notes</p>
<p>Multi-view spectral clustering adapts the spectral clustering algorithm
to applications where more than one view of data is available. This
algorithm relies on the basic assumptions of the co-training, which are:
(a) Sufficiency: each view is sufficient for classification on its own,
(b) Compatibility: the target functions in both views predict the same
labels for co-occurring features with high probability, and (c)
Conditional independence: the views are conditionally independent given
the class labels. In contrast to multi-view k-means clustering,
multi-view spectral clustering performs well on arbitrary shaped clusters,
and can therefore be readily used in applications where clusters are not
expected to be convex. However multi-view spectral clustering tends to be
computationally expensive unless the similarity graph for the data is
sparse.</p>
<p>Multi-view spectral clustering works by using the spectral embedding
from one view to constrain the similarity graph in the other view. By
iteratively applying this procedure, the clustering of the two views
tend to each other. Here we outline the algorithm for the Multi-view
Spectral clustering algorithm for 2 views.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><em>Multi-view Spectral Clustering Algorithm (for 2 views)</em></p>
<p>Input: Similarity matrix for both views: <span class="math notranslate nohighlight">\(\mathbf{K}_1, \mathbf{K}_2\)</span></p>
<p>Output: Assignments to k clusters</p>
<ol class="arabic">
<li><p class="first">Initialize: <span class="math notranslate nohighlight">\(\mathbf{L}_v = \mathbf{D}_v^{-1/2}
\mathbf{K}_v\mathbf{D}_v^{-1/2}\)</span> for <span class="math notranslate nohighlight">\(v = 1, 2\)</span>
<span class="math notranslate nohighlight">\(\mathbf{U}_v^0\)</span> is an <span class="math notranslate nohighlight">\(n \times k\)</span> matrix with the
top k eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{L}_v\)</span> for <span class="math notranslate nohighlight">\(v = 1, 2\)</span></p>
</li>
<li><p class="first">For <span class="math notranslate nohighlight">\(i = 1\)</span> to iter:</p>
<blockquote>
<div><ol class="loweralpha simple">
<li><span class="math notranslate nohighlight">\(\mathbf{S}_1 = sym(\mathbf{U}_2^{i-1}
{\mathbf{U}_2^{i-1}}^T\mathbf{K}_1)\)</span></li>
<li><span class="math notranslate nohighlight">\(\mathbf{S}_2 = sym(\mathbf{U}_1^{i-1}
{\mathbf{U}_1^{i-1}}^T\mathbf{K}_2)\)</span></li>
<li>Use <span class="math notranslate nohighlight">\(\mathbf{S}_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{S}_2\)</span> as the new
graph similarities and compute the Laplacians. Solve for the
largest k eigenvectors to obtain <span class="math notranslate nohighlight">\(\mathbf{U}_1^i\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{U}_2^i\)</span>.</li>
</ol>
</div></blockquote>
</li>
<li><p class="first">Row-normalize <span class="math notranslate nohighlight">\(\mathbf{U}_1^i\)</span> and <span class="math notranslate nohighlight">\(\mathbf{U}_2^i\)</span>.</p>
</li>
<li><p class="first">Form matrix <span class="math notranslate nohighlight">\(\mathbf{V} = \mathbf{U}_v^i\)</span>, where <span class="math notranslate nohighlight">\(v\)</span> is
believed to be the most informative view a priori. If there is no
prior knowledge on the view informativeness, matrix
<span class="math notranslate nohighlight">\(\mathbf{V}\)</span> can also be set to the column-wise concatenation
of the two <span class="math notranslate nohighlight">\(\mathbf{U}_v^i\)</span> s.</p>
</li>
<li><p class="first">Assign example j to cluster c if the j-th row of <span class="math notranslate nohighlight">\(\mathbf{V}\)</span>
is assigned to cluster c by the k-means algorithm.</p>
</li>
</ol>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="clu" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Abhishek Kumar and Hal Daume. &quot;A co-training approach for
multi-view spectral clustering.&quot; In Proceedings of the 28th
International Conference on Machine Learning, page 393–400.
Omnipress, 2011.</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewSpectralClustering</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_spectral</span> <span class="o">=</span> <span class="n">MultiviewSpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_spectral</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.872</span>
</pre></div>
</div>
<dl class="method">
<dt id="mvlearn.cluster.MultiviewSpectralClustering.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>Xs</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_spectral.html#MultiviewSpectralClustering.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs clustering on the multiple views of data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>This list must be of size n_views, corresponding to the number
of views of data. Each view can have a different number of
features, but they must have the same number of samples.</p>
</li>
<li><strong>y</strong> (<em>Ignored</em>) -- Not used, present for API consistency by convention.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">returns an instance of self.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewSpectralClustering.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>Xs</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>A method for fitting then predicting cluster assignments.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of different views to fit the model on.</p>
</li>
<li><strong>y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) -- Labels for each sample. Only used by supervised algorithms.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>labels</strong> -- The predicted cluster labels for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewSpectralClustering.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.cluster.MultiviewSpectralClustering.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>A method to predict cluster labels of multiview data.
:param Xs:</p>
<blockquote>
<div><ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of different views to cluster.</p>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>labels</strong> -- Returns the predicted cluster labels for each sample.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">array-like, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="co-regularized-multiview-spectral-clustering">
<h2>Co-Regularized Multiview Spectral Clustering<a class="headerlink" href="#co-regularized-multiview-spectral-clustering" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mvlearn.cluster.MultiviewCoRegSpectralClustering">
<em class="property">class </em><code class="descclassname">mvlearn.cluster.</code><code class="descname">MultiviewCoRegSpectralClustering</code><span class="sig-paren">(</span><em>n_clusters=2</em>, <em>v_lambda=2</em>, <em>random_state=None</em>, <em>info_view=None</em>, <em>max_iter=10</em>, <em>n_init=10</em>, <em>affinity='rbf'</em>, <em>gamma=None</em>, <em>n_neighbors=10</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_coreg_spectral.html#MultiviewCoRegSpectralClustering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>An implementation of co-regularized multi-view spectral clustering based on
an unsupervied version of the co-training framework.
This algorithm uses the pairwise co-regularization scheme as described
in <a class="footnote-reference" href="#id4" id="id3">[2]</a>. This algorithm can handle 2 or more views of data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) -- The number of clusters</li>
<li><strong>v_lambda</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=2</em>) -- The regularization parameter. This parameter trades-off the spectral
clustering objectives with the degree of agreement between each pair
of views in the new representation. Must be a positive value.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for k-means.</li>
<li><strong>info_view</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- The most informative view. Must be between 0 and n_views-1
If given, then the final clustering will be performed on the
designated view alone. Otherwise, the algorithm will concatenate
across all views and cluster on the result.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The maximum number of iterations to run the clustering
algorithm.</li>
<li><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- The number of random initializations to use for k-means clustering.</li>
<li><strong>affinity</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='rbf'</em>) -- The affinity metric used to construct the affinity matrix. Options
include 'rbf' (radial basis function), 'nearest_neighbors', and
'poly' (polynomial)</li>
<li><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Kernel coefficient for rbf and polynomial kernels. If None then
gamma is computed as 1 / (2 * median(pair_wise_distances(X))^2)
for each data view X.</li>
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=10</em>) -- Only used if nearest neighbors is selected for affinity. The
number of neighbors to use for the nearest neighbors kernel.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewCoRegSpectralClustering.labels_">
<code class="descname">labels_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each point.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewCoRegSpectralClustering.embedding_">
<code class="descname">embedding_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.embedding_" title="Permalink to this definition">¶</a></dt>
<dd><p>The final spectral representation of the data to be used as input
for the KMeans clustering step.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like, shape (n_samples, n_clusters)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewCoRegSpectralClustering.objective_">
<code class="descname">objective_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.objective_" title="Permalink to this definition">¶</a></dt>
<dd><p>The value of the spectral clustering objective for each view at
the end of each iteration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like, shape (n_views, n_iterations)</td>
</tr>
</tbody>
</table>
</dd></dl>

<p class="rubric">Notes</p>
<p>In standard spectral clustering, the eigenvector matrix U for a given view
is the new data representation to be used for the subsequent k-means
clustering stage. In this algorithm, the objective function has been
altered to encourage the pairwise similarities of examples under the new
representation to be similar across all views.</p>
<p>The modified spectral clustering objective for the case of two views is
shown and derived in [#4Clu]. In the clustering objective, the
hyperparameter lambda trades-off the spectral clustering objectives and
the disagreement term.</p>
<p>For a fixed lambda and n, the objective function is bounded from above and
non-decreasing. As such, the algorithm is guaranteed to converge.</p>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[2]</a></td><td>Abhishek Kumar, Piyush Rai, and Hal Daume.  Co-regularized
multi-view spectral cluster-ing. In Proceedings of the 24th
International Conference on Neural Information Processing Systems,
page 1413–1421. Curran Associates Inc., 2011.</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewCoRegSpectralClustering</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_spectral</span> <span class="o">=</span> <span class="n">MultiviewCoRegSpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_spectral</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">,</span> <span class="n">average_method</span><span class="o">=</span><span class="s1">&#39;arithmetic&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.663</span>
</pre></div>
</div>
<dl class="method">
<dt id="mvlearn.cluster.MultiviewCoRegSpectralClustering.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_coreg_spectral.html#MultiviewCoRegSpectralClustering.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs clustering on the multiple views of data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>This list must be of size n_views, corresponding to the number
of views of data. Each view can have a different number of
features, but they must have the same number of samples.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">returns an instance of self.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewCoRegSpectralClustering.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>Xs</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_coreg_spectral.html#MultiviewCoRegSpectralClustering.fit_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs clustering on the multiple views of data and returns
the cluster labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>This list must be of size n_views, corresponding to the number
of views of data. Each view can have a different number of
features, but they must have the same number of samples.</p>
</li>
<li><strong>y</strong> (<em>ignored</em>) -- Included for API compliance.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>labels</strong> -- The predicted cluster labels for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewCoRegSpectralClustering.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.cluster.MultiviewCoRegSpectralClustering.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>A method to predict cluster labels of multiview data.
:param Xs:</p>
<blockquote>
<div><ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of different views to cluster.</p>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>labels</strong> -- Returns the predicted cluster labels for each sample.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">array-like, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="multiview-k-means">
<h2>Multiview K Means<a class="headerlink" href="#multiview-k-means" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mvlearn.cluster.MultiviewKMeans">
<em class="property">class </em><code class="descclassname">mvlearn.cluster.</code><code class="descname">MultiviewKMeans</code><span class="sig-paren">(</span><em>n_clusters=2</em>, <em>random_state=None</em>, <em>init='k-means++'</em>, <em>patience=5</em>, <em>max_iter=300</em>, <em>n_init=5</em>, <em>tol=0.0001</em>, <em>n_jobs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_kmeans.html#MultiviewKMeans"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements multi-view k-means.</p>
<p>This class implements multi-view k-means using the co-EM framework
as described in <a class="footnote-reference" href="#id7" id="id5">[3]</a>. This algorithm is most suitable for cases
in which the different views of data are conditionally independent.
Additionally, this can be effective when the dataset naturally
contains features that are of 2 different data types, such as
continuous features and categorical features <a class="footnote-reference" href="#id8" id="id6">[4]</a>, and then the
original features are separated into two views in this way.</p>
<p>This algorithm currently handles two views of data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=2</em>) -- The number of clusters</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for initializing centroids.
Can seed the random number generator with an int.</li>
<li><strong>init</strong> (<em>{'k-means++'</em><em>, </em><em>'random'}</em><em> or </em><em>list of array-likes</em><em>, </em><em>default='k-means++'</em>) -- <p>Method of initializing centroids.</p>
<p>'k-means++': selects initial cluster centers for k-means clustering
via a method that speeds up convergence.</p>
<p>'random': choose n_cluster samples from the data for the initial
centroids.</p>
<p>If a list of array-likes is passed, the list should have a length of
equal to the number of views. Each of the array-likes should have
the shape (n_clusters, n_features_i) for the ith view, where
n_features_i is the number of features in the ith view of the input
data.</p>
</li>
<li><strong>patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- The number of EM iterations with no decrease in the objective
function after which the algorithm will terminate.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=300</em>) -- The maximum number of EM iterations to run before
termination.</li>
<li><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- Number of times the k-means algorithm will run on different
centroid seeds. The final result will be the best output of
n_init runs with respect to total inertia across all views.</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>default=1e-4</em>) -- Relative tolerance with regards to inertia to declare convergence.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>default=None</em>) -- The number of jobs to use for computation. This works by computing
each of the n_init runs in parallel.
None means 1. -1 means using all processors.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewKMeans.labels_">
<code class="descname">labels_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each sample in the fitted data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like, shape (n_samples)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewKMeans.centroids_">
<code class="descname">centroids_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans.centroids_" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">centroids_</span></code> length: n_views
<code class="docutils literal notranslate"><span class="pre">centroids_[i]</span></code> shape: (n_clusters, n_features_i)</p>
<p>The cluster centroids for each of the two views. <code class="docutils literal notranslate"><span class="pre">centroids_[0]</span></code>
corresponds to the centroids of view 1 and <code class="docutils literal notranslate"><span class="pre">centroids_[1]</span></code>
corresponds to the centroids of view 2.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">list of array-likes</td>
</tr>
</tbody>
</table>
</dd></dl>

<p class="rubric">Notes</p>
<p>Multi-view k-means clustering adapts the traditional k-means clustering
algorithm to handle two views of data. This algorithm requires that a
conditional independence assumption between views holds true. In cases
where both views are informative and conditionally independent, multi-view
k-means clustering can outperform its single-view analog run on a
concatenated version of the two views of data. This is quite useful for
applications where you wish to cluster data from two different modalities
or data with features that naturally fall into two different partitions.
Multi-view k-means works by iteratively performing the maximization and
expectation steps of traditional EM in one view, and then using the
computed hidden variables as the input for the maximization step in
the other view. This algorithm, referred to as Co-EM, is described
below.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><em>Co-EM Algorithm</em></p>
<p>Input: Unlabeled data D with 2 views</p>
<ol class="arabic">
<li><p class="first">Initialize <span class="math notranslate nohighlight">\(\Theta_0^{(2)}\)</span>, T, <span class="math notranslate nohighlight">\(t = 0\)</span>.</p>
</li>
<li><p class="first">E step for view 2: compute expectation for hidden variables given</p>
</li>
<li><p class="first">Loop until stopping criterion is true:</p>
<blockquote>
<div><ol class="loweralpha simple">
<li>For v = 1 ... 2:<ol class="lowerroman">
<li><span class="math notranslate nohighlight">\(t = t + 1\)</span></li>
<li>M step view v: Find model parameters <span class="math notranslate nohighlight">\(\Theta_t^{(v)}\)</span>
that maximize the likelihood for the data given the expected
values for hidden variables of view <span class="math notranslate nohighlight">\(\overline{v}\)</span> of
iteration <span class="math notranslate nohighlight">\(t\)</span> - 1</li>
<li>E step view <span class="math notranslate nohighlight">\(v\)</span>: compute expectation for hidden
variables given the model parameters <span class="math notranslate nohighlight">\(\Theta_t^{(v)}\)</span></li>
</ol>
</li>
</ol>
</div></blockquote>
</li>
<li><p class="first">return combined <span class="math notranslate nohighlight">\(\hat{\Theta} = \Theta_{t-1}^{(1)} \cup
\Theta_t^{(2)}\)</span></p>
</li>
</ol>
<p>The final assignment of examples to partitions is performed by assigning
each example to the cluster with the largest averaged posterior
probability over both views.</p>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="id7" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td><em>(<a class="fn-backref" href="#id5">1</a>, <a class="fn-backref" href="#id9">2</a>)</em> Steffen Bickel and Tobias Scheffer. Multi-view clustering. In
Proceedings of the Fourth IEEE International Conference on Data
Mining, page 19–26. IEEE Computer Society, 2004.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[4]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id6">2</a>, <a class="fn-backref" href="#id10">3</a>)</em> Guoqing Chao, Shiliang Sun, and J. Bi. A survey on multi-view
clustering.arXiv preprint, arXiv:1712.06246, 2017.</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewKMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_kmeans</span> <span class="o">=</span> <span class="n">MultiviewKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.770</span>
</pre></div>
</div>
<p>&quot;&quot;</p>
<dl class="method">
<dt id="mvlearn.cluster.MultiviewKMeans.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>Xs</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_kmeans.html#MultiviewKMeans.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the cluster centroids to the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>This list must be of size 2, corresponding to the two views of
the data. The two views can each have a different number of
features, but they must have the same number of samples.</p>
</li>
<li><strong>y</strong> (<em>Ignored</em>) -- Not used, present for API consistency by convention.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">returns an instance of self.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewKMeans.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_kmeans.html#MultiviewKMeans.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the cluster labels for the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>This list must be of size 2, corresponding to the two
views of the data. The two views can each have a different
number of features, but they must have the same number of samples.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>labels</strong> -- The predicted cluster labels for each sample.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array-like, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewKMeans.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>Xs</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.cluster.MultiviewKMeans.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>A method for fitting then predicting cluster assignments.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of different views to fit the model on.</p>
</li>
<li><strong>y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) -- Labels for each sample. Only used by supervised algorithms.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>labels</strong> -- The predicted cluster labels for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="multiview-spherical-k-means">
<h2>Multiview Spherical K Means<a class="headerlink" href="#multiview-spherical-k-means" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mvlearn.cluster.MultiviewSphericalKMeans">
<em class="property">class </em><code class="descclassname">mvlearn.cluster.</code><code class="descname">MultiviewSphericalKMeans</code><span class="sig-paren">(</span><em>n_clusters=2</em>, <em>random_state=None</em>, <em>init='k-means++'</em>, <em>patience=5</em>, <em>max_iter=None</em>, <em>n_init=5</em>, <em>tol=0.0001</em>, <em>n_jobs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_spherical_kmeans.html#MultiviewSphericalKMeans"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans" title="Permalink to this definition">¶</a></dt>
<dd><p>An implementation of multi-view spherical K-Means.</p>
<p>An implementation of multi-view spherical K-Means using the
co-EM framework as described in <a class="footnote-reference" href="#id7" id="id9">[3]</a>. This algorithm is
most suitable for cases in which the different views of data
are conditionally independent. Additionally, this can be effective
when the dataset naturally contains features that are of 2 different
data types, such as continuous features and categorical features
<a class="footnote-reference" href="#id8" id="id10">[4]</a>, and then the original features are separated into two
views in this way.</p>
<p>This algorithm currently handles two views of data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=2</em>) -- The number of clusters</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- Determines random number generation for initializing centroids.
Can seed the random number generator with an int.</li>
<li><strong>init</strong> (<em>{'k-means++'</em><em>, </em><em>'random'}</em><em> or </em><em>list of array-likes</em><em>, </em><em>default='k-means++'</em>) -- <p>Method of initializing centroids.</p>
<p>'k-means++': selects initial cluster centers for k-means clustering
via a method that speeds up convergence.</p>
<p>'random': choose n_cluster samples from the data for the initial
centroids.</p>
<p>If a list of array-likes is passed, the list should have a length of
equal to the number of views. Each of the array-likes should have
the shape (n_clusters, n_features_i) for the ith view, where
n_features_i is the number of features in the ith view of the input
data.</p>
</li>
<li><strong>patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- The number of EM iterations with no decrease in the objective
function after which the algorithm will terminate.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=None</em>) -- The maximum number of EM iterations to run before
termination.</li>
<li><strong>n_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default=5</em>) -- Number of times the k-means algorithm will run on different
centroid seeds. The final result will be the best output of
n_init runs with respect to total inertia across all views.</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>default=1e-4</em>) -- Relative tolerance with regards to inertia to declare convergence.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>default=None</em>) -- The number of jobs to use for computation. This works by computing
each of the n_init runs in parallel.
None means 1. -1 means using all processors.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewSphericalKMeans.labels_">
<code class="descname">labels_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans.labels_" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster labels for each sample in the fitted data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">array-like, shape (n_samples)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="mvlearn.cluster.MultiviewSphericalKMeans.centroids_">
<code class="descname">centroids_</code><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans.centroids_" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">centroids_</span></code> length: n_views
<code class="docutils literal notranslate"><span class="pre">centroids_[i]</span></code> shape: (n_clusters, n_features_i)</p>
<p>The cluster centroids for each of the two views. <code class="docutils literal notranslate"><span class="pre">centroids_[0]</span></code>
corresponds to the centroids of view 1 and <code class="docutils literal notranslate"><span class="pre">centroids_[1]</span></code>
corresponds to the centroids of view 2.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">list of array-likes</td>
</tr>
</tbody>
</table>
</dd></dl>

<p class="rubric">Notes</p>
<p>Multi-view spherical k-means clustering adapts the traditional spherical
kmeans clustering algorithm to handle two views of data. This algorithm
is similar to the mult-view k-means algorithm, except it uses cosine
distance instead of euclidean distance for the purposes of computing
the optimization objective and making assignments. This algorithm
requires that a conditional independence assumption between views holds
true. In cases where both views are informative and conditionally
independent, multi-view spherical k-means clustering can outperform its
single-view analog run on a concatenated version of the two views of data.
This is quite useful for applications where you wish to cluster data from
two different modalities or data with features that naturally fall into two
different partitions. Multi-view spherical k-means works by iteratively
performing the maximization and expectation steps of traditional EM in
one view, and then using the computed hidden variables as the input for the
maximization step in the other view. This algorithm is described in the
section for multi-view k-means clustering.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.datasets</span> <span class="kn">import</span> <span class="n">load_UCImultifeature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mvlearn.cluster</span> <span class="kn">import</span> <span class="n">MultiviewSphericalKMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">normalized_mutual_info_score</span> <span class="k">as</span> <span class="n">nmi_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get 5-class data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_UCImultifeature</span><span class="p">(</span><span class="n">select_labeled</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># first 2 views only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_kmeans</span> <span class="o">=</span> <span class="n">MultiviewSphericalKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mv_clusters</span> <span class="o">=</span> <span class="n">mv_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">mv_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compute nmi between true class labels and multi-view cluster labels</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nmi</span> <span class="o">=</span> <span class="n">nmi_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mv_clusters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nmi</span><span class="p">))</span>
<span class="go">0.823</span>
</pre></div>
</div>
<dl class="method">
<dt id="mvlearn.cluster.MultiviewSphericalKMeans.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>Xs</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mvlearn/cluster/mv_spherical_kmeans.html#MultiviewSphericalKMeans.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the cluster centroids to the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>This list must be of size 2, corresponding to the two views of
the data. The two views can each have a different number of
features, but they must have the same number of samples.</p>
</li>
<li><strong>y</strong> (<em>Ignored</em>) -- Not used, present for API consistency by convention.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">returns an instance of self.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewSphericalKMeans.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>Xs</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>A method for fitting then predicting cluster assignments.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul>
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>A list of different views to fit the model on.</p>
</li>
<li><strong>y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) -- Labels for each sample. Only used by supervised algorithms.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>labels</strong> -- The predicted cluster labels for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="mvlearn.cluster.MultiviewSphericalKMeans.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>Xs</em><span class="sig-paren">)</span><a class="headerlink" href="#mvlearn.cluster.MultiviewSphericalKMeans.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the cluster labels for the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>Xs</strong> (<em>list of array-likes</em><em> or </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a>) -- <ul class="simple">
<li>Xs length: n_views</li>
<li>Xs[i] shape: (n_samples, n_features_i)</li>
</ul>
<p>This list must be of size 2, corresponding to the two
views of the data. The two views can each have a different
number of features, but they must have the same number of samples.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>labels</strong> -- The predicted cluster labels for each sample.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array-like, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="semi_supervised.html" class="btn btn-neutral float-right" title="Semi-Supervised" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="decomposition.html" class="btn btn-neutral" title="Decomposition" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-2020

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
<p style="text-align: center; margin: .5rem;">
    <a href="https://www.netlify.com">
        <img src="https://www.netlify.com/img/global/badges/netlify-color-accent.svg" />
    </a>
</p>
 


</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/js/copybutton.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>