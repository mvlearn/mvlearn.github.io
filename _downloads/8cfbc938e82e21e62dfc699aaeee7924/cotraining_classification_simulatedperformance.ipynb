{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Co-training performance in various simulated scenarios\n\nMultiview vs. singleview classifier performance:\n- when one view is totally redundant\n- when one view is inseparable\n- when labeled data is excellent\n- when labeled data is not very separable\n- when data is overlapping](#Performance-when-data-is-overlapping)\n- as labeled data proportion (essentially sample size) is varied\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\nfrom mvlearn.semi_supervised import CTClassifier\nfrom mvlearn.datasets import load_UCImultifeature\nfrom sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to create 2 class data\n\nThis function is used to generate examples for 2 classes from multivariate\nnormal distributions. Once the examples are generated, it splits them into\ntraining and testing sets and returns the needed information\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def create_data(seed, class2_mean_center, view1_var, view2_var,\n                N_per_class, view2_class2_mean_center=1):\n\n    np.random.seed(seed)\n\n    view1_mu0 = np.zeros(2,)\n    view1_mu1 = class2_mean_center * np.ones(2,)\n    view1_cov = view1_var*np.eye(2)\n\n    view2_mu0 = np.zeros(2,)\n    view2_mu1 = view2_class2_mean_center * np.ones(2,)\n    view2_cov = view2_var*np.eye(2)\n\n    view1_class0 = np.random.multivariate_normal(\n        view1_mu0, view1_cov, size=N_per_class)\n    view1_class1 = np.random.multivariate_normal(\n        view1_mu1, view1_cov, size=N_per_class)\n\n    view2_class0 = np.random.multivariate_normal(\n        view2_mu0, view2_cov, size=N_per_class)\n    view2_class1 = np.random.multivariate_normal(\n        view2_mu1, view2_cov, size=N_per_class)\n\n    View1 = np.concatenate((view1_class0, view1_class1))\n    View2 = np.concatenate((view2_class0, view2_class1))\n    Labels = np.concatenate((np.zeros(N_per_class,), np.ones(N_per_class,)))\n\n    # Split both views into testing and training\n    View1_train, View1_test, labels_train_full, labels_test_full = \\\n        train_test_split(View1, Labels, test_size=0.3, random_state=42)\n    View2_train, View2_test, labels_train_full, labels_test_full = \\\n        train_test_split(View2, Labels, test_size=0.3, random_state=42)\n\n    labels_train = labels_train_full.copy()\n    labels_test = labels_test_full.copy()\n\n    return View1_train, View2_train, labels_train, labels_train.copy(),\\\n        View1_test, View2_test, labels_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to do predictions on single or concatenated view data\n\nThis function is used create classifiers for single or concatenated views\nand return their predictions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def single_view_class(v1_train, labels_train, v1_test, labels_test,\n                      v2_train, v2_test, v2_solver, v2_penalty):\n\n    gnb0 = LogisticRegression()\n    gnb1 = LogisticRegression(solver=v2_solver, penalty=v2_penalty)\n    gnb2 = LogisticRegression()\n\n    # Train on only the examples with labels\n    gnb0.fit(v1_train, labels_train)\n    y_pred0 = gnb0.predict(v1_test)\n\n    gnb1.fit(v2_train, labels_train)\n    y_pred1 = gnb1.predict(v2_test)\n\n    accuracy_view1 = (accuracy_score(labels_test, y_pred0))\n    accuracy_view2 = (accuracy_score(labels_test, y_pred1))\n\n    # Concatenate views in naive way and train model\n    combined_labeled = np.hstack((v1_train, v2_train))\n    combined_test = np.hstack((v1_test, v2_test))\n\n    gnb2.fit(combined_labeled, labels_train)\n    y_pred2 = gnb2.predict(combined_test)\n\n    accuracy_combined = (accuracy_score(labels_test, y_pred2))\n\n    return accuracy_view1, accuracy_view2, accuracy_combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to create 2 class scatter plots with labeled data shown\n\nThis function is used to create scatter plots of the 2 class data as well as\nshow the samples that are labeled, making it easier to understand what\ndistributions the simulations are dealing with\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scatterplot_classes(not_removed, labels_train, labels_train_full,\n                        View1_train, View2_train):\n\n    idx_train_0 = np.where(labels_train_full == 0)\n    idx_train_1 = np.where(labels_train_full == 1)\n\n    labeled_idx_class0 = not_removed[np.where(labels_train[not_removed] == 0)]\n    labeled_idx_class1 = not_removed[np.where(labels_train[not_removed] == 1)]\n\n    # plot the views\n    plt.figure()\n    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n\n    ax[0].scatter(View1_train[idx_train_0, 0], View1_train[idx_train_0, 1])\n    ax[0].scatter(View1_train[idx_train_1, 0], View1_train[idx_train_1, 1])\n    ax[0].scatter(View1_train[labeled_idx_class0, 0],\n                  View1_train[labeled_idx_class0, 1], s=300, marker='X')\n    ax[0].scatter(View1_train[labeled_idx_class1, 0],\n                  View1_train[labeled_idx_class1, 1], s=300, marker='X')\n    ax[0].set_title('One Randomization of View 1')\n    ax[0].legend(('Class 0', 'Class 1', 'Labeled Class 0', 'Labeled Class 1'))\n    ax[0].axes.get_xaxis().set_visible(False)\n    ax[0].axes.get_yaxis().set_visible(False)\n\n    ax[1].scatter(View2_train[idx_train_0, 0], View2_train[idx_train_0, 1])\n    ax[1].scatter(View2_train[idx_train_1, 0], View2_train[idx_train_1, 1])\n    ax[1].scatter(View2_train[labeled_idx_class0, 0],\n                  View1_train[labeled_idx_class0, 1], s=300, marker='X')\n    ax[1].scatter(View2_train[labeled_idx_class1, 0],\n                  View1_train[labeled_idx_class1, 1], s=300, marker='X')\n    ax[1].set_title('One Randomization of View 2')\n    ax[1].legend(('Class 0', 'Class 1', 'Labeled Class 0', 'Labeled Class 1'))\n    ax[1].axes.get_xaxis().set_visible(False)\n    ax[1].axes.get_yaxis().set_visible(False)\n\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance on simulated data\n\n### General Experimental Setup\n\n- Below are the results from simulated data testing of the cotraining\n  classifier with different classification problems (class distributions)\n- Results are averaged over 20 randomizations, where a single randomization\n  means using a new seed to generate examples from 2 class distributions and\n  then randomly selecting about 1% of the training data as labeled and\n  leaving the rest unlabeled\n- 500 examples per class, with 70% used for training and 30% for testing\n- For a randomization, train 4 classifiers\n    1. Classifier trained on view 1 labeled data only\n    2. Classifier trained on view 2 labeled data only\n    3. Classifier trained on concatenation of labeled features from views 1\n       and 2\n    4. multivew CTClassifier trained on views 1 and 2\n        - For this, test classification accuracy after different numbers of\n          cotraining iterations to see trajectory of classification accuracy\n- Classification Method:\n    - Logistic Regression\n        - 'l2' penalty for view 1 and 'l1' penalty for view 2 to ensure\n          independence between classifiers in the views. This is important\n          because a key aspect of cotraining is view independence, which can\n          either be enforced by completely independent data, or by using an\n          independent classifier for each view, such as using different\n          parameters with the same type of classifier, or two different\n          classification algorithms.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performance when classes are well separated and labeled examples are randomly\nchosen\n\nHere, the 2 class distributions are the following\n- Class 0 mean: [0, 0]\n- Class 0 covariance: .2*eye(2)\n- Class 1 mean: [1, 1]\n- Class 1 covariance: .2*eye(2)\n\nLabeled examples are chosen randomly from the training set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "randomizations = 20\nN_per_class = 500\nview2_penalty = 'l1'\nview2_solver = 'liblinear'\n\nN_iters = np.arange(1, 202, 15)\nacc_ct = [[] for _ in N_iters]\nacc_view1 = []\nacc_view2 = []\nacc_combined = []\n\nfor count, iters in enumerate(N_iters):\n\n    for seed in range(randomizations):\n\n        View1_train, View2_train, labels_train, labels_train_full, View1_test,\\\n            View2_test, labels_test = create_data(seed, 1, .2, .2, N_per_class)\n\n        # randomly remove some labels\n        np.random.seed(11)\n        remove_idx = np.random.rand(len(labels_train),) < .99\n        labels_train[remove_idx] = np.nan\n        not_removed = np.where(~remove_idx)[0]\n\n        # make sure both classes have at least 1 labeled example\n        if len(set(labels_train[not_removed])) != 2:\n            continue\n\n        if seed == 0 and count == 0:\n            scatterplot_classes(not_removed, labels_train,\n                                labels_train_full, View1_train, View2_train)\n\n        # Single view semi-supervised learning\n        # Only do this calculation once, as unaffected by number of iterations\n        if count == 0:\n            accuracy_view1, accuracy_view2, accuracy_combined = \\\n                single_view_class(View1_train[not_removed, :].squeeze(),\n                                  labels_train[not_removed],\n                                  View1_test,\n                                  labels_test,\n                                  View2_train[not_removed, :].squeeze(),\n                                  View2_test,\n                                  view2_solver,\n                                  view2_penalty)\n            acc_view1.append(accuracy_view1)\n            acc_view2.append(accuracy_view2)\n            acc_combined.append(accuracy_combined)\n\n        # Multiview\n        gnb0 = LogisticRegression()\n        gnb1 = LogisticRegression(solver=view2_solver, penalty=view2_penalty)\n        ctc = CTClassifier(gnb0, gnb1, num_iter=iters)\n        ctc.fit([View1_train, View2_train], labels_train)\n        y_pred_ct = ctc.predict([View1_test, View2_test])\n        acc_ct[count].append((accuracy_score(labels_test, y_pred_ct)))\n\nacc_view1 = np.mean(acc_view1)\nacc_view2 = np.mean(acc_view2)\nacc_combined = np.mean(acc_combined)\nacc_ct = [sum(row) / float(len(row)) for row in acc_ct]\n\n\n# make a figure from the data\nplt.figure()\nplt.plot(N_iters, acc_view1*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_view2*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_combined*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_ct)\nplt.legend(('View 1', 'View 2', 'Naive Concatenated', 'multiview'))\nplt.ylabel(\"Average Accuracy Over {} Randomizations\".format(randomizations))\nplt.xlabel('Iterations of Co-Training')\nplt.title('When Views are Independent and Labeled Samples are Random\\n\\\n    CoTraining Outperforms Single Views and Naive Concatenation')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance when one view is totally redundant\n\nHere, the 2 class distributions are the following\n- Class 0 mean: [0, 0]\n- Class 0 covariance: .2*eye(2)\n- Class 1 mean: [1, 1]\n- Class 1 covariance: .2*eye(2)\n\nViews 1 and 2 hold the exact same samples\n\nLabeled examples are chosen randomly from the training set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "randomizations = 20\nN_per_class = 500\nview2_penalty = 'l1'\nview2_solver = 'liblinear'\n\nN_iters = np.arange(1, 202, 15)\nacc_ct = [[] for _ in N_iters]\nacc_view1 = []\nacc_view2 = []\nacc_combined = []\n\nfor count, iters in enumerate(N_iters):\n\n    for seed in range(randomizations):\n\n        # Create Data\n        View1_train, View2_train, labels_train, labels_train_full, View1_test,\\\n            View2_test, labels_test = create_data(seed, 1, .2, .2, N_per_class)\n        View2_train = View1_train.copy()\n        View2_test = View1_test.copy()\n\n        # randomly remove some labels\n        np.random.seed(11)\n        remove_idx = np.random.rand(len(labels_train),) < .99\n        labels_train[remove_idx] = np.nan\n        not_removed = np.where(~remove_idx)[0]\n\n        # make sure both classes have at least 1 labeled example\n        if len(set(labels_train[not_removed])) != 2:\n            continue\n\n        if seed == 0 and count == 0:\n            scatterplot_classes(not_removed, labels_train,\n                                labels_train_full, View1_train, View2_train)\n\n        # Single view semi-supervised learning\n        # Only do this calculation once, as unaffected by number of iterations\n        if count == 0:\n            accuracy_view1, accuracy_view2, accuracy_combined = \\\n                single_view_class(View1_train[not_removed, :].squeeze(),\n                                  labels_train[not_removed],\n                                  View1_test,\n                                  labels_test,\n                                  View2_train[not_removed, :].squeeze(),\n                                  View2_test,\n                                  view2_solver,\n                                  view2_penalty)\n            acc_view1.append(accuracy_view1)\n            acc_view2.append(accuracy_view2)\n            acc_combined.append(accuracy_combined)\n\n        # Multiview\n        gnb0 = LogisticRegression()\n        gnb1 = LogisticRegression(solver=view2_solver, penalty=view2_penalty)\n        ctc = CTClassifier(gnb0, gnb1, num_iter=iters)\n        ctc.fit([View1_train, View2_train], labels_train)\n        y_pred_ct = ctc.predict([View1_test, View2_test])\n        acc_ct[count].append((accuracy_score(labels_test, y_pred_ct)))\n\nacc_view1 = np.mean(acc_view1)\nacc_view2 = np.mean(acc_view2)\nacc_combined = np.mean(acc_combined)\nacc_ct = [sum(row) / float(len(row)) for row in acc_ct]\n\n\n# make a figure from the data\nplt.figure()\nplt.plot(N_iters, acc_view1*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_view2*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_combined*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_ct)\nplt.legend(('View 1', 'View 2', 'Naive Concatenated', 'multiview'))\nplt.ylabel(\"Average Accuracy Over {} Randomizations\".format(randomizations))\nplt.xlabel('Iterations of Co-Training')\nplt.title('When One View is Completely Redundant\\n\\\n    CoTraining Performs Worse Than\\nSingle View or View Concatenation')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance when one view is inseparable\n\nHere, the 2 class distributions are the following for the first view\n- Class 0 mean: [0, 0]\n- Class 0 covariance: .2*eye(2)\n- Class 1 mean: [1, 1]\n- Class 1 covariance: .2*eye(2)\n\nFor the second view:\n- Class 0 mean: [0, 0]\n- Class 0 covariance: .2*eye(2)\n- Class 1 mean: [0, 0]\n- Class 1 covariance: .2*eye(2)\n\nLabeled examples are chosen randomly from the training set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "randomizations = 20\nN_per_class = 500\nview2_penalty = 'l1'\nview2_solver = 'liblinear'\n\nN_iters = np.arange(1, 202, 15)\nacc_ct = [[] for _ in N_iters]\nacc_view1 = []\nacc_view2 = []\nacc_combined = []\n\nfor count, iters in enumerate(N_iters):\n\n    for seed in range(randomizations):\n\n        # Create Data\n        View1_train, View2_train, labels_train, labels_train_full, View1_test,\\\n            View2_test, labels_test = create_data(seed, 1, .2, .2, N_per_class,\n                                                  view2_class2_mean_center=0)\n\n        # randomly remove some labels\n        np.random.seed(11)\n        remove_idx = np.random.rand(len(labels_train),) < .99\n        labels_train[remove_idx] = np.nan\n        not_removed = np.where(~remove_idx)[0]\n\n        # make sure both classes have at least 1 labeled example\n        if len(set(labels_train[not_removed])) != 2:\n            continue\n\n        if seed == 0 and count == 0:\n            scatterplot_classes(not_removed, labels_train,\n                                labels_train_full, View1_train, View2_train)\n\n        # Single view semi-supervised learning\n        # Only do this calculation once, as unaffected by number of iterations\n        if count == 0:\n            accuracy_view1, accuracy_view2, accuracy_combined = \\\n                single_view_class(View1_train[not_removed, :].squeeze(),\n                                  labels_train[not_removed],\n                                  View1_test,\n                                  labels_test,\n                                  View2_train[not_removed, :].squeeze(),\n                                  View2_test,\n                                  view2_solver,\n                                  view2_penalty)\n            acc_view1.append(accuracy_view1)\n            acc_view2.append(accuracy_view2)\n            acc_combined.append(accuracy_combined)\n\n        # Multiview\n        gnb0 = LogisticRegression()\n        gnb1 = LogisticRegression(solver=view2_solver, penalty=view2_penalty)\n        ctc = CTClassifier(gnb0, gnb1, num_iter=iters)\n        ctc.fit([View1_train, View2_train], labels_train)\n        y_pred_ct = ctc.predict([View1_test, View2_test])\n        acc_ct[count].append((accuracy_score(labels_test, y_pred_ct)))\n\nacc_view1 = np.mean(acc_view1)\nacc_view2 = np.mean(acc_view2)\nacc_combined = np.mean(acc_combined)\nacc_ct = [sum(row) / float(len(row)) for row in acc_ct]\n\n\n# make a figure from the data\nplt.figure()\nplt.plot(N_iters, acc_view1*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_view2*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_combined*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_ct)\nplt.legend(('View 1', 'View 2', 'Naive Concatenated', 'multiview'))\nplt.ylabel(\"Average Accuracy Over {} Randomizations\".format(randomizations))\nplt.xlabel('Iterations of Co-Training')\nplt.title('When One View is Uninformative\\n\\\n    CoTraining Performs Worse Than Single View')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance when labeled data is excellent\n\nHere, the 2 class distributions are the following\n- Class 0 mean: [0, 0]\n- Class 0 covariance: .2*eye(2)\n- Class 1 mean: [1, 1]\n- Class 1 covariance: .2*eye(2)\n\nLabeled examples are chosen to be very close to the mean of their respective\nclass\n- Normally distributed around their class mean with standard deviation 0.05\nin both dimensions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "randomizations = 20\nN_per_class = 500\nnum_perfect = 3\nperfect_scale = 0.05\nview2_penalty = 'l1'\nview2_solver = 'liblinear'\n\nN_iters = np.arange(1, 202, 15)\nacc_ct = [[] for _ in N_iters]\nacc_view1 = []\nacc_view2 = []\nacc_combined = []\n\nfor count, iters in enumerate(N_iters):\n\n    for seed in range(randomizations):\n\n        # Create Data\n        np.random.seed(seed)\n\n        view1_mu0 = np.zeros(2,)\n        view1_mu1 = np.ones(2,)\n        view1_cov = .2*np.eye(2)\n\n        view2_mu0 = np.zeros(2,)\n        view2_mu1 = np.ones(2,)\n        view2_cov = .2*np.eye(2)\n\n        # generage perfect examples\n        perfect_class0_v1 = view1_mu0 + \\\n            np.random.normal(loc=0, scale=perfect_scale, size=view1_mu0.shape)\n        perfect_class0_v2 = view1_mu0 + \\\n            np.random.normal(loc=0, scale=perfect_scale, size=view1_mu0.shape)\n        perfect_class1_v1 = view1_mu1 + \\\n            np.random.normal(loc=0, scale=perfect_scale, size=view1_mu1.shape)\n        perfect_class1_v2 = view1_mu1 + \\\n            np.random.normal(loc=0, scale=perfect_scale, size=view1_mu1.shape)\n        for p in range(1, num_perfect):\n            perfect_class0_v1 = np.vstack(\n                (perfect_class0_v1, view1_mu0 + np.random.normal(\n                    loc=0, scale=0.01, size=view1_mu0.shape)))\n            perfect_class0_v2 = np.vstack(\n                (perfect_class0_v2, view1_mu0 + np.random.normal(\n                    loc=0, scale=0.01, size=view1_mu0.shape)))\n            perfect_class1_v1 = np.vstack(\n                (perfect_class1_v1, view1_mu1 + np.random.normal(\n                    loc=0, scale=0.01, size=view1_mu1.shape)))\n            perfect_class1_v2 = np.vstack(\n                (perfect_class1_v2, view1_mu1 + np.random.normal(\n                    loc=0, scale=0.01, size=view1_mu1.shape)))\n        perfect_labels = np.zeros(num_perfect,)\n        perfect_labels = np.concatenate((\n            perfect_labels, np.ones(num_perfect,)))\n\n        view1_class0 = np.random.multivariate_normal(\n            view1_mu0, view1_cov, size=N_per_class)\n        view1_class1 = np.random.multivariate_normal(\n            view1_mu1, view1_cov, size=N_per_class)\n\n        view2_class0 = np.random.multivariate_normal(\n            view2_mu0, view2_cov, size=N_per_class)\n        view2_class1 = np.random.multivariate_normal(\n            view2_mu1, view2_cov, size=N_per_class)\n\n        View1 = np.concatenate((view1_class0, view1_class1))\n        View2 = np.concatenate((view2_class0, view2_class1))\n        Labels = np.concatenate(\n            (np.zeros(N_per_class,), np.ones(N_per_class,)))\n\n        # Split both views into testing and training\n        View1_train, View1_test, labels_train_full, labels_test_full = \\\n            train_test_split(View1, Labels, test_size=0.3, random_state=42)\n        View2_train, View2_test, labels_train_full, labels_test_full = \\\n            train_test_split(View2, Labels, test_size=0.3, random_state=42)\n\n        labels_train = labels_train_full.copy()\n        labels_test = labels_test_full.copy()\n\n        # Add the perfect examples\n        View1_train = np.vstack(\n            (View1_train, perfect_class0_v1, perfect_class1_v1))\n        View2_train = np.vstack(\n            (View2_train, perfect_class0_v2, perfect_class1_v2))\n        labels_train = np.concatenate((labels_train, perfect_labels))\n\n        # randomly remove all but perfect labeled samples\n        remove_idx = [True for i in range(len(labels_train)-2*num_perfect)]\n        for i in range(2*num_perfect):\n            remove_idx.append(False)\n\n        labels_train[remove_idx] = np.nan\n        not_removed = np.where(~remove_idx)[0]\n        not_removed = np.arange(len(labels_train)-2 *\n                                num_perfect, len(labels_train))\n\n        # make sure both classes have at least 1 labeled example\n        if len(set(labels_train[not_removed])) != 2:\n            continue\n\n        if seed == 0 and count == 0:\n            scatterplot_classes(not_removed, labels_train,\n                                labels_train_full, View1_train, View2_train)\n\n        # Single view semi-supervised learning\n        # Only once, since not affected by \"num iters\"\n        if count == 0:\n            accuracy_view1, accuracy_view2, accuracy_combined = \\\n                single_view_class(View1_train[not_removed, :].squeeze(),\n                                  labels_train[not_removed],\n                                  View1_test,\n                                  labels_test,\n                                  View2_train[not_removed, :].squeeze(),\n                                  View2_test,\n                                  view2_solver,\n                                  view2_penalty)\n            acc_view1.append(accuracy_view1)\n            acc_view2.append(accuracy_view2)\n            acc_combined.append(accuracy_combined)\n\n        # Multiview\n        gnb0 = LogisticRegression()\n        gnb1 = LogisticRegression(solver=view2_solver, penalty=view2_penalty)\n        ctc = CTClassifier(gnb0, gnb1, num_iter=iters)\n        ctc.fit([View1_train, View2_train], labels_train)\n        y_pred_ct = ctc.predict([View1_test, View2_test])\n        acc_ct[count].append((accuracy_score(labels_test, y_pred_ct)))\n\nacc_view1 = np.mean(acc_view1)\nacc_view2 = np.mean(acc_view2)\nacc_combined = np.mean(acc_combined)\nacc_ct = [sum(row) / float(len(row)) for row in acc_ct]\n\n\n# make a figure from the data\nplt.figure()\nplt.plot(N_iters, acc_view1*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_view2*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_combined*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_ct)\nplt.legend(('View 1', 'View 2', 'Naive Concatenated', 'multiview'))\nplt.ylabel(\"Average Accuracy Over {} Randomizations\".format(randomizations))\nplt.xlabel('Iterations of Co-Training')\nplt.title('When Labeled Data is Extremely Clean\\nCoTraining Outperforms \\\n    Single Views\\nbut Naive Concatenation Performs Better')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance when labeled data is not very separable\n\nHere, the 2 class distributions are the following\n- Class 0 mean: [0, 0]\n- Class 0 covariance: .2*eye(2)\n- Class 1 mean: [1, 1]\n- Class 1 covariance: .2*eye(2)\n\nLabeled examples are chosen to be far from their respective means according\nto a uniform distribution in 2 dimensions between .2 and .75 away from the x1\nor x2 coordinate of the mean\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "randomizations = 20\nN_per_class = 500\nnum_perfect = 2\nuniform_min = 0.2\nuniform_max = 0.75\nview2_penalty = 'l1'\nview2_solver = 'liblinear'\n\nN_iters = np.arange(1, 202, 15)\nacc_ct = [[] for _ in N_iters]\nacc_view1 = []\nacc_view2 = []\nacc_combined = []\n\nfor count, iters in enumerate(N_iters):\n\n    for seed in range(randomizations):\n\n        # Create Data\n        np.random.seed(seed)\n\n        view1_mu0 = np.zeros(2,)\n        view1_mu1 = np.ones(2,)\n        view1_cov = .2*np.eye(2)\n\n        view2_mu0 = np.zeros(2,)\n        view2_mu1 = np.ones(2,)\n        view2_cov = .2*np.eye(2)\n\n        # generage bad examples\n        perfect_class0_v1 = view1_mu0 + \\\n            np.random.uniform(uniform_min, uniform_max, size=view1_mu0.shape)\n        perfect_class0_v2 = view1_mu0 + \\\n            np.random.uniform(uniform_min, uniform_max, size=view1_mu0.shape)\n        perfect_class1_v1 = view1_mu1 - \\\n            np.random.uniform(uniform_min, uniform_max, size=view1_mu0.shape)\n        perfect_class1_v2 = view1_mu1 - \\\n            np.random.uniform(uniform_min, uniform_max, size=view1_mu0.shape)\n        for p in range(1, num_perfect):\n            perfect_class0_v1 = np.vstack(\n                (perfect_class0_v1, view1_mu0 + np.random.uniform(\n                    uniform_min, uniform_max, size=view1_mu0.shape)))\n            perfect_class0_v2 = np.vstack(\n                (perfect_class0_v2, view1_mu0 + np.random.uniform(\n                    uniform_min, uniform_max, size=view1_mu0.shape)))\n            perfect_class1_v1 = np.vstack(\n                (perfect_class1_v1, view1_mu1 - np.random.uniform(\n                    uniform_min, uniform_max, size=view1_mu0.shape)))\n            perfect_class1_v2 = np.vstack(\n                (perfect_class1_v2, view1_mu1 - np.random.uniform(\n                    uniform_min, uniform_max, size=view1_mu0.shape)))\n        perfect_labels = np.zeros(num_perfect,)\n        perfect_labels = np.concatenate((\n            perfect_labels, np.ones(num_perfect,)))\n\n        view1_class0 = np.random.multivariate_normal(\n            view1_mu0, view1_cov, size=N_per_class)\n        view1_class1 = np.random.multivariate_normal(\n            view1_mu1, view1_cov, size=N_per_class)\n\n        view2_class0 = np.random.multivariate_normal(\n            view2_mu0, view2_cov, size=N_per_class)\n        view2_class1 = np.random.multivariate_normal(\n            view2_mu1, view2_cov, size=N_per_class)\n\n        View1 = np.concatenate((view1_class0, view1_class1))\n        View2 = np.concatenate((view2_class0, view2_class1))\n        Labels = np.concatenate((np.zeros(N_per_class,),\n                                 np.ones(N_per_class,)))\n\n        # Split both views into testing and training\n        View1_train, View1_test, labels_train_full, labels_test_full = \\\n            train_test_split(View1, Labels, test_size=0.3, random_state=42)\n        View2_train, View2_test, labels_train_full, labels_test_full = \\\n            train_test_split(View2, Labels, test_size=0.3, random_state=42)\n\n        labels_train = labels_train_full.copy()\n        labels_test = labels_test_full.copy()\n\n        # Add the perfect examples\n        View1_train = np.vstack(\n            (View1_train, perfect_class0_v1, perfect_class1_v1))\n        View2_train = np.vstack(\n            (View2_train, perfect_class0_v2, perfect_class1_v2))\n        labels_train = np.concatenate((labels_train, perfect_labels))\n\n        # randomly remove all but perfect labeled samples\n        remove_idx = [True for i in range(len(labels_train)-2*num_perfect)]\n        for i in range(2*num_perfect):\n            remove_idx.append(False)\n\n        labels_train[remove_idx] = np.nan\n        not_removed = np.where(~remove_idx)[0]\n        not_removed = np.arange(len(labels_train)-2 *\n                                num_perfect, len(labels_train))\n\n        # make sure both classes have at least 1 labeled example\n        if len(set(labels_train[not_removed])) != 2:\n            continue\n\n        if seed == 0 and count == 0:\n\n            scatterplot_classes(not_removed, labels_train,\n                                labels_train_full, View1_train, View2_train)\n\n        # Single view semi-supervised learning\n        # Only once, since not affected by \"num iters\"\n        if count == 0:\n            accuracy_view1, accuracy_view2, accuracy_combined = \\\n                single_view_class(View1_train[not_removed, :].squeeze(),\n                                  labels_train[not_removed],\n                                  View1_test,\n                                  labels_test,\n                                  View2_train[not_removed, :].squeeze(),\n                                  View2_test,\n                                  view2_solver,\n                                  view2_penalty)\n            acc_view1.append(accuracy_view1)\n            acc_view2.append(accuracy_view2)\n            acc_combined.append(accuracy_combined)\n\n        # Multiview\n        gnb0 = LogisticRegression()\n        gnb1 = LogisticRegression(solver=view2_solver, penalty=view2_penalty)\n        ctc = CTClassifier(gnb0, gnb1, num_iter=iters)\n        ctc.fit([View1_train, View2_train], labels_train)\n        y_pred_ct = ctc.predict([View1_test, View2_test])\n        acc_ct[count].append((accuracy_score(labels_test, y_pred_ct)))\n\n\nacc_view1 = np.mean(acc_view1)\nacc_view2 = np.mean(acc_view2)\nacc_combined = np.mean(acc_combined)\nacc_ct = [sum(row) / float(len(row)) for row in acc_ct]\n\n\n# make a figure from the data\nplt.figure()\nplt.plot(N_iters, acc_view1*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_view2*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_combined*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_ct)\nplt.legend(('View 1', 'View 2', 'Naive Concatenated', 'multiview'))\nplt.ylabel(\"Average Accuracy Over {} Randomizations\".format(randomizations))\nplt.xlabel('Iterations of Co-Training')\nplt.title(\n    'When Labeled Examples are Not Representative\\n\\\n        CoTraining Does Poorly, as Expected')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance when data is overlapping\n\nHere, the 2 class distributions are the following\n- Class 0 mean: [0, 0]\n- Class 0 covariance: .2*eye(2)\n- Class 1 mean: [0, 0]\n- Class 1 covariance: .2*eye(2)\n\nLabeled examples are chosen randomly from the training set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "randomizations = 20\nN_per_class = 500\nview2_penalty = 'l1'\nview2_solver = 'liblinear'\nclass2_mean_center = 0  # 1 would make this identical to first test\n\nN_iters = np.arange(1, 202, 15)\nacc_ct = [[] for _ in N_iters]\nacc_view1 = []\nacc_view2 = []\nacc_combined = []\n\nfor count, iters in enumerate(N_iters):\n\n    for seed in range(randomizations):\n\n        # Create Data\n        View1_train, View2_train, labels_train, labels_train_full, View1_test,\\\n            View2_test, labels_test = create_data(seed, 0, .2, .2, N_per_class,\n                                                  class2_mean_center)\n\n        # randomly remove some labels\n        np.random.seed(11)\n        remove_idx = np.random.rand(len(labels_train),) < .99\n        labels_train[remove_idx] = np.nan\n        not_removed = np.where(~remove_idx)[0]\n\n        # make sure both classes have at least 1 labeled example\n        if len(set(labels_train[not_removed])) != 2:\n            continue\n\n        if seed == 0 and count == 0:\n\n            scatterplot_classes(not_removed, labels_train,\n                                labels_train_full, View1_train, View2_train)\n\n        # Single view semi-supervised learning\n        # Only once, since not affected by \"num iters\"\n        if count == 0:\n            accuracy_view1, accuracy_view2, accuracy_combined = \\\n                single_view_class(View1_train[not_removed, :].squeeze(),\n                                  labels_train[not_removed],\n                                  View1_test,\n                                  labels_test,\n                                  View2_train[not_removed, :].squeeze(),\n                                  View2_test,\n                                  view2_solver,\n                                  view2_penalty)\n            acc_view1.append(accuracy_view1)\n            acc_view2.append(accuracy_view2)\n            acc_combined.append(accuracy_combined)\n\n        # Multiview\n        gnb0 = LogisticRegression()\n        gnb1 = LogisticRegression(solver=view2_solver, penalty=view2_penalty)\n        ctc = CTClassifier(gnb0, gnb1, num_iter=iters)\n        ctc.fit([View1_train, View2_train], labels_train)\n        y_pred_ct = ctc.predict([View1_test, View2_test])\n        acc_ct[count].append((accuracy_score(labels_test, y_pred_ct)))\n\nacc_view1 = np.mean(acc_view1)\nacc_view2 = np.mean(acc_view2)\nacc_combined = np.mean(acc_combined)\nacc_ct = [sum(row) / float(len(row)) for row in acc_ct]\n\n\n# make a figure from the data\nplt.figure()\nplt.plot(N_iters, acc_view1*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_view2*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_combined*np.ones(N_iters.shape))\nplt.plot(N_iters, acc_ct)\nplt.legend(('View 1', 'View 2', 'Naive Concatenated', 'multiview'))\nplt.ylabel(\"Average Accuracy Over {} Randomizations\".format(randomizations))\nplt.xlabel('Iterations of Co-Training')\nplt.title('When Both Views Have Overlapping Data\\n\\\n    CoTraining Performs with Chance, as Expected')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance as labeled data proportion (essentially sample size) is varied\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data, labels = load_UCImultifeature(select_labeled=[0, 1])\n\n# Use only the first 2 views as an example\nView0, View1 = data[0], data[1]\n\n# Split both views into testing and training\nView0_train, View0_test, labels_train_full, labels_test_full = \\\n    train_test_split(View0, labels, test_size=0.33, random_state=42)\nView1_train, View1_test, labels_train_full, labels_test_full = \\\n    train_test_split(View1, labels, test_size=0.33, random_state=42)\n\n# Do PCA to visualize data\npca = PCA(n_components=2)\nView0_pca = pca.fit_transform(View0_train)\nView1_pca = pca.fit_transform(View1_train)\n\nView0_pca_class0 = View0_pca[np.where(labels_train_full == 0)[0], :]\nView0_pca_class1 = View0_pca[np.where(labels_train_full == 1)[0], :]\nView1_pca_class0 = View1_pca[np.where(labels_train_full == 0)[0], :]\nView1_pca_class1 = View1_pca[np.where(labels_train_full == 1)[0], :]\n\n# plot the views\nplt.figure()\nfig, ax = plt.subplots(1, 2, figsize=(14, 5))\n\nax[0].scatter(View0_pca_class0[:, 0], View0_pca_class0[:, 1])\nax[0].scatter(View0_pca_class1[:, 0], View0_pca_class1[:, 1])\nax[0].set_title(\n    '2 Component PCA of Full View 1 (Fourier Coefficients) Training Data')\nax[0].legend(('Class 0', 'Class 1'))\n\nax[1].scatter(View1_pca_class0[:, 0], View1_pca_class0[:, 1])\nax[1].scatter(View1_pca_class1[:, 0], View1_pca_class1[:, 1])\nax[1].set_title(\n    '2 Component PCA of Full View 2 (Profile Correlations) Training Data')\nax[1].legend(('Class 0', 'Class 1'))\n\nplt.show()\n\n\nN_labeled_full = []\nacc_ct_full = []\nacc_v0_full = []\nacc_v1_full = []\n\niters = 500\n\nfor i, num in zip(np.linspace(0.03, .30, 20),\n                  np.linspace(4, 30, 20).astype(int)):\n\n    N_labeled = []\n    acc_ct = []\n    acc_v0 = []\n    acc_v1 = []\n\n    View0_train, View0_test, labels_train_full, labels_test_full = \\\n        train_test_split(View0, labels, test_size=0.33, random_state=42)\n    View1_train, View1_test, labels_train_full, labels_test_full = \\\n        train_test_split(View1, labels, test_size=0.33, random_state=42)\n\n    for seed in range(iters):\n\n        labels_train = labels_train_full.copy()\n        labels_test = labels_test_full.copy()\n\n        # Randomly remove all but a small percentage of the labels\n        np.random.seed(2*seed)  # 6\n        remove_idx = np.random.rand(len(labels_train),) < 1-i\n        labels_train[remove_idx] = np.nan\n        not_removed = np.where(~remove_idx)[0]\n        not_removed = not_removed[:num]\n        N_labeled.append(len(labels_train[not_removed])/len(labels_train))\n        if len(set(labels_train[not_removed])) != 2:\n            continue\n\n        # Single view semi-supervised learning\n        gnb0 = GaussianNB()\n        gnb1 = GaussianNB()\n\n        # Train on only the examples with labels\n        gnb0.fit(View0_train[not_removed, :].squeeze(),\n                 labels_train[not_removed])\n\n        y_pred0 = gnb0.predict(View0_test)\n        gnb1.fit(View1_train[not_removed, :].squeeze(),\n                 labels_train[not_removed])\n        y_pred1 = gnb1.predict(View1_test)\n\n        acc_v0.append(accuracy_score(labels_test, y_pred0))\n        acc_v1.append(accuracy_score(labels_test, y_pred1))\n\n        # Multi-view co-training semi-supervised learning\n        # Train a CTClassifier on all the labeled and unlabeled training data\n        ctc = CTClassifier()\n        ctc.fit([View0_train, View1_train], labels_train)\n        y_pred_ct = ctc.predict([View0_test, View1_test])\n        acc_ct.append(accuracy_score(labels_test, y_pred_ct))\n\n    acc_ct_full.append(np.mean(acc_ct))\n    acc_v0_full.append(np.mean(acc_v0))\n    acc_v1_full.append(np.mean(acc_v1))\n    N_labeled_full.append(np.mean(N_labeled))\n\n\nmatplotlib.rcParams.update({'font.size': 12})\n\nplt.figure()\nplt.plot(N_labeled_full, acc_v0_full)\nplt.plot(N_labeled_full, acc_v1_full)\nplt.plot(N_labeled_full, acc_ct_full, \"r\")\nplt.legend((\"Fourier Coefficients Only:\\nsklearn Gaussian Naive Bayes\",\n            \"Profile Correlations Only:\\nsklearn Gaussian Naive Bayes\",\n            \"Using Both Views:\\nmultiview CTClassifier (default)\"))\nplt.title(\n    \"Semi-Supervised Classification Accuracy with\\n\\\n        CTClassifier (default Naive Bayes)\")\nplt.xlabel(\"Labeled Data Proportion\")\nplt.ylabel(\"Average Accuracy on Test Data: {} Trials\".format(iters))\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}