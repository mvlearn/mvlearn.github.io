{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multiview Independent Component Analysis (ICA) Comparison\n\nAdopted from the code at\n`https://github.com/hugorichard/multiviewica`_\nand their tutorial written by Hugo Richard and Pierre Ablin.\n\nTwo multiview ICA algorithms are compared. GroupICA concatenates\nthe individual views prior to dimensionality reduction and running\nICA over the result. MultiviewICA performs better by optimizing\nthe set of mixing matrices relative to the average source signal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Hugo Richard, Pierre Ablin\n# License: BSD 3 clause\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom mvlearn.decomposition import MultiviewICA, GroupICA\n\n# sigmas: data noise\n# m: number of subjects\n# k: number of components\n# n: number of samples\nsigmas = np.logspace(-2, 1, 6)\nn_seeds = 3\nm, k, n = 5, 3, 1000\n\ncm = plt.cm.tab20\nalgos = [\n    (\"MultiViewICA\", cm(0), MultiviewICA),\n    (\"GroupICA\", cm(6), GroupICA),\n]\n\n\ndef amari_d(W, A):\n    P = np.dot(A, W)\n\n    def s(r):\n        return np.sum(np.sum(r ** 2, axis=1) / np.max(r ** 2, axis=1) - 1)\n\n    return (s(np.abs(P.T)) + s(np.abs(P))) / (2 * P.shape[1])\n\n\nplots = []\nfor name, color, algo in algos:\n    means = []\n    lows = []\n    highs = []\n    for sigma in sigmas:\n        dists = []\n        for seed in range(n_seeds):\n            rng = np.random.RandomState(seed)\n            S_true = rng.laplace(size=(n, k))\n            A_list = rng.randn(m, k, k)\n            noises = rng.randn(m, n, k)\n            Xs = np.array([S_true.dot(A) for A in A_list])\n            Xs += [sigma * N.dot(A) for A, N in zip(A_list, noises)]\n            if name == 'MultiViewICA':\n                ica = algo(tol=1e-4, max_iter=1000, random_state=0).fit(Xs)\n            elif name == 'GroupICA':\n                ica = algo(ica_kwargs={'tol': 1e-4}, random_state=0).fit(Xs)\n            W = ica.individual_components_\n            dist = np.mean([amari_d(W[i].T, A_list[i]) for i in range(m)])\n            dists.append(dist)\n        dists = np.array(dists)\n        mean = np.mean(dists)\n        low = np.quantile(dists, 0.1)\n        high = np.quantile(dists, 0.9)\n        means.append(mean)\n        lows.append(low)\n        highs.append(high)\n    lows = np.array(lows)\n    highs = np.array(highs)\n    means = np.array(means)\n    plots.append((highs, lows, means))\n\n\nfig = plt.figure(figsize=(5, 3))\nfor i, (name, color, algo) in enumerate(algos):\n    highs, lows, means = plots[i]\n    plt.fill_between(\n        sigmas, lows, highs, color=color, alpha=0.3,\n    )\n    plt.loglog(\n        sigmas, means, label=name, color=color,\n    )\nplt.legend()\nx_ = plt.xlabel(r\"Data noise\")\ny_ = plt.ylabel(r\"Amari distance\")\nfig.tight_layout()\nplt.show()\n\n# MultiviewICA has the best performance (lowest Amari distance)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}