{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Constructing multiple views to classify singleview data\n\nAs demonstrated in \"Asymmetric bagging and random subspace for support vector\nmachines-based relevance feedback in image retrieval\" (Dacheng 2006), in high\ndimensional data it can be useful to subsample the features and construct\nmultiple classifiers on each subsample whose individual predictions are\ncombined using majority vote. This is akin to bagging but concerns the\nfeatures rather than samples and is how random forests are ensembled\nfrom individual decision trees. Here, we apply Linear Discriminant Analysis\n(LDA) to a high dimensional image classification problem and demonstrate\nhow subsampling features can help when the sample size is relatively low.\n\nA variety of possible subsample dimensions are considered, and for each the\nnumber of classifiers (views) is chosen such that their product is equal to\nthe number of features in the singleview data.\n\nTwo subsampling methods are applied. The random subspace method simply selects\na random subset of the features. The random Gaussian projection method creates\nnew features by sampling random multivariate Gaussian vectors used to project\nthe original features. The latter method can potentially help in complicated\nsettings where combinations of features better capture informative relations.\n\nIt is clear that subsampling features in this setting leads to improved\nout-of-sample accuracy, most likely as it reduces overfitting to the large\nnumber of raw features. This is confirmed as the accuracy seems to peak\naround when the number of features is equal to the number of samples, at which\npoint overfitting becomes possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Ronan Perry\n# License: MIT\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score, ShuffleSplit\nfrom sklearn.datasets import fetch_olivetti_faces\nfrom mvlearn.compose import RandomSubspaceMethod, RandomGaussianProjection, \\\n    ViewClassifier\n\n# Load the singleview Olivevetti faces dataset from sklearn\nX, y = fetch_olivetti_faces(return_X_y=True)\n\n# The data has 4096 features. The following subspace dimensions are used\ndims = [16, 64, 256, 1024]\n\n# We are interested in when the low sample size, high dimensionality setting\ntrain_size = 0.2\nrsm_scores = []\nrgp_scores = []\n\n# Initialze cross validation\nsplitter = ShuffleSplit(n_splits=5, train_size=train_size, random_state=0)\n\n# Compute singleview score, using all dimensions\nsingleview_clf = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis())\nsingleview_scores = cross_val_score(singleview_clf, X, y, cv=splitter)\n\n# For each dimension, we compute scores for a multiview classifier\nfor dim in dims:\n    n_views = int(X.shape[1] / dim)\n\n    rsm_clf = make_pipeline(\n            StandardScaler(),\n            RandomSubspaceMethod(n_views=n_views, subspace_dim=dim),\n            ViewClassifier(LinearDiscriminantAnalysis())\n        )\n    rsm_scores.append(cross_val_score(rsm_clf, X, y, cv=splitter))\n\n    rgp_clf = make_pipeline(\n        StandardScaler(),\n        RandomGaussianProjection(n_views=n_views, n_components=dim),\n        ViewClassifier(LinearDiscriminantAnalysis())\n    )\n    rgp_scores.append(cross_val_score(rgp_clf, X, y, cv=splitter))\n\n# The results are plotted\nfig, ax = plt.subplots()\nax.axvline(X.shape[0] * train_size, ls=':', c='grey',\n           label='Number of training samples')\nax.axhline(np.mean(singleview_scores), ls='--', c='grey',\n           label='LDA singleview score')\nax.errorbar(\n    dims, np.mean(rsm_scores, axis=1),\n    yerr=np.std(rsm_scores, axis=1), label='LDA o Random Subspace')\nax.errorbar(\n    dims, np.mean(rgp_scores, axis=1),\n    yerr=np.std(rgp_scores, axis=1), label='LDA o Random Gaussian Projection')\nax.set_xlabel('Number of subsampled dimensions')\nax.set_ylabel('Score')\nplt.title('Classification accuracy using constructed multiview data')\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}