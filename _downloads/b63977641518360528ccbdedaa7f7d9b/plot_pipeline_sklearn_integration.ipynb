{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Integrating mvlearn with scikit-learn\n\n`mvlearn` mimics most of `scikit-learn` API, and integrates seamlessly with\nit. In scikit-learn, a dataset is represented as a 2d array `X` of shape\n`(n_samples, n_features)`. In `mvlearn`, datasets `Xs` are lists of views,\nwhich are themselves 2d arrays of shape `(n_samples, n_features_i)`. The\nnumber of features does not have to be constant:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Pierre Ablin\n# License: MIT\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import FastICA\nfrom sklearn.pipeline import Pipeline\nfrom mvlearn.compose import ViewTransformer, ConcatMerger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 100\nn_features1 = 20\nn_features2 = 30\n\nX1 = np.random.randn(n_samples, n_features1)\nX2 = np.random.randn(n_samples, n_features2)\nXs = [X1, X2]\n\n# Here, `Xs` is a multiview dataset, containing two views. `mvlearn` works\n# with these objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ViewTransformer\n\n`mvlearn.compose.ViewTransformer` is a handy tool to apply the same\n`sklearn` transformer to each view of the multiview dataset. For instance, it\nis simple to apply PCA to each view. In the following, we reduce the\ndimension of each view to 3:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=3)\nmvpca = ViewTransformer(pca)\nXs_transformed = mvpca.fit_transform(Xs)\nprint(len(Xs_transformed))\nprint([X.shape for X in Xs_transformed])\n\n# The PCA is applied to each view with the `mvpca` transformer, and the output\n# of PCA, `Xs_transformed`, is a multiview dataset, where each view now has\n# `3`features.\n#\n# Importantly, it is possible to apply a different transform to each view, by\n# passing a list to `ViewTransformer`. For instance, if we want to keep 5\n# components in the second dataset, we can do:\n\n\npca2 = PCA(n_components=5)\nmvpca = ViewTransformer([pca, pca2])\nXs_transformed = mvpca.fit_transform(Xs)\nprint(len(Xs_transformed))\nprint([X.shape for X in Xs_transformed])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mergers\n\nAt the end of a multiview machine learning pipeline, it is sometimes needed\nto transform the multiview dataset in a single view dataset. All `sklearn`\nmethods can then be used on this single view dataset. Mergers make this task\nsimple.\n\nA simple way to transform a multiview dataset in a single view dataset is\nsimply by stacking each features. The class\n`mvlearn.compose.ConcatMerger` implements this:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "merge = ConcatMerger()\n\nX_transformed = merge.fit_transform(Xs)\nprint(X_transformed.shape)\n\n# This allows for simple integration in scikit-learn pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Example: group-ICA\n\nAs a simple illustration, we now show how easy it is to code group\nindependent component analysis (groupICA) from scratch using `mvlearn`.\n\nWe use the group ICA of *Calhoun et al. \"A method for making group\ninferences from functional MRI data using independent component analysis.\",\nHuman Brain Mapping 14.3 (2001): 140-151.* as reference.\n\nGroupICA takes a multiview dataset, and tries to extract from it some shared\nindependent sources. In its usual formulation, it consists of three simple\nsteps:\n\n- Apply an individual PCA to each view\n- Concatenate the features of each view\n- Apply usual ICA on the concatenated features\n\nThis is easily implemented using `mvlearn` and scikit-learn pipelines:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_components = 2\nindividual_pca = ViewTransformer(PCA(n_components=n_components))\nmerge = ConcatMerger()\nica = FastICA(n_components=n_components)\n\ngroupica = Pipeline([('individual pca', individual_pca),\n                     ('concatenate', merge),\n                     ('ica', ica)])\n\nX_transformed = groupica.fit_transform(Xs)\nprint(X_transformed.shape)\n\n# Here, `Xs` contains Gaussian noise, so nothing of value is extracted.\n# However, if each view consists of a linear transform of some independent\n# sources, it works as intended:\n\n\ntime = np.linspace(0, 1, 1000)\nsource1 = np.cos(20 * time)\nsource2 = np.sin(50 * time)\nS = np.c_[source1, source2]\nA1 = np.random.randn(3, 2)\nA2 = np.random.randn(4, 2)\nX1 = np.dot(S, A1.T) + .1 * np.random.randn(1000, 3)\nX2 = np.dot(S, A2.T) + .1 * np.random.randn(1000, 4)\nXs = [X1, X2]\nplt.figure()\nplt.plot(time, source1, time, source2)\nplt.title('Sources')\n\nplt.figure()\nfor x in X1.T:\n    plt.plot(time, x)\nplt.title('signals')\n\nX_transformed = groupica.fit_transform(Xs)\n\nfor x in X_transformed.T:\n    plt.plot(time, x)\nplt.title('recovered signals')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}