{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Conditional Independence of Views on Multiview Spectral Clustering\n\nThe co-training framework relies on the fundamental assumption that data\nviews are conditionally independent. In this tutorial we test that\nassumption by examining the multiview spectral clustering algorithm,\nwhich is based on the co-training framework, on synthetic multiview\ndatasets under different conditions related to independence\nbetween the views conditioned on true class labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: MIT\n\nimport numpy as np\nimport scipy as scp\nfrom mvlearn.cluster.mv_spectral import MultiviewSpectralClustering\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.metrics import normalized_mutual_info_score as nmi_score\nfrom sklearn.datasets import fetch_covtype\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nRANDOM_SEED = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Artificial dataset withconditional independence assumption between views\n\nHere, we create an artificial dataset where the conditional independence\nassumption between\nviews, given the true labels, is enforced. Our artificial dataset is derived\nfrom the forest\ncovertypes dataset from the scikit-learn package. This dataset is comprised\nof 7 different classes, with\nwith 54 different numerical features per sample. To create our artificial\ndata, we will select 500 samples from\neach of the first 6 classes in the dataset, and from these, construct 3\nartificial classes with\n2 views each.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_ci_data(num_samples=500):\n    # Load in the vectorized news group data from scikit-learn package\n    cov = fetch_covtype()\n    all_data = np.array(cov.data)\n    all_targets = np.array(cov.target)\n\n    # Set class pairings as described in the multiview clustering paper\n    view1_classes = [1, 2, 3]\n    view2_classes = [4, 5, 6]\n\n    # Create lists to hold data and labels for each of the classes across\n    # 2 different views\n    labels = [num for num in range(len(view1_classes))\n              for _ in range(num_samples)]\n    labels = np.array(labels)\n    view1_data = list()\n    view2_data = list()\n\n    # Randomly sample items from each of the selected classes in view1\n    for class_num in view1_classes:\n        class_data = all_data[(all_targets == class_num)]\n        indices = np.random.choice(class_data.shape[0], num_samples)\n        view1_data.append(class_data[indices])\n    view1_data = np.concatenate(view1_data)\n\n    # Randomly sample items from each of the selected classes in view2\n    for class_num in view2_classes:\n        class_data = all_data[(all_targets == class_num)]\n        indices = np.random.choice(class_data.shape[0], num_samples)\n        view2_data.append(class_data[indices])\n    view2_data = np.concatenate(view2_data)\n\n    # Shuffle and normalize vectors\n    shuffled_inds = np.random.permutation(num_samples * len(view1_classes))\n    view1_data = np.vstack(view1_data)\n    view2_data = np.vstack(view2_data)\n    view1_data = view1_data[shuffled_inds]\n    view2_data = view2_data[shuffled_inds]\n    magnitudes1 = np.linalg.norm(view1_data, axis=0)\n    magnitudes2 = np.linalg.norm(view2_data, axis=0)\n    magnitudes1[magnitudes1 == 0] = 1\n    magnitudes2[magnitudes2 == 0] = 1\n    magnitudes1 = magnitudes1.reshape((1, -1))\n    magnitudes2 = magnitudes2.reshape((1, -1))\n    view1_data /= magnitudes1\n    view2_data /= magnitudes2\n    labels = labels[shuffled_inds]\n    return [view1_data, view2_data], labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a function to perform both singleview and multiview clustering\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def perform_clustering(seed, m_data, labels, n_clusters):\n\n    # Singleview spectral clustering\n    # Cluster each view separately\n    s_spectral = SpectralClustering(\n        n_clusters=n_clusters, random_state=RANDOM_SEED, n_init=100)\n    s_clusters_v1 = s_spectral.fit_predict(m_data[0])\n    s_clusters_v2 = s_spectral.fit_predict(m_data[1])\n\n    # Concatenate the multiple views into a single view\n    s_data = np.hstack(m_data)\n    s_clusters = s_spectral.fit_predict(s_data)\n\n    # Compute nmi between true class labels and singleview cluster labels\n    s_nmi_v1 = nmi_score(labels, s_clusters_v1)\n    s_nmi_v2 = nmi_score(labels, s_clusters_v2)\n    s_nmi = nmi_score(labels, s_clusters)\n    print('Singleview View 1 NMI Score: {0:.3f}\\n'.format(s_nmi_v1))\n    print('Singleview View 2 NMI Score: {0:.3f}\\n'.format(s_nmi_v2))\n    print('Singleview Concatenated NMI Score: {0:.3f}\\n'.format(s_nmi))\n\n    # Multiview spectral clustering\n    # Use the MultiviewSpectralClustering instance to cluster the data\n    m_spectral = MultiviewSpectralClustering(\n        n_clusters=n_clusters, random_state=RANDOM_SEED, n_init=100)\n    m_clusters = m_spectral.fit_predict(m_data)\n\n    # Compute nmi between true class labels and multiview cluster labels\n    m_nmi = nmi_score(labels, m_clusters)\n    print('Multiview Concatenated NMI Score: {0:.3f}\\n'.format(m_nmi))\n\n    return m_clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a function to display data and the results of clustering\nThe following function plots both views of data given a dataset and\ncorresponding labels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def display_plots(pre_title, data, labels):\n\n    # plot the views\n    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n    dot_size = 10\n    ax[0].scatter(new_data[0][:, 0], new_data[0][:, 1], c=labels, s=dot_size)\n    ax[0].set_title(pre_title + ' View 1')\n    ax[0].axes.get_xaxis().set_visible(False)\n    ax[0].axes.get_yaxis().set_visible(False)\n\n    ax[1].scatter(new_data[1][:, 0], new_data[1][:, 1], c=labels, s=dot_size)\n    ax[1].set_title(pre_title + ' View 2')\n    ax[1].axes.get_xaxis().set_visible(False)\n    ax[1].axes.get_yaxis().set_visible(False)\n\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing the performance with conditionally independent views\n\nThe co-training framework relies on the fundamental assumption that data\nviews are conditionally independent. If all views are informative and\nconditionally independent, then Multiview Spectral Clustering is expected to\nproduce higher quality clusters than Singleview Spectral Clustering, for\neither view or for both views concatenated together. Here, we will evaluate\nthe quality of clusters by using the normalized mutual information metric,\nwhich is essentially a measure of the purity of clusters with respect to the\ntrue underlying class labels.\n\nAs we see below, Multiview Spectral Clustering produces clusters with lower\npurity than those produced by Singleview Spectral clustering on the\nconcatenated views, which is surprising.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data, labels = get_ci_data()\nm_clusters = perform_clustering(RANDOM_SEED, data, labels, 3)\n\n# Running TSNE to display clustering results via low dimensional embedding\ntsne = TSNE()\nnew_data = list()\nnew_data.append(tsne.fit_transform(data[0]))\nnew_data.append(tsne.fit_transform(data[1]))\ndisplay_plots('True Labels', new_data, labels)\ndisplay_plots('Multiview Clustering Results', new_data, m_clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Artificial dataset with conditionally dependent views\n\nHere, we create an artificial dataset where the conditional independence\nassumption between\nviews, given the true labels, is violated. We again derive our dataset from\nthe forest covertypes\ndataset from sklearn. However, this time, we use only the first 3 classes of\nthe dataset, which will\ncorrespond to the 3 clusters for view 1. To produce view 2, we will apply a\nsimple nonlinear transformation to view 1\nusing the logistic function, and we will apply a negligible amount of noise\nto the second view to avoid convergence\nissues. This will result in a dataset where the correspondance between views\nis very high.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_cd_data(num_samples=500):\n\n    # Load in the vectorized news group data from scikit-learn package\n    cov = fetch_covtype()\n    all_data = np.array(cov.data)\n    all_targets = np.array(cov.target)\n\n    # Set class pairings as described in the multiview clustering paper\n    view1_classes = [1, 2, 3]\n\n    # Create lists to hold data and labels for each of the classes across\n    # 2 different views\n    labels = [num for num in range(len(view1_classes))\n              for _ in range(num_samples)]\n    labels = np.array(labels)\n    view1_data = list()\n    view2_data = list()\n\n    # Randomly sample 500 items from each of the selected classes in view1\n    for class_num in view1_classes:\n        class_data = all_data[(all_targets == class_num)]\n        indices = np.random.choice(class_data.shape[0], num_samples)\n        view1_data.append(class_data[indices])\n    view1_data = np.concatenate(view1_data)\n\n    # Construct view 2 by applying a nonlinear transformation\n    # to data from view 1 comprised of a linear transformation\n    # and a logistic nonlinearity\n    t_mat = np.random.random((view1_data.shape[1], 50))\n    noise = 0.005 - 0.01*np.random.random((view1_data.shape[1], 50))\n    t_mat *= noise\n    transformed = view1_data @ t_mat\n    view2_data = scp.special.expit(transformed)\n\n    # Shuffle and normalize vectors\n    shuffled_inds = np.random.permutation(num_samples * len(view1_classes))\n    view1_data = np.vstack(view1_data)\n    view2_data = np.vstack(view2_data)\n    view1_data = view1_data[shuffled_inds]\n    view2_data = view2_data[shuffled_inds]\n    magnitudes1 = np.linalg.norm(view1_data, axis=0)\n    magnitudes2 = np.linalg.norm(view2_data, axis=0)\n    magnitudes1[magnitudes1 == 0] = 1\n    magnitudes2[magnitudes2 == 0] = 1\n    magnitudes1 = magnitudes1.reshape((1, -1))\n    magnitudes2 = magnitudes2.reshape((1, -1))\n    view1_data /= magnitudes1\n    view2_data /= magnitudes2\n    labels = labels[shuffled_inds]\n    return [view1_data, view2_data], labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing the performance with conditionally dependent views\n\nAs mentioned before, the co-training framework relies on the fundamental\nassumption that data views are conditionally independent. Here, we will again\ncompare the performance of singleview and multiview spectral clustering\nusing the same methods as before, but on our conditionally dependent dataset.\n\nAs we see below, Multiview Spectral Clustering does not beat the best\nSingleview spectral clustering performance with respect to purity, since that\nthe views are conditionally dependent.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data, labels = get_cd_data()\nm_clusters = perform_clustering(RANDOM_SEED, data, labels, 3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}