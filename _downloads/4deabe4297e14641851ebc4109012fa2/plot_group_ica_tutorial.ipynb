{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# ICA: a tutorial\n\nAuthor: Pierre Ablin\n\nGroup ICA extends the celebrated Independent Component Analysis to multiple\ndatasets.\n\nSingle view ICA decomposes a dataset $X$ as\n$X = S \\times A^{\\top}$, where $S$ are the independent\nsources (meaning that the columns of $S$ are independent),\nand $A$ is the mixing matrix.\n\nIn group ICA, we have several views $Xs = [X_1, \\dots, X_n]$.\nEach view is obtained as\n\n\\begin{align}X_i \\simeq S \\times A_i.T\\end{align}\n\nso the views share the same sources $S$, but have different mixing\nmatrices $A_i$. It is a powerful tool for group inference, as it\nallows to extract signals that are comon across views.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: MIT\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mvlearn.decomposition import GroupICA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a Function to Plot Sources\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_sources(S):\n    n_samples, n_sources = S.shape\n    fig, axes = plt.subplots(n_sources, 1, figsize=(6, 4), sharex=True)\n    for ax, sig in zip(axes, S.T):\n        ax.plot(sig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Independent Sources and Generate Noisy Observations\n\nDefine indepdent sources. Next, generate some views, which are noisy\nobservations of linear transforms of these sources.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\nn_samples = 2000\ntime = np.linspace(0, 8, n_samples)\n\ns1 = np.sin(2 * time) * np.sin(40 * time)\ns2 = np.sin(3 * time) ** 5\ns3 = np.random.laplace(size=s1.shape)\n\nS = np.c_[s1, s2, s3]\n\nplot_sources(S)\n\nn_views = 10\nmixings = [np.random.randn(3, 3) for _ in range(n_views)]\nXs = [np.dot(S, A.T) + 0.3 * np.random.randn(n_samples, 3) for A in mixings]\n\n# We can visualize one dataset: it looks quite messy.\nplot_sources(Xs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Group ICA\n\nNext, we can apply group ICA. The option `multiview_output=False` means that\nwe want to recover the estimated sources when we do `.transform`. Here, we\nlook at what the algorithm estimates as the sources from the multiview\ndata.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "groupica = GroupICA(multiview_output=False).fit(Xs)\n\nestimated_sources = groupica.transform(Xs)\nplot_sources(estimated_sources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Estimated Mixings\n\nWe see they look pretty good! We can also wheck that it has correctly\npredicted each mixing matrix. The estimated mixing matrices are stored in\nthe `.individual_mixing_` attribute.\n\nIf $\\tilde{A}$ is the estimated mixing matrix and $A$ is the\ntrue mixing matrix, we can look at $\\tilde{A}^{-1}A$. It should be\nclose to a scale and permuation matrix: in this case, the sources are\ncorrectly estimated, up to scale and permutation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimated_mixings = groupica.individual_mixing_\n\nplt.matshow(np.dot(np.linalg.pinv(estimated_mixings[0]), mixings[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Group ICA on Only 2 Views\n\nA great advantage of groupICA is that it leverages the multiple views to\nreduce noise. For instance, if only had two views, we would have obtained\nthe following.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimated_sources = groupica.fit_transform(Xs[:2])\nplot_sources(estimated_sources)\n\n# Another important property of group ICA is that it can recover signals that\n# are common to all datasets, and separate these signals from the rest.\n# Imagine that we only have one common source across datasets:\n\n\ncommon_source = S[:, 0]\nmixings = np.random.randn(n_views, 3)\nXs = [a * common_source[:, None] + 0.3 * np.random.randn(n_samples, 3)\n      for a in mixings]\n\n\nestimated_sources = groupica.fit_transform(Xs)\nplot_sources(estimated_sources)\n\n# It recovers the common source on one channel, and the other estimated\n# sources are noise."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}