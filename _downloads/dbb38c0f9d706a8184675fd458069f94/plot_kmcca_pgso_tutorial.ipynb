{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Partial Gram-Schmidt Orthogonalization (PGSO) for KMCCA\n\nKernel matrices grow exponentially with the size of the data. There are\nimmense storage and run-time constraints that arise when working with large\ndatasets. The partial Gram-Schmidt orthogonalization (PGSO) finds a low-rank\napproximation of the Cholesky decomposition of the kernel matrix. This\nreduces storage requirements from O(n^2) to O(nm), where n is the number of\nsubjects (rows) and m is the rank of the kernel matrix. This also reduces the\nrun-time from O(n^3) to O(nm^2).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Ronan Perry, Theodore Lee\n# License: MIT\n\nimport timeit\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mvlearn.plotting.plot import crossviews_plot\nfrom mvlearn.embed import KMCCA\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndef make_data(N, seed=None):\n    np.random.seed(seed)\n    t = np.random.uniform(-np.pi, np.pi, N)\n    e1 = np.random.normal(0, 0.1, (N, 2))\n    e2 = np.random.normal(0, 0.1, (N, 2))\n\n    X1 = np.zeros((N, 2))\n    X1[:, 0] = t\n    X1[:, 1] = np.sin(3*t)\n    X1 += e1\n\n    X2 = np.zeros((N, 2))\n    X2[:, 0] = np.exp(t/4)*np.cos(2*t)\n    X2[:, 1] = np.exp(t/4)*np.sin(2*t)\n    X2 += e2\n\n    return [X1, X2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full Decomposition vs PGSO on Sample Data\n\nPGSO is run on two views of data that each have two dimensions that are\nsinuisoidally related. The data has 100 samples and thus the fully decomposed\nkernel matrix would have dimensions (100, 100). PSGO finds an approximation\nwith lower rank at the given tolerance of 0.5 to the full kernel matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Xs_train = make_data(100, seed=1)\nXs_test = make_data(200, seed=2)\n\n\ncrossviews_plot(Xs_test, ax_ticks=False, ax_labels=True, equal_axes=True,\n                title='Raw 2 view Gaussian data crossplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full Decomposition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kmcca = KMCCA(kernel=\"rbf\", n_components=2, regs=0.01)\nscores = kmcca.fit(Xs_train).transform(Xs_test)\n\ncrossviews_plot(scores, ax_ticks=False, ax_labels=True, equal_axes=True,\n                title='KMCCA scores (full decomposition)')\n\ncorrs = kmcca.canon_corrs(scores)\n\nprint(\"The first two canonical correlations are \"\n      f\"[{corrs[0]:.3f}, {corrs[1]:.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PGSO Decomposition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kmcca = KMCCA(kernel=\"rbf\", n_components=2, regs=0.01, pgso=True)\nscores = kmcca.fit(Xs_train).transform(Xs_test)\n\ncrossviews_plot(scores, ax_ticks=False, ax_labels=True, equal_axes=True,\n                title='KMCCA scores (PGSO decomposition)')\n\ncorrs = kmcca.canon_corrs(scores)\n\nprint(\"The first two canonical correlations are \"\n      f\"[{corrs[0]:.3f}, {corrs[1]:.3f}], at ranks \"\n      f\"{kmcca.pgso_ranks_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PGSO Tolerance vs. Canonical Correlation and Rank\n\nWe can observe the relationship between the PGSO tolerance and canonical\ncorrelation of the first canonical component as well as the approximation\nrank.\n\nWe observe that at tol=0.1, the mean rank is approximately 15 and yet we\nachieve similarly high canonical correlation as with the full kernel matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "canon_corrs = []\nranks = []\ntols = [0, 0.001, 0.005, 0.01, 0.02, 0.1, 1]\nfor p in tols:\n    kmcca = KMCCA(kernel=\"rbf\", n_components=2, regs=0.01, pgso=True,\n                  tol=p)\n    scores = kmcca.fit(Xs_train).transform(Xs_test)\n    corrs = kmcca.canon_corrs(scores)\n    canon_corrs.append(corrs[0])\n    ranks.append(np.mean(kmcca.pgso_ranks_))\n\nfig, ax1 = plt.subplots()\n\ncolor = 'tab:blue'\nax1.set_ylabel('Mean PGSO rank', color=color)\nax1.set_xlabel('Tolerance')\nax1.plot(tols, ranks, color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.axvline(0.1, ls='--', c='grey')\n\ncolor = 'tab:red'\nax2 = ax1.twinx()\nax2.set_ylabel('First cannonical correlation', color=color)\nax2.plot(tols, canon_corrs, color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nplt.title('PGSO canonical correlations across tolerances')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PGSO Tolerance vs. Runtime and Rank\n\nWe can observe the relationship between the PGSO tolerance and the run-time\nfit and transform the two views (separately). We average the run-time of each\nrank over multiple trials.\n\nFrom the rank vs canonical correlation analysis in the previous section, we\ndiscovered that a tolerance of 0.1 will preserve the canonical correlation\n(accuracy). We also see here that we can get an order of magnitude\ndecrease in run-time compared to the full decomposition (tolerance 0).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "runtimes = []\nranks = []\nfor p in tols:\n    kmcca = KMCCA(kernel=\"rbf\", n_components=2, regs=0.01, pgso=True,\n                  tol=p)\n    runtime = timeit.timeit(\n        lambda: kmcca.fit(Xs_train).transform(Xs_test), number=10)\n    runtimes.append(runtime)\n    ranks.append(np.mean(kmcca.pgso_ranks_))\n\nfig, ax1 = plt.subplots()\n\ncolor = 'tab:blue'\nax1.set_ylabel('Mean PGSO rank', color=color)\nax1.set_xlabel('Tolerance')\nax1.plot(tols, ranks, color=color)\nax1.tick_params(axis='y', labelcolor=color)\n\ncolor = 'tab:red'\nax2 = ax1.twinx()\nax2.set_ylabel('Runtime', color=color)\nax2.plot(tols, runtimes, color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nplt.title('PGSO runtimes across tolerances')\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}