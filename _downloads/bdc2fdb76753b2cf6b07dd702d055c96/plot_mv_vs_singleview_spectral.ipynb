{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multiview vs. Singleview Spectral Clustering of UCI Multiview Digits\n\nHere, we directly compare multiview methods available within *mvlearn* to\nanalagous singleview methods. Using the UCI Multiple Features Dataset, we\nfirst examine the dataset by viewing it after using dimensionality reduction\ntechniques, then we perform unsupervised clustering and compare the results to\nthe analagous singleview methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Gavin Mischler, Ronan Perry\n#\n# License: MIT\n\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.metrics import homogeneity_score\nfrom mvlearn.cluster import MultiviewSpectralClustering\nfrom mvlearn.embed import MVMDS\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix\nfrom mvlearn.datasets import load_UCImultifeature\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and visualize the multiple handwritten digit views\n\nWe load a 6-view, 4-class dataset from the Multiple Features Dataset. Each\nof the six views are as follows:\n    1. 76 Fourier coefficients of the character shapes\n    2. 216 profile correlations\n    3. 64 Karhunen-Love coefficients\n    4. 240 pixel averages of the images from 2x3 windows\n    5. 47 Zernike moments\n    6. 6 morphological features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Xs, y = load_UCImultifeature(select_labeled=[0, 1, 2, 3])\nview_names = ['Fourier\\nCoefficients', 'Profile\\nCorrelations',\n              'Karhunen-\\nLoeve', 'Pixel\\nAverages',\n              'Zernike\\nMoments', 'Morphological\\nFeatures']\n\norder = np.argsort(y)\nsub_samp = np.arange(0, Xs[0].shape[0], step=3)\n\nfig, axes = plt.subplots(1, 6, figsize=(8, 4))\nfor i, view in enumerate(Xs):\n    sorted_view = view[order, :].copy()\n    sorted_view = sorted_view[sub_samp, :]\n\n    # Scale features in each view to [0, 1]\n    minim = np.min(sorted_view, axis=0)\n    maxim = np.max(sorted_view, axis=0)\n    sorted_view = (sorted_view - minim) / (maxim - minim)\n\n    pts = axes[i].imshow(\n        sorted_view, cmap='Spectral_r', aspect='auto', vmin=0, vmax=1)\n\n    axes[i].set_title(view_names[i], fontsize=12)\n    axes[i].set_yticks([])\n    max_dim = view.shape[1]\n    axes[i].set_xticks([max_dim-1])\n    axes[i].set_xticklabels([str(max_dim)])\n\ndivider = make_axes_locatable(axes[-1])\ncax = divider.append_axes(\"right\", size=\"20%\", pad=0.1)\nplt.colorbar(pts, cax=cax)\nfig.text(0.5, 0, 'Features in each view', ha='center')\naxes[0].set_ylabel('Samples')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing dimensionality reduction techniques\n\nAs one might do with a new dataset, we first visualize the data in 2\ndimensions. The naive approach using singleview method would be to\nconcatenate the views and apply PCA. Ung the multiview Multi-dimensional\nScaling (:class:`mvlearn.embed.MVMDS`) available in the package we can\njointly embed the views to find their common principal components across\nviews.\n\nA visual inspection of the resulting embeddings see that MVMDS better\nfinds four separate groups. With PCA, it is less clear how many clusters\nthere are in the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Xs_mvmds = MVMDS(n_components=2).fit_transform(Xs)\nXs_pca = PCA(n_components=2).fit_transform(np.hstack(Xs))\n\nsca_kwargs = {'s': 10, 'color': 'darkgray'}\nf, axes = plt.subplots(1, 2, figsize=(8, 4))\naxes[0].scatter(Xs_pca[:, 0], Xs_pca[:, 1], **sca_kwargs)\naxes[0].set_title('PCA embedding (concatenated)', fontsize=14)\naxes[0].set_xlabel('PCA Component 1')\naxes[0].set_ylabel('PCA Component 2')\naxes[1].scatter(Xs_mvmds[:, 0], Xs_mvmds[:, 1], **sca_kwargs)\naxes[1].set_title('MVMDS embedding (multiview)', fontsize=14)\naxes[1].set_xlabel('MVMDS Component 1')\naxes[1].set_ylabel('MVMDS Component 2')\nplt.setp(axes, xticks=[], yticks=[])\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing clustering techniques\n\nNow, assuming we are trying to group the samples into 4 clusters (as was\nmuch more obvious after using *mvlearn*'s MVMDS dimensionality reduction\nmethod), we compare multiview spectral clustering\n(:class:`mvlearn.cluster.MultiviewSpectralClustering`) to its singleview\nspectral clustering on the concatenated data. For multiview\nclustering, we use all 6 full views of data (not the dimensionality-reduced\ndata). For singleview clustering, we concatenate these 6 full views into a\nsingle large matrix, the same as what we did before for PCA.\n\nThe true and predicted cluster labels are plotted on the prior reduced\ndimensionality embeddings. Since we have the true class labels, we assess\nthe clustering accuracy with a homogeneity score. The multiview clustering\nclearly dominates its singleview approach.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def rearrange_labels(y_true, y_pred):\n    \"\"\"\n    Rearranges labels among groups for better visual comparison\n    \"\"\"\n    conf_mat = confusion_matrix(y_true, y_pred)\n    maxes = np.argmax(conf_mat, axis=0)\n    y_pred_new = np.zeros_like(y_pred)\n    for i, new in enumerate(maxes):\n        y_pred_new[y_pred == i] = new\n    return y_pred_new\n\n\ndef plot_clusters(Xs, y_true, y_predicted, title, method):\n    y_predicted = rearrange_labels(y, y_predicted)\n    score = homogeneity_score(y, y_predicted)\n\n    sca_kwargs = {'alpha': 0.7, 's': 10}\n    f, axes = plt.subplots(1, 2, figsize=(8, 4))\n    axes[0].scatter(Xs[:, 0], Xs[:, 1], c=y_true, **sca_kwargs)\n    axes[0].set_title('True labels', fontsize=14)\n    axes[1].scatter(Xs[:, 0], Xs[:, 1], c=y_predicted, **sca_kwargs)\n    axes[1].set_title(title, fontsize=14)\n    axes[1].annotate(\n        f'Homogeneity\\nscore = {score:.2f}', xy=(0.95, 0.85),\n        xycoords='axes fraction', fontsize=13, ha='right')\n    axes[0].set_ylabel(f'{method} Component 2')\n    plt.setp(axes, xticks=[], yticks=[], xlabel=f'{method} Component 1')\n    plt.tight_layout()\n    plt.show()\n\n\n# Cluster concatenated data\nsv_clust = SpectralClustering(n_clusters=4, affinity='nearest_neighbors')\nsv_labels = sv_clust.fit_predict(np.hstack(Xs))\n\nplot_clusters(Xs_pca, y, sv_labels, 'Concatenated clustering labels', 'PCA')\n\n# Cluster multiview data\nmv_clust = MultiviewSpectralClustering(\n    n_clusters=4, affinity='nearest_neighbors')\nmv_labels = mv_clust.fit_predict(Xs)\n\nplot_clusters(Xs_mvmds, y, mv_labels, 'Multiview clustering labels', 'MVMDS')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}