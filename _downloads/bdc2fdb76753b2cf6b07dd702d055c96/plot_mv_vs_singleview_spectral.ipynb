{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multiview vs. Singleview Spectral Clustering of UCI Multiview Digits\n\nHere, we directly compare multiview methods available within *mvlearn* to\nanalagous singleview methods. Using the UCI Multiple Features Dataset, we\nfirst examine the dataset by viewing it after using dimensionality reduction\ntechniques, then we perform unsupervised clustering and compare the results to\nthe analagous singleview methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: MIT\n\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.metrics import homogeneity_score\nfrom mvlearn.cluster import MultiviewSpectralClustering\nfrom sklearn.decomposition import PCA\nfrom mvlearn.plotting import quick_visualize\nfrom sklearn.metrics import confusion_matrix\nfrom mvlearn.datasets import load_UCImultifeature\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load 6-view, 4-class data from the Multiple Features Dataset. The full 6\n# views with all features will be used for clustering.\n\n# Load 4-class, multiview data\nXs, y = load_UCImultifeature(select_labeled=[0, 1, 2, 3])\n#     Six views of handwritten digit images\n#     1. 76 Fourier coefficients of the character shapes\n#     2. 216 profile correlations\n#     3. 64 Karhunen-Love coefficients\n#     4. 240 pixel averages of the images from 2x3 windows\n#     5. 47 Zernike moments\n#     6. 6 morphological features\nview_names = ['Fourier\\nCoefficients', 'Profile\\nCorrelations',\n              'Karhunen-\\nLoeve', 'Pixel\\nAverages',\n              'Zernike\\nMoments', 'Morphological\\nFeatures']\n\norder = np.argsort(y)\nsub_samp = np.arange(0, Xs[0].shape[0], step=3)\nset_aspect = 'equal'\nset_cmap = 'Spectral'\n\nfor i, view in enumerate(Xs):\n    sorted_view = view[order, :].copy()\n    sorted_view = sorted_view[sub_samp, :]\n    if set_aspect == 'auto':\n        plt.figure(figsize=(1.5, 4.5))\n    else:\n        plt.figure()\n\n    # Scale matrix to [0, 1]\n    minim = np.min(sorted_view)\n    maxim = np.max(sorted_view)\n    sorted_view = (sorted_view - minim) / (maxim - minim)\n\n    plt.imshow(sorted_view, cmap=set_cmap, aspect=set_aspect)\n    plt.title(view_names[i], fontsize=14)\n    plt.yticks([], \"\")\n    max_dim = view.shape[1]\n    plt.xticks([max_dim-1], [str(max_dim)])\n    if i == 0:\n        plt.ylabel('Samples')\n    if i == 5:\n        plt.colorbar()\n    plt.xlabel('Features')\n    plt.show()\n\n# Define a function to rearrange the predicted labels so that the predicted\n# class '0' corresponds better to the true class '0'. This is only used so that\n# the colors generated by the labels in the prediction plots can be more easily\n# compared to the true labels.\n\n\ndef rearrange_labels(y_true, y_pred):\n    conf_mat = confusion_matrix(y_true, y_pred)\n    maxes = np.argmax(conf_mat, axis=0)\n    y_pred_new = np.zeros_like(y_pred)\n    for i, new in enumerate(maxes):\n        y_pred_new[y_pred == i] = new\n    return y_pred_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Dimensionality Reduction Techniques\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# As one might do with a new dataset, we first visualize the data in 2\n# dimensions. For multiview data, rather than using PCA, we use Multiview\n# Multi-dimensional Scaling (MVMDS) available in the package to capture the\n# common principal components across views. This is performed automatically\n# within the quick_visualize function. From the unlabeled plot, it is clear\n# that there may be 4 underlying clusters, so unsupervised clustering with 4\n# clusters may be a natural next step in analyzing this data.\n\n\n# Use all 6 views available to reduce the dimensionality, since MVMDS is not\n# limited\nsca_kwargs = {'alpha': 0.7, 's': 10}\n\nquick_visualize(Xs, title=\"Unlabeled\", ax_ticks=False,\n                ax_labels=False, scatter_kwargs=sca_kwargs)\nquick_visualize(Xs, labels=y, title=\"True Labels\", ax_ticks=False,\n                ax_labels=False, scatter_kwargs=sca_kwargs)\n\n# As a comparison, we concatenate the views and use PCA to reduce the\n# dimensionality. From the unlabeled plot, it is much less clear how many\n# underlying classes there are, so PCA was not as useful for visualizing the\n# data if our goal was to determine underlying clusters.\n\n\n# Concatenate views to get naive single view\nX_viewing = np.hstack([Xs[i] for i in range(len(Xs))])\n\n# Use PCA for dimensionality reduction on the naive single view\npca = PCA(n_components=2)\npca_X = pca.fit_transform(X_viewing)\n\nplt.figure(figsize=(5, 5))\nplt.scatter(pca_X[:, 0], pca_X[:, 1], **sca_kwargs)\nplt.xticks([], [])\nplt.yticks([], [])\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.title(\"Unlabeled\")\nplt.show()\n\nplt.figure(figsize=(5, 5))\nplt.scatter(pca_X[:, 0], pca_X[:, 1], c=y, **sca_kwargs)\nplt.xticks([], [])\nplt.yticks([], [])\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.title(\"True Labels\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Clustering Techniques using the Full Feature Space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now, assuming we are trying to group the samples into 4 clusters (as was\n# much more obvious after using *mvlearn*'s dimensionality reduction viewing\n# method), we compare multiview clustering techniques to singleview\n# counterparts. Specifically, we compare 6view spectral clustering in *mvlearn*\n# with single view spectral clustering from *scikit-learn*. For multiview\n# clustering, all 6 full views of data (not the dimensionality-reduced data).\n# For singleview comparison, we concatenate these 6 full views into a single\n# large matrix, the same as what we did before for PCA.\n#\n# Since we have the true class labels, we assess the clustering accuracy with\n# a homogeneity score.\n\n\nmv_clust = MultiviewSpectralClustering(\n    n_clusters=4, affinity='nearest_neighbors')\nmvlearn_cluster_labels = mv_clust.fit_predict(Xs)\n\n# Test the accuracy of the clustering\nmv_score = homogeneity_score(y, mvlearn_cluster_labels)\nprint('Multiview homogeneity score: {0:.3f}'.format(mv_score))\n\n# Use function defined at beginning of notebook to rearrange the labels\n# for easier visual comparison to true labeled plot\nmvlearn_cluster_labels = rearrange_labels(y, mvlearn_cluster_labels)\n\n# Visualize the clusters in the 2-dimensional space\nquick_visualize(Xs, labels=mvlearn_cluster_labels, title=\"Predicted Clusters\",\n                ax_ticks=False, ax_labels=False, scatter_kwargs=sca_kwargs)\n\n# To compare to singleview methods, we concatenate the 6 views we used for\n# co-clustering into one data matrix, and then perform spectral clustering\n# using the *scikit-learn* library. From the figure and cluster scores that are\n# produced, we can see that singleview spectral clustering is unable to perform\n# as well as the multiview version.\n\n\n# Concatenate views and cluster\nX_clustering = X_viewing\nclust = SpectralClustering(n_clusters=4, affinity='nearest_neighbors')\nsklearn_cluster_labels = clust.fit_predict(X_clustering)\n\n# Test the accuracy of the clustering\nsk_score = homogeneity_score(y, sklearn_cluster_labels)\nprint('Singleview homogeneity score: {0:.3f}'.format(sk_score))\n\n# Rearrange for easier visual comparison to true label plot\nsklearn_cluster_labels = rearrange_labels(y, sklearn_cluster_labels)\n\n# Use PCA for dimensionality reduction on the naive single view\npca = PCA(n_components=2)\npca_X = pca.fit_transform(X_viewing)\n\nplt.figure(figsize=(5, 5))\nplt.scatter(pca_X[:, 0], pca_X[:, 1], c=sklearn_cluster_labels, **sca_kwargs)\nplt.xticks([], [])\nplt.yticks([], [])\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.title(\"Predicted Clusters\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}