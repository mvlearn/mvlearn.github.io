{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 2-View Semi-Supervised Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom mvlearn.semi_supervised import CTClassifier\nfrom mvlearn.datasets import load_UCImultifeature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the UCI Multiple Digit Features Dataset\n\nTo simulate a semi-supervised learning scenario, randomly remove 98% of the\nlabels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data, labels = load_UCImultifeature(select_labeled=[0, 1])\n\n# Use only the first 2 views as an example\nView0, View1 = data[0], data[1]\n\n# Split both views into testing and training\nView0_train, View0_test, labels_train, labels_test = train_test_split(\n    View0, labels, test_size=0.33, random_state=42)\nView1_train, View1_test, labels_train, labels_test = train_test_split(\n    View1, labels, test_size=0.33, random_state=42)\n\n# Randomly remove all but 4 of the labels\nnp.random.seed(6)\nremove_idx = np.random.rand(len(labels_train),) < 0.98\nlabels_train[remove_idx] = np.nan\nnot_removed = np.where(~remove_idx)\nprint(\"Remaining labeled sample labels: \" + str(labels_train[not_removed]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Co-Training on 2 Views vs. Single View Semi-Supervised Learning\nHere, we use the default co-training classifier, which uses Gaussian naive\nbayes classifiers for both views. We compare its performance to the single-\nview semi-supervised setting with the same basic classifiers, and with the\nnaive technique of concatenating the two views and performing single view\nlearning.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Single view semi-supervised learning\n\ngnb0 = GaussianNB()\ngnb1 = GaussianNB()\ngnb2 = GaussianNB()\n\n# Train on only the examples with labels\ngnb0.fit(View0_train[not_removed, :].squeeze(), labels_train[not_removed])\ny_pred0 = gnb0.predict(View0_test)\ngnb1.fit(View1_train[not_removed, :].squeeze(), labels_train[not_removed])\ny_pred1 = gnb1.predict(View1_test)\n# Concatenate the 2 views for naive \"multiview\" learning\nView01_train = np.hstack(\n    (View0_train[not_removed, :].squeeze(),\n     View1_train[not_removed, :].squeeze()))\nView01_test = np.hstack((View0_test, View1_test))\ngnb2.fit(View01_train, labels_train[not_removed])\ny_pred2 = gnb2.predict(View01_test)\n\nprint(\"Single View Accuracy on First View: {0:.3f}\\n\".format(\n    accuracy_score(labels_test, y_pred0)))\nprint(\"Single View Accuracy on Second View: {0:.3f}\\n\".format(\n    accuracy_score(labels_test, y_pred1)))\nprint(\"Naive Concatenated View Accuracy: {0:.3f}\\n\".format(\n    accuracy_score(labels_test, y_pred2)))\n\n# Multi-view co-training semi-supervised learning\n# Train a CTClassifier on all the labeled and unlabeled training data\n\nctc = CTClassifier()\nctc.fit([View0_train, View1_train], labels_train)\ny_pred_ct = ctc.predict([View0_test, View1_test])\n\nprint(f\"Co-Training Accuracy on 2 Views: \\\n    {accuracy_score(labels_test, y_pred_ct):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select a different base classifier for the CTClassifier\nNow, we use a random forest classifier with different attributes for each\nview.\nFurthermore, we manually select the number of positive (p) and negative (n)\nexamples chosen each round in the co-training process, and we define the\nunlabeled pool size to draw them from and the number of iterations of\ntraining to perform.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Single view semi-supervised learning\nrfc0 = RandomForestClassifier(n_estimators=100, bootstrap=True)\nrfc1 = RandomForestClassifier(n_estimators=6, bootstrap=False)\nrfc2 = RandomForestClassifier(n_estimators=100, bootstrap=False)\n\n# Train on only the examples with labels\nrfc0.fit(View0_train[not_removed, :].squeeze(), labels_train[not_removed])\ny_pred0 = rfc0.predict(View0_test)\nrfc1.fit(View1_train[not_removed, :].squeeze(), labels_train[not_removed])\ny_pred1 = rfc1.predict(View1_test)\n# Concatenate the 2 views for naive \"multiview\" learning\nView01_train = np.hstack(\n    (View0_train[not_removed, :].squeeze(),\n     View1_train[not_removed, :].squeeze()))\nView01_test = np.hstack((View0_test, View1_test))\nrfc2.fit(View01_train, labels_train[not_removed])\ny_pred2 = rfc2.predict(View01_test)\n\nprint(\"Single View Accuracy on First View: {0:.3f}\\n\".format(\n    accuracy_score(labels_test, y_pred0)))\nprint(\"Single View Accuracy on Second View: {0:.3f}\\n\".format(\n    accuracy_score(labels_test, y_pred1)))\nprint(\"Naive Concatenated View Accuracy: {0:.3f}\\n\".format(\n    accuracy_score(labels_test, y_pred2)))\n\n# Multi-view co-training semi-supervised learning\n\nrfc0 = RandomForestClassifier(n_estimators=100, bootstrap=True)\nrfc1 = RandomForestClassifier(n_estimators=6, bootstrap=False)\nctc = CTClassifier(rfc0, rfc1, p=2, n=2, unlabeled_pool_size=20, num_iter=100)\nctc.fit([View0_train, View1_train], labels_train)\ny_pred_ct = ctc.predict([View0_test, View1_test])\n\nprint(f\"Co-Training Accuracy: \\\n    {accuracy_score(labels_test, y_pred_ct):.3f}\")\n\n# Get the prediction probabilities for all the examples\n\ny_pred_proba = ctc.predict_proba([View0_test, View1_test])\nprint(\"Full y_proba shape = \" + str(y_pred_proba.shape))\nprint(\"\\nFirst 10 class probabilities:\\n\")\nprint(y_pred_proba[:10, :])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}